{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "documentary-theta",
   "metadata": {},
   "source": [
    "## Topic Modeling & Subject Headings\n",
    "\n",
    "## gensim \n",
    "\n",
    "Kapadia, Shashank, \"[Topic Modeling in Python: Latent Dirichlet Allocation (LDA)](https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0),\" <i>towards data science</i>, Accessed 10/09/2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "systematic-springer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>entry</th>\n",
       "      <th>date</th>\n",
       "      <th>subject</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>('JQADiaries-v49-1825-01-p795.xml',)</td>\n",
       "      <td>jqadiaries-v49-1825-01-10</td>\n",
       "      <td>1825-01-10</td>\n",
       "      <td>War of 1812,Foreign Relations</td>\n",
       "      <td>10. VI:45. Visits at my house from John Herkim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>('JQADiaries-v49-1825-01-p795.xml',)</td>\n",
       "      <td>jqadiaries-v49-1825-01-11</td>\n",
       "      <td>1825-01-11</td>\n",
       "      <td>Native Americans,Adams Family Finances,Foreign...</td>\n",
       "      <td>11. VII. Visitors, W. Plumer jr. Settled with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>('JQADiaries-v49-1825-01-p795.xml',)</td>\n",
       "      <td>jqadiaries-v49-1825-01-12</td>\n",
       "      <td>1825-01-12</td>\n",
       "      <td>Native Americans</td>\n",
       "      <td>12. V:30.Thomas J. Hellen went at 6. in the St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>('JQADiaries-v49-1825-01-p795.xml',)</td>\n",
       "      <td>jqadiaries-v49-1825-01-13</td>\n",
       "      <td>1825-01-13</td>\n",
       "      <td>Elections, Presidential (1824),Slavery,Coloniz...</td>\n",
       "      <td>13. VI:15. I called this morning on James Barb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>('JQADiaries-v49-1825-06-p849.xml',)</td>\n",
       "      <td>jqadiaries-v49-1825-06-17</td>\n",
       "      <td>1825-06-17</td>\n",
       "      <td>Recreation</td>\n",
       "      <td>17. IV:45. symbols 31 symbols 32 symbols  Bath...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    file                      entry  \\\n",
       "9   ('JQADiaries-v49-1825-01-p795.xml',)  jqadiaries-v49-1825-01-10   \n",
       "10  ('JQADiaries-v49-1825-01-p795.xml',)  jqadiaries-v49-1825-01-11   \n",
       "11  ('JQADiaries-v49-1825-01-p795.xml',)  jqadiaries-v49-1825-01-12   \n",
       "12  ('JQADiaries-v49-1825-01-p795.xml',)  jqadiaries-v49-1825-01-13   \n",
       "31  ('JQADiaries-v49-1825-06-p849.xml',)  jqadiaries-v49-1825-06-17   \n",
       "\n",
       "          date                                            subject  \\\n",
       "9   1825-01-10                      War of 1812,Foreign Relations   \n",
       "10  1825-01-11  Native Americans,Adams Family Finances,Foreign...   \n",
       "11  1825-01-12                                   Native Americans   \n",
       "12  1825-01-13  Elections, Presidential (1824),Slavery,Coloniz...   \n",
       "31  1825-06-17                                         Recreation   \n",
       "\n",
       "                                                 text  \n",
       "9   10. VI:45. Visits at my house from John Herkim...  \n",
       "10  11. VII. Visitors, W. Plumer jr. Settled with ...  \n",
       "11  12. V:30.Thomas J. Hellen went at 6. in the St...  \n",
       "12  13. VI:15. I called this morning on James Barb...  \n",
       "31  17. IV:45. symbols 31 symbols 32 symbols  Bath...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries.\n",
    "import re, nltk, warnings, csv, sys, os, gensim, tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from itertools import chain\n",
    "from scipy import stats\n",
    "\n",
    "# Import NLTK packages.\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Import and append stopwords.\n",
    "stop_words = stopwords.words(\"english\")\n",
    "stop_words.append('mr')\n",
    "\n",
    "# Ignore warnings related to deprecated functions.\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "\n",
    "# Declare directory location to shorten filepaths later.\n",
    "abs_dir = \"/Users/quinn.wi/Documents/Data/\"\n",
    "\n",
    "# Read in file; select columns; drop rows with NA values (entries without a named person).\n",
    "df = pd.read_csv(abs_dir + 'Output/ParsedXML/JQA_Subjects-dataframe.txt',\n",
    "                 sep = '\\t') \\\n",
    "    .dropna()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-basis",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "quick-peninsula",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 3.81 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[w for w in simple_preprocess(str(doc)) if w not in stop_words] for doc in texts]\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield (gensim.utils.simple_preprocess(str(sentence), deacc = True)) # deacc = True :: removes punctuation\n",
    "        \n",
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus = corpus, \n",
    "                                           id2word = id2word, \n",
    "                                           num_topics = 10, \n",
    "                                           random_state = 100, \n",
    "                                           chunksize = 100, \n",
    "                                           passes = 10, \n",
    "                                           alpha = a, \n",
    "                                           eta = b, \n",
    "                                           per_word_topics = True)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model = lda_model, \n",
    "                                         texts = data_words, \n",
    "                                         dictionary = id2word, \n",
    "                                         coherence = 'c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-allen",
   "metadata": {},
   "source": [
    "## Create Corpus Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "native-employee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.69 s, sys: 33.2 ms, total: 2.72 s\n",
      "Wall time: 2.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Convert text to list.\n",
    "data = df['text'].values.tolist()\n",
    "        \n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "# Create corpus + remove stopwords.\n",
    "texts = remove_stopwords(data_words)\n",
    "\n",
    "# Create dictionary.\n",
    "id2word = corpora.Dictionary(texts)\n",
    "\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-minneapolis",
   "metadata": {},
   "source": [
    "## Evaluate Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dense-shoulder",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [20:44<?, ?it/s]\n",
      "  0%|          | 0/30 [2:07:40<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 9s, sys: 2min 36s, total: 17min 46s\n",
      "Wall time: 2h 7min 40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Topics range.\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "\n",
    "min_topics = 10\n",
    "max_topics = 100\n",
    "step_size = 10\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "beta.append('symmetric')\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(corpus)\n",
    "\n",
    "corpus_sets = [corpus]\n",
    "\n",
    "corpus_title = ['100% corpus']\n",
    "\n",
    "model_results = {'Validation_Set': [], 'Topics': [], 'Alpha': [], 'Beta': [], 'Coherence': []}\n",
    "\n",
    "# Run model (can take a long time)\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total = 30)\n",
    "    \n",
    "#     iterate through validation corpora\n",
    "    for i in range(len(corpus_sets)):\n",
    "        \n",
    "#         iterate through number of topics.\n",
    "        for k in topics_range:\n",
    "            \n",
    "#             Adjust alpha and beta once number of topics determined.\n",
    "#             iterature through alpha values\n",
    "            for a in alpha:\n",
    "            \n",
    "#                 iterature through beta values\n",
    "                for b in beta:\n",
    "                    \n",
    "#                     Get coherence score for given parameters\n",
    "                    cv = compute_coherence_values(corpus = corpus_sets[i], \n",
    "                                                  dictionary = id2word, \n",
    "                                                  k = k, \n",
    "                                                  a = a, \n",
    "                                                  b = b)\n",
    "#                     Save model results.\n",
    "                    model_results['Validation_Set'].append(corpus_sets[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv)\n",
    "                    \n",
    "    pd.DataFrame(model_results).to_csv(abs_dir + 'Output/TopicModels/jqa_topics_tuning.csv', sep = ',', index = False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-novel",
   "metadata": {},
   "source": [
    "## Load results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "revolutionary-stuart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.11 s, sys: 227 ms, total: 2.34 s\n",
      "Wall time: 2.36 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validation_Set</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9099999999999999</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.345717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, ...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.9099999999999999</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.343886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>[[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, ...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.9099999999999999</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.343886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>[[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, ...</td>\n",
       "      <td>90</td>\n",
       "      <td>0.9099999999999999</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.343886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>[[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, ...</td>\n",
       "      <td>60</td>\n",
       "      <td>0.9099999999999999</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.343886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Validation_Set  Topics  \\\n",
       "17   [[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, ...      10   \n",
       "47   [[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, ...      20   \n",
       "77   [[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, ...      30   \n",
       "257  [[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, ...      90   \n",
       "167  [[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, ...      60   \n",
       "\n",
       "                  Alpha  Beta  Coherence  \n",
       "17   0.9099999999999999  0.61   0.345717  \n",
       "47   0.9099999999999999  0.61   0.343886  \n",
       "77   0.9099999999999999  0.61   0.343886  \n",
       "257  0.9099999999999999  0.61   0.343886  \n",
       "167  0.9099999999999999  0.61   0.343886  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results = pd.read_csv(abs_dir + 'Output/TopicModels/jqa_topics_tuning.csv', sep = ',')\n",
    "\n",
    "results.sort_values(by = ['Coherence'], ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-level",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
