{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prerequisite-atmosphere",
   "metadata": {},
   "source": [
    "# Subject Correlations & Year Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e851827b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'JQA_XML_parser'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t2/01ffpgd11p9_t88s5bg2d2fm0000gp/T/ipykernel_58666/4014439048.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mJQA_XML_parser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'JQA_XML_parser'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries.\n",
    "import re, nltk, warnings, csv, sys, os, pickle, string, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from itertools import chain\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools as iter\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "from networkx.readwrite import json_graph\n",
    "from json import JSONEncoder\n",
    "from operator import itemgetter\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Import project-specific functions. \n",
    "# Python files (.py) have to be in same folder to work.\n",
    "lib_path = os.path.abspath(os.path.join(os.path.dirname('JQA_XML_parser.py'), '../Scripts'))\n",
    "sys.path.append(lib_path)\n",
    "\n",
    "from JQA_XML_parser import *\n",
    "\n",
    "\n",
    "# Ignore warnings related to deprecated functions.\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbdfbc9",
   "metadata": {},
   "source": [
    "## Gather XML Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Declare directory location to shorten filepaths later.\n",
    "abs_dir = \"/Users/quinn.wi/Documents/Data\"\n",
    "files = glob.glob(abs_dir + \"/PSC/JQA/*/*.xml\")\n",
    "\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cefb51",
   "metadata": {},
   "source": [
    "## Build Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c32e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Build dataframe from XML files.\n",
    "# build_dataframe() called from Correspondence_XML_parser\n",
    "df = build_dataframe(files)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0500ee9b",
   "metadata": {},
   "source": [
    "## Count Subject Headings by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f71625",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Extract month, year from date.\n",
    "df['date'] = pd.to_datetime(df['date'], format = '%Y-%m-%d', errors = 'ignore')\n",
    "df['month'] = df['date'].dt.month\n",
    "df['year'] = df['date'].dt.year\n",
    "\n",
    "# Group by month, year and count subjects.\n",
    "subjects = df.groupby(['year', 'subject'], as_index = False)['subject'] \\\n",
    "    .size() \\\n",
    "    .reset_index()\n",
    "\n",
    "subjects.columns = ['year', 'subject', 'count']\n",
    "\n",
    "subjects.to_csv(abs_dir + 'GitHub/dsg-mhs/lab_space/data/subjects/subject-year-count.csv',\n",
    "                sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-proof",
   "metadata": {},
   "source": [
    "## Create Adjacency Matrix of Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create adjacency matrix.\n",
    "adj = pd.crosstab(df['entry'], df['subject'])\n",
    "\n",
    "# Convert entry-person matrix into an adjacency matrix of persons.\n",
    "adj = adj.T.dot(adj)\n",
    "\n",
    "# Change same-same connections to zero.\n",
    "np.fill_diagonal(adj.values, 0)\n",
    "\n",
    "# Simple correlation matrix from dataframe.\n",
    "adj = adj.corr()\n",
    "\n",
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "sns.clustermap(adj, z_score = 1)\n",
    "\n",
    "plt.figure(figsize=(16, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fda3e47",
   "metadata": {},
   "source": [
    "## Save Subject Adj. as Network Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c68e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "adj['source'] = adj.index\n",
    "\n",
    "df = pd.melt(adj, id_vars = ['source'], var_name = 'target', value_name = 'weight') \\\n",
    "    .query('(source != target) & (weight > 0.65)')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079645ff",
   "metadata": {},
   "source": [
    "## Create Graph Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84646ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize graph object.\n",
    "G = nx.from_pandas_edgelist(df, 'source', 'target', 'weight')\n",
    "\n",
    "# Add nodes.\n",
    "nodes = list( dict.fromkeys( df['source'].values.tolist() + df['target'].values.tolist() ))\n",
    "nodes = pd.DataFrame(nodes, columns = ['source'])\n",
    "G.add_nodes_from(nodes)\n",
    "\n",
    "print (nx.info(G))\n",
    "\n",
    "# Set degree attributes.\n",
    "nx.set_node_attributes(G, dict(G.degree(G.nodes())), 'degree')\n",
    "\n",
    "# Sort nodes by degree and print top results.\n",
    "sorted_degree = sorted(dict(G.degree(G.nodes())).items(),\n",
    "                       key = itemgetter(1), reverse = True)\n",
    "\n",
    "print (\"Top 10 nodes by degree:\")\n",
    "for d in sorted_degree[:10]:\n",
    "    print (f'\\t{d}')\n",
    "\n",
    "\n",
    "# Measure network density.\n",
    "density = nx.density(G)\n",
    "print (f\"Network density: {density:.3f}\")\n",
    "\n",
    "# Related to diameter, check if network is connected and, therefore, can have a diameter.\n",
    "print (f\"Is the network connected? {nx.is_connected(G)}\")\n",
    "\n",
    "# Get a list of network components (communities).\n",
    "# Find the largest component.\n",
    "components = nx.connected_components(G)\n",
    "largest_component = max(components, key = len)\n",
    "\n",
    "# Create a subgraph of the largest component and measure its diameter.\n",
    "subgraph = G.subgraph(largest_component)\n",
    "diameter = nx.diameter(subgraph)\n",
    "print (f\"Network diameter of the largest component: {diameter:.3f}\")\n",
    "\n",
    "# Find triadic closure (similar to density).\n",
    "triadic_closure = nx.transitivity(G)\n",
    "print (f\"Triadic closure: {triadic_closure:.3f}\\n\")\n",
    "\n",
    "# Find centrality measures.\n",
    "betweenness_dict = nx.betweenness_centrality(G) # Run betweenness centrality\n",
    "eigenvector_dict = nx.eigenvector_centrality(G) # Run eigenvector centrality\n",
    "degree_cent_dict = nx.degree_centrality(G)\n",
    "\n",
    "# Assign each centrality measure to an attribute.\n",
    "nx.set_node_attributes(G, betweenness_dict, 'betweenness')\n",
    "nx.set_node_attributes(G, eigenvector_dict, 'eigenvector')\n",
    "nx.set_node_attributes(G, degree_cent_dict, 'degree_cent')\n",
    "\n",
    "\n",
    "# Find communities.\n",
    "communities = community.greedy_modularity_communities(G)\n",
    "\n",
    "# Create a dictionary that maps nodes to their community.\n",
    "modularity_dict = {}\n",
    "for i, c in enumerate(communities):\n",
    "    for name in c:\n",
    "        modularity_dict[name] = i\n",
    "        \n",
    "# Add modularity information to graph object.\n",
    "nx.set_node_attributes(G, modularity_dict, 'modularity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b41cfc",
   "metadata": {},
   "source": [
    "## Write Graph Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d3c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# Convert graph object into a dictionary.\n",
    "data = json_graph.node_link_data(G)\n",
    "    \n",
    "data_json = json.dumps(data)\n",
    "\n",
    "with open(abs_dir + \"Data/Output/Graphs/JQA_Network_correlation/jqa-subjects-network.json\", \"w\") as f:\n",
    "    f.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c211eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
