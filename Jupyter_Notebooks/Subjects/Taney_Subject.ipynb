{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e88c6972",
   "metadata": {},
   "source": [
    "# Subject Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae54e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries.\n",
    "import re, nltk, warnings, csv, sys, os, pickle, string, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import glob as glob\n",
    "from itertools import chain\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools as iter\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "from networkx.readwrite import json_graph\n",
    "from json import JSONEncoder\n",
    "from operator import itemgetter\n",
    "from collections import Counter\n",
    "\n",
    "# Import project-specific functions. \n",
    "# Python files (.py) have to be in same folder to work.\n",
    "lib_path = os.path.abspath(os.path.join(os.path.dirname('Correspondence_XML_parser.py'), '../Scripts'))\n",
    "sys.path.append(lib_path)\n",
    "\n",
    "from Correspondence_XML_parser import *\n",
    "\n",
    "# Ignore warnings related to deprecated functions.\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119ec85c",
   "metadata": {},
   "source": [
    "## Gather XML Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70bbe673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.24 ms, sys: 1.43 ms, total: 2.67 ms\n",
      "Wall time: 1.68 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Declare directory location to shorten filepaths later.\n",
    "abs_dir = \"/Users/quinn.wi/Documents/\"\n",
    "\n",
    "input_directory = \"Data/PSC/Taney/RBT_RawXML/*/*.xml\"\n",
    "\n",
    "# Gather all .xml files using glob.\n",
    "files = glob.glob(abs_dir + input_directory)\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c9a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # Must be connected to Northeastern's VPN.\n",
    "# r = requests.get(url, \n",
    "#                  auth = (user, pw), \n",
    "#                  headers = {'Content-Type': 'application/xml'}\n",
    "#                 )\n",
    "    \n",
    "# # Read in contents of pipeline.\n",
    "# soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "# # Split soup's content by \\n (each line is a file path to an XML doc).\n",
    "# # Use filter() to remove empty strings ('').\n",
    "# # Convert back to list using list().\n",
    "# files = list(filter(None, soup.text.split('\\n')))\n",
    "\n",
    "# # Filter list and retrieve only jqa/ files.\n",
    "# files = [i for i in files if 'jqa/' in i]\n",
    "\n",
    "# len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52787d8",
   "metadata": {},
   "source": [
    "## Build Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab81851b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 75.8 ms, sys: 8.81 ms, total: 84.6 ms\n",
      "Wall time: 84.4 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>subjects</th>\n",
       "      <th>references</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RBT00099-verification.xml</td>\n",
       "      <td>1833-05-05</td>\n",
       "      <td>RBT</td>\n",
       "      <td>Ellicott-Thomas</td>\n",
       "      <td></td>\n",
       "      <td>jackson-andrew,kendall-amos,mickle-robert,tane...</td>\n",
       "      <td>Washington May 5. 1833My Dear Sir I received y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RBT00146-verification.xml</td>\n",
       "      <td>1834-03-30</td>\n",
       "      <td>RBT</td>\n",
       "      <td>ellicott-thomas</td>\n",
       "      <td></td>\n",
       "      <td>mccubbin-george</td>\n",
       "      <td>Washington March 30. 1834My Dear Sir I have on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RBT01364-verification.xml</td>\n",
       "      <td>1833-08-05</td>\n",
       "      <td>RBT</td>\n",
       "      <td>jackson-andrew</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Washington Augt. 5. 1833 My Dear Sir After ref...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        file        date source           target subjects  \\\n",
       "0  RBT00099-verification.xml  1833-05-05    RBT  Ellicott-Thomas            \n",
       "1  RBT00146-verification.xml  1834-03-30    RBT  ellicott-thomas            \n",
       "2  RBT01364-verification.xml  1833-08-05    RBT   jackson-andrew            \n",
       "\n",
       "                                          references  \\\n",
       "0  jackson-andrew,kendall-amos,mickle-robert,tane...   \n",
       "1                                    mccubbin-george   \n",
       "2                                                      \n",
       "\n",
       "                                                text  \n",
       "0  Washington May 5. 1833My Dear Sir I received y...  \n",
       "1  Washington March 30. 1834My Dear Sir I have on...  \n",
       "2  Washington Augt. 5. 1833 My Dear Sir After ref...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Build dataframe from XML files.\n",
    "# build_dataframe() called from Correspondence_XML_parser\n",
    "\n",
    "# df = build_dataframe(files, url, user, pw)\n",
    "df = build_dataframe(files)\n",
    "\n",
    "# Unnest subject headings. \n",
    "df['subjects'] = df['subjects'].str.split(',')\n",
    "df = df.explode('subjects')\n",
    "\n",
    "# Remove leading and trailing whitespace.\n",
    "df['subjects'] = df['subjects'].str.strip()\n",
    "\n",
    "# Remove rows with subject of \"The\".\n",
    "df = df[~df['subjects'].isin(['The'])]\n",
    "\n",
    "# Remove rows with empty values.\n",
    "df.replace('', np.nan, inplace = True)\n",
    "df.dropna(inplace = True)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f3e00e",
   "metadata": {},
   "source": [
    "## Count Subject Headings by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de98e90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 ms, sys: 3.54 ms, total: 19.6 ms\n",
      "Wall time: 18.4 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>subjects</th>\n",
       "      <th>count</th>\n",
       "      <th>total</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [year, subjects, count, total, percentage]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Extract month, year from date.\n",
    "df['date'] = pd.to_datetime(df['date'], format = '%Y-%m-%d', errors = 'coerce')\n",
    "df = df.query('date != \"NaT\"') # remove Not-a-Time values.\n",
    "\n",
    "df['month'] = df['date'].dt.month\n",
    "df['year'] = df['date'].dt.year\n",
    "\n",
    "# Group by year & subject to get count of subjects per year.\n",
    "subjects = df.groupby(['year', 'subjects'], as_index = False)['subjects'] \\\n",
    "    .size() \\\n",
    "    .reset_index()\n",
    "\n",
    "subjects.columns = ['year', 'subjects', 'count']\n",
    "\n",
    "# Group by year and get total number of subjects per year.\n",
    "subjects['total'] = subjects.groupby('year')['count'].transform('sum')\n",
    "\n",
    "# Get percentage of subject for each year.\n",
    "subjects['percentage'] = round(subjects['count'] / subjects['total'], 2) * 100\n",
    "\n",
    "subjects.to_csv(abs_dir + 'Github/dsg-mhs/lab_space/projects/taney/subjects/data/subject-year-count.csv',\n",
    "                sep = ',', index = False)\n",
    "\n",
    "subjects.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41111298",
   "metadata": {},
   "source": [
    "## Create Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc2d700c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.57 ms, sys: 452 µs, total: 7.03 ms\n",
      "Wall time: 6.88 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create adjacency matrix.\n",
    "adj = pd.crosstab(df['file'], df['subjects'])\n",
    "\n",
    "# Convert entry-person matrix into an adjacency matrix of persons.\n",
    "adj = adj.T.dot(adj)\n",
    "\n",
    "# Change same-same connections to zero.\n",
    "np.fill_diagonal(adj.values, 0)\n",
    "\n",
    "# Simple correlation matrix from dataframe.\n",
    "adj = adj.corr()\n",
    "\n",
    "adj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c296eb",
   "metadata": {},
   "source": [
    "## Create Graph Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55e53556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.16 ms, sys: 291 µs, total: 9.45 ms\n",
      "Wall time: 9.28 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [source, target, weight]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "adj['source'] = adj.index\n",
    "\n",
    "df = pd.melt(adj, id_vars = ['source'], var_name = 'target', value_name = 'weight') \\\n",
    "    .query('(source != target) & (weight > 0.55)') \\\n",
    "    .query('source != \"source\"')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf2c755c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0122ece",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t2/01ffpgd11p9_t88s5bg2d2fm0000gp/T/ipykernel_59966/2020628139.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'G' is not defined"
     ]
    }
   ],
   "source": [
    "G.nodes( data = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecfd7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize graph object.\n",
    "G = nx.from_pandas_edgelist(df, 'source', 'target', 'weight')\n",
    "\n",
    "# Add nodes.\n",
    "nodes = list( dict.fromkeys( df['source'].values.tolist() + df['target'].values.tolist() ))\n",
    "G.add_nodes_from(nodes)\n",
    "\n",
    "print (nx.info(G))\n",
    "\n",
    "# Set degree attributes.\n",
    "nx.set_node_attributes(G, dict(G.degree(G.nodes())), 'degree')\n",
    "\n",
    "# Sort nodes by degree and print top results.\n",
    "sorted_degree = sorted(dict(G.degree(G.nodes())).items(),\n",
    "                       key = itemgetter(1), reverse = True)\n",
    "\n",
    "print (\"Top 10 nodes by degree:\")\n",
    "for d in sorted_degree[:10]:\n",
    "    print (f'\\t{d}')\n",
    "\n",
    "\n",
    "# Measure network density.\n",
    "density = nx.density(G)\n",
    "print (f\"Network density: {density:.3f}\")\n",
    "\n",
    "# Related to diameter, check if network is connected and, therefore, can have a diameter.\n",
    "print (f\"Is the network connected? {nx.is_connected(G)}\")\n",
    "\n",
    "# Get a list of network components (communities).\n",
    "# Find the largest component.\n",
    "components = nx.connected_components(G)\n",
    "largest_component = max(components, key = len)\n",
    "\n",
    "# Create a subgraph of the largest component and measure its diameter.\n",
    "subgraph = G.subgraph(largest_component)\n",
    "diameter = nx.diameter(subgraph)\n",
    "print (f\"Network diameter of the largest component: {diameter:.3f}\")\n",
    "\n",
    "# Find triadic closure (similar to density).\n",
    "triadic_closure = nx.transitivity(G)\n",
    "print (f\"Triadic closure: {triadic_closure:.3f}\\n\")\n",
    "\n",
    "# Find centrality measures.\n",
    "betweenness_dict = nx.betweenness_centrality(G) # Run betweenness centrality\n",
    "eigenvector_dict = nx.eigenvector_centrality(G) # Run eigenvector centrality\n",
    "degree_cent_dict = nx.degree_centrality(G)\n",
    "\n",
    "# Assign each centrality measure to an attribute.\n",
    "nx.set_node_attributes(G, betweenness_dict, 'betweenness')\n",
    "nx.set_node_attributes(G, eigenvector_dict, 'eigenvector')\n",
    "nx.set_node_attributes(G, degree_cent_dict, 'degree_cent')\n",
    "\n",
    "\n",
    "# Find communities.\n",
    "communities = community.naive_greedy_modularity_communities(subgraph)\n",
    "\n",
    "# Create a dictionary that maps nodes to their community.\n",
    "modularity_dict = {}\n",
    "for i, c in enumerate(communities):\n",
    "    for name in c:\n",
    "        modularity_dict[name] = i\n",
    "        \n",
    "# Add modularity information to graph object.\n",
    "nx.set_node_attributes(G, modularity_dict, 'modularity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889e86e2",
   "metadata": {},
   "source": [
    "## Save Graph Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2a249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Convert graph object into a dictionary.\n",
    "data = json_graph.node_link_data(G)\n",
    "    \n",
    "data_json = json.dumps(data)\n",
    "\n",
    "with open(abs_dir + \"Github/dsg-mhs/lab_space/projects/taney/subjects/data/taney-subjects-network.json\", \"w\") as f:\n",
    "    f.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154117ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
