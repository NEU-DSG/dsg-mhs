{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e89a19",
   "metadata": {},
   "source": [
    "# Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b554e7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json, glob, csv, sys, os, warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools as iter\n",
    "import networkx as nx\n",
    "import xml.etree.ElementTree as ET\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.algorithms import community\n",
    "from networkx.readwrite import json_graph\n",
    "from json import JSONEncoder\n",
    "from operator import itemgetter\n",
    "from collections import Counter\n",
    "\n",
    "# Ignore warnings related to deprecated functions.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import project-specific functions. \n",
    "# Python files (.py) have to be in same folder to work.\n",
    "lib_path = os.path.abspath(os.path.join(os.path.dirname('Correspondence_XML_parser.py'), '../Scripts'))\n",
    "sys.path.append(lib_path)\n",
    "from Correspondence_XML_parser import *\n",
    "\n",
    "# # Read in config.py (git ignored file) for API username and pw.\n",
    "# config_path = os.path.abspath(os.path.join(os.path.dirname('config.py'), '../Scripts'))\n",
    "# sys.path.append(config_path)\n",
    "# import config\n",
    "\n",
    "# url = 'https://dsg.xmldb-dev.northeastern.edu/BaseX964/rest/psc/'\n",
    "# user = config.username\n",
    "# pw = config.password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b22601a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 739 Âµs, sys: 1.3 ms, total: 2.04 ms\n",
      "Wall time: 1.69 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Declare directory location to shorten filepaths later.\n",
    "abs_dir = \"/Users/quinn.wi/Documents/\"\n",
    "\n",
    "input_directory = \"Data/PSC/Taney/TaneyXML-Oct2020/*.xml\"\n",
    "\n",
    "# Gather all .xml files using glob.\n",
    "files = glob.glob(abs_dir + input_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909ac91b",
   "metadata": {},
   "source": [
    "## Gather XML Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ba9f183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # Must be connected to Northeastern's VPN.\n",
    "# r = requests.get(url, \n",
    "#                  auth = (user, pw), \n",
    "#                  headers = {'Content-Type': 'application/xml'}\n",
    "#                 )\n",
    "    \n",
    "# # Read in contents of pipeline.\n",
    "# soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "# # Split soup's content by \\n (each line is a file path to an XML doc).\n",
    "# # Use filter() to remove empty strings ('').\n",
    "# # Convert back to list using list().\n",
    "# files = list(filter(None, soup.text.split('\\n')))\n",
    "\n",
    "# # Filter list and retrieve only jqa/ files.\n",
    "# files = [i for i in files if 'jqa/' in i]\n",
    "\n",
    "# len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fbbae8",
   "metadata": {},
   "source": [
    "## Build Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "040c92a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/quinn.wi/Documents/Data/PSC/Taney/TaneyXML-Oct2020/RBT00009-collation.xml \n",
      "\n",
      "/Users/quinn.wi/Documents/Data/PSC/Taney/TaneyXML-Oct2020/RBT00021-collation.xml \n",
      "\n",
      "/Users/quinn.wi/Documents/Data/PSC/Taney/TaneyXML-Oct2020/RBT00022-collation.xml \n",
      "\n",
      "CPU times: user 71.6 ms, sys: 4.58 ms, total: 76.2 ms\n",
      "Wall time: 75.2 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>subjects</th>\n",
       "      <th>references</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RBT00107-collation.xml</td>\n",
       "      <td>1833-09-11</td>\n",
       "      <td>rbt</td>\n",
       "      <td>ellicott-thomas</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>Washington Sept. 11. 1833 My Dear Sir I hope ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RBT00110-collation.xml</td>\n",
       "      <td>1833-09-19</td>\n",
       "      <td>rbt</td>\n",
       "      <td>ellicott-thomas</td>\n",
       "      <td>Bank War</td>\n",
       "      <td>[]</td>\n",
       "      <td>Washington Sept. 20th 1833 My Dear Sir I rece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RBT00667-collation.xml</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>rbt</td>\n",
       "      <td>henshaw-david</td>\n",
       "      <td>Bank of the United States,Treasury</td>\n",
       "      <td>[]</td>\n",
       "      <td>October 2nd 183 Sir, It having been intimated...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     file        date source           target  \\\n",
       "0  RBT00107-collation.xml  1833-09-11    rbt  ellicott-thomas   \n",
       "1  RBT00110-collation.xml  1833-09-19    rbt  ellicott-thomas   \n",
       "2  RBT00667-collation.xml  0000-00-00    rbt    henshaw-david   \n",
       "\n",
       "                             subjects references  \\\n",
       "0                                             []   \n",
       "1                            Bank War         []   \n",
       "2  Bank of the United States,Treasury         []   \n",
       "\n",
       "                                                text  \n",
       "0   Washington Sept. 11. 1833 My Dear Sir I hope ...  \n",
       "1   Washington Sept. 20th 1833 My Dear Sir I rece...  \n",
       "2   October 2nd 183 Sir, It having been intimated...  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Build dataframe from XML files.\n",
    "# build_dataframe() called from Correspondence_XML_parser\n",
    "# df = build_dataframe(files, url, user, pw)\n",
    "\n",
    "df = build_dataframe(files)\n",
    "\n",
    "# Lowercase values in source, target, and reference columns.\n",
    "df['source'] = df['source'].str.lower()\n",
    "df['target'] = df['target'].str.lower()\n",
    "df['references'] = df['references'].str.lower()\n",
    "\n",
    "# Split references into list objects.\n",
    "df['references'] = df['references'].str.split(r',|;')\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dea9bd6",
   "metadata": {},
   "source": [
    "## Create Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fd32b6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50 ms, sys: 2.4 ms, total: 52.4 ms\n",
      "Wall time: 50.5 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>gill-x</td>\n",
       "      <td>benton-thomas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>jackson-andrew</td>\n",
       "      <td>benton-thomas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>perine-david</td>\n",
       "      <td>benton-thomas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            source         target  weight\n",
       "38          gill-x  benton-thomas       1\n",
       "40  jackson-andrew  benton-thomas       1\n",
       "49    perine-david  benton-thomas       1"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Explode list so that each list value becomes a row.\n",
    "refs = df.explode('references')\n",
    "\n",
    "# Create file-person matrix.\n",
    "refs = pd.crosstab(refs['file'], refs['references'])\n",
    "\n",
    "# Repeat with correspondence (source + target)\n",
    "source = pd.crosstab(df['file'], df['source'])\n",
    "target = pd.crosstab(df['file'], df['target'])\n",
    "\n",
    "# Sum values of sources to refs or create new column with sources' values.\n",
    "for col in source:\n",
    "    if col in refs:\n",
    "        refs[str(col)] = refs[str(col)] + source[str(col)]\n",
    "    else:\n",
    "        refs[str(col)] = source[str(col)]\n",
    "\n",
    "# Repeat for targets.\n",
    "for col in target:\n",
    "    if col in refs:\n",
    "        refs[str(col)] = refs[str(col)] + target[str(col)]\n",
    "    else:\n",
    "        refs[str(col)] = target[str(col)]\n",
    "\n",
    "# Convert entry-person matrix into an adjacency matrix of persons.\n",
    "refs = refs.T.dot(refs)\n",
    "\n",
    "# # Change diagonal values to zero. That is, a person cannot co-occur with themself.\n",
    "# np.fill_diagonal(refs.values, 0)\n",
    "\n",
    "# Create new 'source' column that corresponds to index (person).\n",
    "refs['source'] = refs.index\n",
    "\n",
    "# # Reshape dataframe to focus on source, target, and weight.\n",
    "# # Rename 'people' column name to 'target'.\n",
    "df_graph = pd.melt(refs, id_vars = ['source'], var_name = 'target', value_name = 'weight') \\\n",
    "    .rename(columns = {'references':'target'}) \\\n",
    "    .query('(source != target) & (weight > 0)') \\\n",
    "\n",
    "# Remove rows with empty source or target.\n",
    "df_graph['source'].replace('', np.nan, inplace=True)\n",
    "df_graph['target'].replace('', np.nan, inplace=True)\n",
    "df_graph.dropna(subset=['source', 'target'], inplace=True)\n",
    "\n",
    "\n",
    "df_graph.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f22239",
   "metadata": {},
   "source": [
    "## Create Graph Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "21e3f010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 32\n",
      "Number of edges: 87\n",
      "Average degree:   5.4375\n",
      "Top 10 nodes by degree:\n",
      "\t('rbt', 28)\n",
      "\t('ellicott-thomas', 22)\n",
      "\t('jackson-andrew', 11)\n",
      "\t('perine-david', 11)\n",
      "\t('webster-daniel', 9)\n",
      "\t('howard-benjamin', 7)\n",
      "\t('gill-x', 6)\n",
      "\t('benton-thomas', 6)\n",
      "\t('williamson-x', 6)\n",
      "\t('taney-anne', 6)\n",
      "Network density: 0.175\n",
      "Is the network connected? False\n",
      "Triadic closure: 0.361\n",
      "\n",
      "Network diameter of the largest component: 3.000\n",
      "CPU times: user 4.16 s, sys: 24.3 ms, total: 4.19 s\n",
      "Wall time: 4.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize graph object.\n",
    "G = nx.from_pandas_edgelist(df_graph, 'source', 'target', 'weight')\n",
    "\n",
    "# Add nodes.\n",
    "nodes = list( dict.fromkeys( df_graph['source'].values.tolist() + df_graph['target'].values.tolist() ))\n",
    "nodes = pd.DataFrame(nodes, columns = ['source'])\n",
    "G.add_nodes_from(nodes)\n",
    "\n",
    "print (nx.info(G))\n",
    "\n",
    "# Set degree attributes.\n",
    "nx.set_node_attributes(G, dict(G.degree(G.nodes())), 'degree')\n",
    "\n",
    "# Sort nodes by degree and print top results.\n",
    "sorted_degree = sorted(dict(G.degree(G.nodes())).items(),\n",
    "                       key = itemgetter(1), reverse = True)\n",
    "\n",
    "print (\"Top 10 nodes by degree:\")\n",
    "for d in sorted_degree[:10]:\n",
    "    print (f'\\t{d}')\n",
    "\n",
    "# Measure network density.\n",
    "density = nx.density(G)\n",
    "print (f\"Network density: {density:.3f}\")\n",
    "\n",
    "# Related to diameter, check if network is connected and, therefore, can have a diameter.\n",
    "print (f\"Is the network connected? {nx.is_connected(G)}\")\n",
    "\n",
    "# Find triadic closure (similar to density).\n",
    "triadic_closure = nx.transitivity(G)\n",
    "print (f\"Triadic closure: {triadic_closure:.3f}\\n\")\n",
    "\n",
    "\n",
    "# Get a list of network components (communities).\n",
    "# Find the largest component.\n",
    "components = nx.connected_components(G)\n",
    "largest_component = max(components, key = len)\n",
    "\n",
    "# Create a subgraph of the largest component and measure its diameter.\n",
    "subgraph = G.subgraph(largest_component)\n",
    "diameter = nx.diameter(subgraph)\n",
    "print (f\"Network diameter of the largest component: {diameter:.3f}\")\n",
    "\n",
    "# Find centrality measures. \n",
    "betweenness_dict = nx.betweenness_centrality(subgraph) # Run betweenness centrality\n",
    "eigenvector_dict = nx.eigenvector_centrality(subgraph) # Run eigenvector centrality\n",
    "degree_cent_dict = nx.degree_centrality(subgraph)\n",
    "\n",
    "# Assign each centrality measure to an attribute.\n",
    "nx.set_node_attributes(subgraph, betweenness_dict, 'betweenness')\n",
    "nx.set_node_attributes(subgraph, eigenvector_dict, 'eigenvector')\n",
    "nx.set_node_attributes(subgraph, degree_cent_dict, 'degree_cent')\n",
    "\n",
    "# Find communities. naive_greedy_modularity_communities\n",
    "communities = community.naive_greedy_modularity_communities(subgraph)\n",
    "# communities = community.k_clique_communities(subgraph, 5)\n",
    "# communities = community.greedy_modularity_communities(subgraph)\n",
    "# communities = community.kernighan_lin_bisection(subgraph)\n",
    "\n",
    "# Create a dictionary that maps nodes to their community.\n",
    "modularity_dict = {}\n",
    "for i, c in enumerate(communities):\n",
    "    for name in c:\n",
    "        modularity_dict[name] = i\n",
    "        \n",
    "# Add modularity information to graph object.\n",
    "nx.set_node_attributes(subgraph, modularity_dict, 'modularity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a82f74d",
   "metadata": {},
   "source": [
    "## Save Graph Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bc204216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.21 ms, sys: 1.4 ms, total: 3.61 ms\n",
      "Wall time: 2.73 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Convert graph object into a dictionary.\n",
    "data = json_graph.node_link_data(subgraph)\n",
    "\n",
    "# # Serialize dictionary with json.\n",
    "# class NPEncoder(JSONEncoder):\n",
    "#     def default(self, obj):\n",
    "#         if isinstance(obj, np.ndarray):\n",
    "#             return obj.tolist()\n",
    "#         return JSONEncoder.default(self, obj)\n",
    "    \n",
    "# data_json = json.dumps(data, cls=NPEncoder)\n",
    "\n",
    "with open(\"/Users/quinn.wi/Documents/\" + \"Github/dsg-mhs/lab_space/projects/taney/coref/data/taney_coRef-network.json\", \n",
    "          \"w\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "#     f.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5db6fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
