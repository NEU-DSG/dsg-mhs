{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "architectural-request",
   "metadata": {},
   "source": [
    "# CoReference Network -- Sedgwick\n",
    "\n",
    "Notes\n",
    "* Notebook currently treats the letter author and recipient as co-references. A strict author-recipient network at the moment (2021-09-27) would only have two nodes (Ellen Richards and Edward Atkinson)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "comprehensive-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json, glob, csv, sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools as iter\n",
    "import xml.etree.ElementTree as ET\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "from networkx.readwrite import json_graph\n",
    "from json import JSONEncoder\n",
    "from operator import itemgetter\n",
    "from collections import Counter\n",
    "    \n",
    "# Declare directory location to shorten filepaths later.\n",
    "abs_dir = \"/Users/quinn.wi/Documents/\"\n",
    "\n",
    "input_directory = \"Data/PSC/Sedgwick/*.xml\"\n",
    "output_file = \"Data/Output/Graphs/Sedgwick/Sedgwick_coRef-network.json\"\n",
    "\n",
    "list_of_files = glob.glob(abs_dir + input_directory)\n",
    "# dataframe = pd.read_csv(abs_dir + 'Data/Output/ParsedXML/Sedgwick_dataframe.txt', sep = '\\t')\n",
    "\n",
    "# dataframe.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9532eb",
   "metadata": {},
   "source": [
    "## Parse XML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffe0ee10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/quinn.wi/Documents/Data/PSC/Sedgwick/CMS1807-04-26-toFrancesSedgwickWatsonFD.xml \n",
      "\n",
      "/Users/quinn.wi/Documents/Data/PSC/Sedgwick/CMS1803-10-06-toPamelaDwightSedgwickF.xml \n",
      "\n",
      "/Users/quinn.wi/Documents/Data/PSC/Sedgwick/CMS1809-01-27-toTheodoreSedgwickIFD.xml \n",
      "\n",
      "/Users/quinn.wi/Documents/Data/PSC/Sedgwick/CMS1807-12-25-toFrancesSedgwickWatsonFD.xml \n",
      "\n",
      "/Users/quinn.wi/Documents/Data/PSC/Sedgwick/CMS1806-01-17-toPamelaDwightSedgwickFD (1).xml \n",
      "\n",
      "/Users/quinn.wi/Documents/Data/PSC/Sedgwick/CMS1805-11-29-toPamelaDwightSedgwickFD.xml \n",
      "\n",
      "/Users/quinn.wi/Documents/Data/PSC/Sedgwick/CMS1807-04-26-toFSWF.xml \n",
      "\n",
      "/Users/quinn.wi/Documents/Data/PSC/Sedgwick/CMS1800-01-12-toTheodoreSedgwickIF.xml \n",
      "\n",
      "/Users/quinn.wi/Documents/Data/PSC/Sedgwick/CMS1805-11-15-toPamelaDwightSedgwickFD (1).xml \n",
      "\n",
      "/Users/quinn.wi/Documents/Data/PSC/Sedgwick/CMS1807-12-28-toFrancesSedgwickWatsonFD.xml \n",
      "\n",
      "/Users/quinn.wi/Documents/Data/PSC/Sedgwick/CMS1807-03-24-toFrancesSedgwickWatsonFD.xml \n",
      "\n",
      "/Users/quinn.wi/Documents/Data/PSC/Sedgwick/CMS1808-11-22-toTheodoreSedgwickIFD.xml \n",
      "\n",
      "/Users/quinn.wi/Documents/Data/PSC/Sedgwick/CMS1806-01-17-toPamelaDwightSedgwickFD.xml \n",
      "\n",
      "CPU times: user 75.5 ms, sys: 15 ms, total: 90.4 ms\n",
      "Wall time: 117 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>data</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>subjects</th>\n",
       "      <th>references</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CMS1819-03-08-toRobertSedgwickIF (1).xml</td>\n",
       "      <td>1819-03-08</td>\n",
       "      <td>Catharine Maria Sedgwick</td>\n",
       "      <td>sedgwick-robert</td>\n",
       "      <td></td>\n",
       "      <td>sedgwick-charles,sedgwick-elizabeth,sedgwick-h...</td>\n",
       "      <td>Albany March 8' 1819 -- I came here my dear Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CMS1816-03-25-toFrancesSedgwickWatsonF.xml</td>\n",
       "      <td>1816-03-25</td>\n",
       "      <td>Catharine Maria Sedgwick</td>\n",
       "      <td>FSW</td>\n",
       "      <td></td>\n",
       "      <td>RSI,banyer-maria,jay-sarah,van vechten-jacob,s...</td>\n",
       "      <td>Albany March 25th 1816 I have just heard of an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMS1813-08-15-toRobertSedgwickIF.xml</td>\n",
       "      <td>1813-08-15</td>\n",
       "      <td>Catharine Maria Sedgwick</td>\n",
       "      <td>RSI</td>\n",
       "      <td></td>\n",
       "      <td>FSW,U,payne-eloise,warner-thomas,warner-france...</td>\n",
       "      <td>Stockbridge August 15th 1813 I recollect very...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         file        data  \\\n",
       "0    CMS1819-03-08-toRobertSedgwickIF (1).xml  1819-03-08   \n",
       "1  CMS1816-03-25-toFrancesSedgwickWatsonF.xml  1816-03-25   \n",
       "2        CMS1813-08-15-toRobertSedgwickIF.xml  1813-08-15   \n",
       "\n",
       "                     source           target subjects  \\\n",
       "0  Catharine Maria Sedgwick  sedgwick-robert            \n",
       "1  Catharine Maria Sedgwick              FSW            \n",
       "2  Catharine Maria Sedgwick              RSI            \n",
       "\n",
       "                                          references  \\\n",
       "0  sedgwick-charles,sedgwick-elizabeth,sedgwick-h...   \n",
       "1  RSI,banyer-maria,jay-sarah,van vechten-jacob,s...   \n",
       "2  FSW,U,payne-eloise,warner-thomas,warner-france...   \n",
       "\n",
       "                                                text  \n",
       "0  Albany March 8' 1819 -- I came here my dear Ro...  \n",
       "1  Albany March 25th 1816 I have just heard of an...  \n",
       "2   Stockbridge August 15th 1813 I recollect very...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "'''\n",
    "Arguments of Functions:\n",
    "\n",
    "    namespace:\n",
    "\n",
    "    ancestor:\n",
    "    \n",
    "    xpath_as_string:\n",
    "    \n",
    "    attrib_val_str:\n",
    "    \n",
    "'''\n",
    "\n",
    "# Read in file and get root of XML tree.\n",
    "def get_root(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    return root\n",
    "\n",
    "\n",
    "# Get namespace of individual file from root element.\n",
    "def get_namespace(root):\n",
    "    namespace = re.match(r\"{(.*)}\", str(root.tag))\n",
    "    ns = {\"ns\":namespace.group(1)}\n",
    "    return ns\n",
    "\n",
    "dataframe = []\n",
    "\n",
    "for file in list_of_files:\n",
    "    \n",
    "    try:\n",
    "        root = get_root(file)\n",
    "        ns = get_namespace(root)\n",
    "\n",
    "        reFile = str(re.search(r'.*/(.*.xml)', str(file)).group(1)) # get filename without path\n",
    "\n",
    "        date = root.find('.//ns:date/[@type=\"creation\"]', ns).get('when') # get date.\n",
    "\n",
    "        source = root.find('.//ns:author', ns).text   # get source/author & target/recipient\n",
    "        target = root.find('.//ns:recipient', ns).text\n",
    "\n",
    "    #     Loops\n",
    "    #     loop to get all references (persRef)\n",
    "        references_l = []\n",
    "        for ref in root.findall('.//ns:persRef', ns):\n",
    "            person = ref.get('ref')\n",
    "            references_l.append(person)\n",
    "        references = ','.join(references_l)\n",
    "\n",
    "    #     loop to get subjects.\n",
    "        subject_l = []\n",
    "        for subject in root.findall('.//ns:subject', ns):\n",
    "            subject_l.append(subject.text)\n",
    "        subjects = ','.join(subject_l)\n",
    "\n",
    "    #     loop to get all text within <div type=\"docbody\">\n",
    "        text_l = []\n",
    "        for txt in root.findall('.//ns:div[@type=\"docbody\"]', ns):\n",
    "            string = ''.join(ET.tostring(txt, encoding='unicode', method='text'))\n",
    "            clean_string = re.sub(r'[\\t\\n\\s]+', ' ', string)\n",
    "            text_l.append(clean_string)\n",
    "        content = ' '.join(text_l)\n",
    "\n",
    "\n",
    "        row = {'file': reFile, 'data': date, 'source': source, 'target':target, \n",
    "               'subjects': subjects, 'references': references, 'text': content}\n",
    "        \n",
    "\n",
    "        dataframe.append(row)\n",
    "        \n",
    "    except:\n",
    "        print (file, '\\n')\n",
    "    \n",
    "dataframe = pd.DataFrame(dataframe)\n",
    "\n",
    "dataframe.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-suggestion",
   "metadata": {},
   "source": [
    "## Reshape Dataframe for Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "quiet-italic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 81.9 ms, sys: 5.84 ms, total: 87.8 ms\n",
      "Wall time: 86.6 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CSWW</td>\n",
       "      <td>EHW</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ESP</td>\n",
       "      <td>EHW</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FSW</td>\n",
       "      <td>EHW</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PDS</td>\n",
       "      <td>EHW</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>TSII</td>\n",
       "      <td>EHW</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77769</th>\n",
       "      <td>sedgwick-susan</td>\n",
       "      <td>woolsey-unknown</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77771</th>\n",
       "      <td>sedgwick-theodore2</td>\n",
       "      <td>woolsey-unknown</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77792</th>\n",
       "      <td>symmes-susannah</td>\n",
       "      <td>woolsey-unknown</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77800</th>\n",
       "      <td>unknown-edward</td>\n",
       "      <td>woolsey-unknown</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77818</th>\n",
       "      <td>warner-thomas</td>\n",
       "      <td>woolsey-unknown</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6008 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   source           target  weight\n",
       "7                    CSWW              EHW       1\n",
       "12                    ESP              EHW       1\n",
       "17                    FSW              EHW       1\n",
       "22                    PDS              EHW       1\n",
       "30                   TSII              EHW       1\n",
       "...                   ...              ...     ...\n",
       "77769      sedgwick-susan  woolsey-unknown       2\n",
       "77771  sedgwick-theodore2  woolsey-unknown       2\n",
       "77792     symmes-susannah  woolsey-unknown       2\n",
       "77800      unknown-edward  woolsey-unknown       2\n",
       "77818       warner-thomas  woolsey-unknown       2\n",
       "\n",
       "[6008 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Split string of people into individuals.\n",
    "dataframe['references'] = dataframe['references'].str.split(r',|;')\n",
    "\n",
    "# Explode list so that each list value becomes a row.\n",
    "refs = dataframe.explode('references')\n",
    "\n",
    "# Create entry-person matrix.\n",
    "refs = pd.crosstab(refs['file'], refs['references'])\n",
    "\n",
    "# # Repeat with correspondence (source + target)\n",
    "# source = pd.crosstab(dataframe['file'], dataframe['source'])\n",
    "# target = pd.crosstab(dataframe['file'], dataframe['target'])\n",
    "\n",
    "# # Join source & target to references as columns\n",
    "# refs = refs.join(source, on = 'file')\n",
    "# refs = refs.join(target, on = 'file')\n",
    "\n",
    "# Convert entry-person matrix into an adjacency matrix of persons.\n",
    "refs = refs.T.dot(refs)\n",
    "\n",
    "# Change diagonal values to zero. That is, a person cannot co-occur with themself.\n",
    "np.fill_diagonal(refs.values, 0)\n",
    "\n",
    "# Create new 'source' column that corresponds to index (person).\n",
    "refs['source'] = refs.index\n",
    "\n",
    "# # Reshape dataframe to focus on source, target, and weight.\n",
    "# # Rename 'people' column name to 'target'.\n",
    "df = pd.melt(refs, id_vars = ['source'], var_name = 'target', value_name = 'weight') \\\n",
    "    .rename(columns = {'people':'target'}) \\\n",
    "    .query('(source != target) & (weight > 0)')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-equilibrium",
   "metadata": {},
   "source": [
    "## Build Graph Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "annual-vector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 280\n",
      "Number of edges: 3004\n",
      "Average degree:  21.4571\n",
      "Top 10 nodes by degree:\n",
      "\t('U', 184)\n",
      "\t('FSW', 150)\n",
      "\t('HDS', 144)\n",
      "\t('CSI', 137)\n",
      "\t('EWI', 127)\n",
      "\t('ESP', 110)\n",
      "\t('RSI', 110)\n",
      "\t('SRS', 106)\n",
      "\t('TSI', 105)\n",
      "\t('PRS', 103)\n",
      "Network density: 0.077\n",
      "Is the network connected? False\n",
      "Network diameter of the largest component: 4.000\n",
      "Triadic closure: 0.335\n",
      "\n",
      "CPU times: user 1.19 s, sys: 10.1 ms, total: 1.2 s\n",
      "Wall time: 1.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize graph object.\n",
    "G = nx.from_pandas_edgelist(df, 'source', 'target', 'weight')\n",
    "\n",
    "# Add nodes.\n",
    "nodes = list( dict.fromkeys( df['source'].values.tolist() + df['target'].values.tolist() ))\n",
    "nodes = pd.DataFrame(nodes, columns = ['source'])\n",
    "G.add_nodes_from(nodes)\n",
    "\n",
    "print (nx.info(G))\n",
    "\n",
    "# Set degree attributes.\n",
    "nx.set_node_attributes(G, dict(G.degree(G.nodes())), 'degree')\n",
    "\n",
    "# Sort nodes by degree and print top results.\n",
    "sorted_degree = sorted(dict(G.degree(G.nodes())).items(),\n",
    "                       key = itemgetter(1), reverse = True)\n",
    "\n",
    "print (\"Top 10 nodes by degree:\")\n",
    "for d in sorted_degree[:10]:\n",
    "    print (f'\\t{d}')\n",
    "\n",
    "\n",
    "# Measure network density.\n",
    "density = nx.density(G)\n",
    "print (f\"Network density: {density:.3f}\")\n",
    "\n",
    "# Related to diameter, check if network is connected and, therefore, can have a diameter.\n",
    "print (f\"Is the network connected? {nx.is_connected(G)}\")\n",
    "\n",
    "# Get a list of network components (communities).\n",
    "# Find the largest component.\n",
    "components = nx.connected_components(G)\n",
    "largest_component = max(components, key = len)\n",
    "\n",
    "# Create a subgraph of the largest component and measure its diameter.\n",
    "subgraph = G.subgraph(largest_component)\n",
    "diameter = nx.diameter(subgraph)\n",
    "print (f\"Network diameter of the largest component: {diameter:.3f}\")\n",
    "\n",
    "# Find triadic closure (similar to density).\n",
    "triadic_closure = nx.transitivity(G)\n",
    "print (f\"Triadic closure: {triadic_closure:.3f}\\n\")\n",
    "\n",
    "# Find centrality measures.\n",
    "betweenness_dict = nx.betweenness_centrality(G) # Run betweenness centrality\n",
    "eigenvector_dict = nx.eigenvector_centrality(G) # Run eigenvector centrality\n",
    "degree_cent_dict = nx.degree_centrality(G)\n",
    "\n",
    "# Assign each centrality measure to an attribute.\n",
    "nx.set_node_attributes(G, betweenness_dict, 'betweenness')\n",
    "nx.set_node_attributes(G, eigenvector_dict, 'eigenvector')\n",
    "nx.set_node_attributes(G, degree_cent_dict, 'degree_cent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-harassment",
   "metadata": {},
   "source": [
    "## Write Graph Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "impossible-concert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.62 ms, sys: 1.8 ms, total: 9.42 ms\n",
      "Wall time: 8.91 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Convert graph object into a dictionary.\n",
    "data = json_graph.node_link_data(G)\n",
    "\n",
    "# # Serialize dictionary with json.\n",
    "# class NPEncoder(JSONEncoder):\n",
    "#     def default(self, obj):\n",
    "#         if isinstance(obj, np.ndarray):\n",
    "#             return obj.tolist()\n",
    "#         return JSONEncoder.default(self, obj)\n",
    "    \n",
    "data_json = json.dumps(data) # , cls=NPEncoder\n",
    "\n",
    "with open(abs_dir + output_file, \"w\") as f:\n",
    "    f.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-beverage",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
