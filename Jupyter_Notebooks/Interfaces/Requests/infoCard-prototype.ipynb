{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "civic-bahamas",
   "metadata": {},
   "source": [
    "# Infocard Prototype\n",
    "\n",
    "This prototype seeks to sketch out possible interfaces that can pull data from names authority databases and supplement the Primary Source Coop.\n",
    "\n",
    "Cheverus\n",
    "\n",
    "Links:\n",
    "\n",
    "SNAC ID -> SNAC Bio, Resources\n",
    "\n",
    "LCNAF ID -> Wikidata Q ID, VIAF\n",
    "https://id.loc.gov/authorities/names/n80001490.html\n",
    "\n",
    "Wikidata -> Image Field (p18), Gender (p21), Occupation (p106), Position held (p39)\n",
    "\n",
    "Wikidata Query Service: https://query.wikidata.org/\n",
    "\n",
    "VIAF -> Works\n",
    "\n",
    "## Linked Open Data\n",
    "\n",
    "* Making documents discoverable\n",
    "* Internal Coop links amplify with Wikidata, etc.?\n",
    "* Reverse link (wikidata, etc. id to xml-id)\n",
    "* List of Coop references\n",
    "\n",
    "Wikidata congressmen during timeframe and find them in dJQA.\n",
    "\n",
    "## Notes\n",
    "\n",
    "* Messy\n",
    "    * There are series of responses required to get some data: LOC -> VIAF -> VIAF.xml\n",
    "    * Pro: LOC gets VIAF; Con: slows down responsivity\n",
    "    \n",
    "* To Do\n",
    "    * Return list of all documents that reference individual persRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "known-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re, warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import dash, dash_table\n",
    "from dash.dependencies import Input, Output, State\n",
    "from dash.exceptions import PreventUpdate\n",
    "import dash_core_components as dcc\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash_html_components as html\n",
    "from jupyter_dash import JupyterDash\n",
    "\n",
    "# Ignore simple warnings.\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "\n",
    "abs_dir = '/Users/quinn.wi/Documents/Data/JQA_pre-2021-04-14/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "proud-shannon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 676 ms, total: 1min 8s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "names_data = pd.read_excel(abs_dir + 'DJQA_Names-List_singleSheet.xlsx', index_col = None) \n",
    "\n",
    "names_data.columns = names_data.columns.str.replace('\\s', '_')\n",
    "\n",
    "# names_data = names_data.query('(Last_Name == \"Randolph\") & (First_Name == \"John\")')\n",
    "\n",
    "names_data = names_data.dropna(subset = ['LC_Name_Authority'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "little-cause",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 331 µs, sys: 17 µs, total: 348 µs\n",
      "Wall time: 345 µs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Last_Name</th>\n",
       "      <th>First_Name</th>\n",
       "      <th>Middle_Name</th>\n",
       "      <th>Maiden_Name</th>\n",
       "      <th>Variant_form_of_name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Suffix</th>\n",
       "      <th>Short-hand_option_for_name</th>\n",
       "      <th>Hyogebated-unique-string-of-characters</th>\n",
       "      <th>Birth_Date</th>\n",
       "      <th>...</th>\n",
       "      <th>notes_for_editorial_team</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Source</th>\n",
       "      <th>URL</th>\n",
       "      <th>LC_Name_Authority</th>\n",
       "      <th>SNAC</th>\n",
       "      <th>Identifier's_initials_and_date</th>\n",
       "      <th>project</th>\n",
       "      <th>Date_First_Mentioned</th>\n",
       "      <th>Second_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>Adams</td>\n",
       "      <td>Louisa</td>\n",
       "      <td>Catherine</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adams-louisa-catherine</td>\n",
       "      <td>1775</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wife of JQA</td>\n",
       "      <td>Adams Biographical Sketches at MHS website</td>\n",
       "      <td>http://www.masshist.org/2012/adams/biographies...</td>\n",
       "      <td>n 86022545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KNB 9/8/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Last_Name First_Name Middle_Name Maiden_Name  Variant_form_of_name Title  \\\n",
       "1419     Adams    Louisa    Catherine     Johnson                   NaN   NaN   \n",
       "\n",
       "     Suffix  Short-hand_option_for_name  \\\n",
       "1419    NaN                         NaN   \n",
       "\n",
       "     Hyogebated-unique-string-of-characters Birth_Date  ...  \\\n",
       "1419                 adams-louisa-catherine       1775  ...   \n",
       "\n",
       "     notes_for_editorial_team        Notes  \\\n",
       "1419                      NaN  wife of JQA   \n",
       "\n",
       "                                          Source  \\\n",
       "1419  Adams Biographical Sketches at MHS website   \n",
       "\n",
       "                                                    URL LC_Name_Authority  \\\n",
       "1419  http://www.masshist.org/2012/adams/biographies...        n 86022545   \n",
       "\n",
       "     SNAC Identifier's_initials_and_date  project Date_First_Mentioned  \\\n",
       "1419  NaN                   KNB 9/8/2018      NaN                  NaN   \n",
       "\n",
       "      Second_URL  \n",
       "1419         NaN  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "names_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-characteristic",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "earlier-reverse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def parseLOC(identifier):\n",
    "#     Lookup URI.\n",
    "    url = f\"https://id.loc.gov/authorities/names/{identifier}.madsxml.xml\"\n",
    "    response = requests.get(url).text\n",
    "    \n",
    "#     Parse XML with namespace from string.\n",
    "    root = ET.fromstring(response)\n",
    "    namespace = re.match(r\"{(.*)}\", str(root.tag))\n",
    "    ns = {\"ns\":namespace.group(1)}\n",
    "    \n",
    "#     Gather information.\n",
    "    namePart = root.find('.//ns:name[@authority=\"naf\"]/ns:namePart', ns).text\n",
    "    birthDeathDate = root.find('.//ns:name[@authority=\"naf\"]/ns:namePart[@type=\"date\"]', ns).text\n",
    "    genderedTerm = root.find('.//ns:genderTerm', ns).text\n",
    "    \n",
    "    return {'id': identifier, \"name\": namePart, \"birthDeath\": birthDeathDate, \"genderedTerm\": genderedTerm}\n",
    "\n",
    "# Read LOC html to get Wikidata & VIAF.\n",
    "def locSoup(identifier):\n",
    "    url = f\"https://id.loc.gov/authorities/names/{identifier}.html\"\n",
    "    response = requests.get(url).text\n",
    "    locSoup = BeautifulSoup(response)\n",
    "\n",
    "    wiki = locSoup.find('span', {'href': re.compile(r'http://www.wikidata.org/entity/.*')})['href']\n",
    "    wiki_id = re.search(r'.*/(Q.*)', wiki).group(1)\n",
    "    \n",
    "    viaf = locSoup.find('a', {'href': re.compile(r'http://viaf.org/viaf/.*')})['href']\n",
    "    \n",
    "    return {'wiki': {'id': wiki_id, 'url': wiki}, \n",
    "            'viaf': {'url': viaf}}\n",
    "    \n",
    "\n",
    "def parseSNAC(identifier):\n",
    "#     Lookup URI & get JSON format.\n",
    "    url = f\"https://snaccooperative.org/download/{identifier}?type=constellation_json\"\n",
    "    response = requests.get(url).json()\n",
    "\n",
    "    namePart = response['nameEntries'][0]['original']\n",
    "    birthDeathDate = re.search('\\d{4}-\\d{4}', namePart).group(0)\n",
    "    \n",
    "    return {'id': identifier, 'name': namePart, 'birthDeath': birthDeathDate}\n",
    "\n",
    "# Use SPARQL to gather Wikidata.\n",
    "# Run this function after locSoup.\n",
    "def sparqlWiki(data):\n",
    "    wiki_key = data['wiki']['id']\n",
    "    url = 'https://query.wikidata.org/sparql'\n",
    "    \n",
    "    \n",
    "    query = f\"\"\"\n",
    "\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "    SELECT ?personLabel ?genderLabel ?birthDate ?deathDate ?occupationLabel\n",
    "\n",
    "    WHERE \n",
    "    {{\n",
    "      wd:{wiki_key} rdfs:label ?person ;\n",
    "                wdt:P18 ?image ;\n",
    "                wdt:P21 ?gender ;\n",
    "                wdt:P569 ?birthDate ;\n",
    "                wdt:P570 ?deathDate ;\n",
    "                wdt:P106 ?occupationLabel .\n",
    "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "      FILTER ( LANG ( ?person ) = 'en' )\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    resp = requests.get(url, params = {'format': 'json', 'query': query}).json()\n",
    "    \n",
    "#     data['wiki']['image'] = resp['results']['bindings'][0]['image']['value']\n",
    "    data['wiki']['genderLabel'] = resp['results']['bindings'][0]['genderLabel']['value']\n",
    "    data['wiki']['birthDate'] = resp['results']['bindings'][0]['birthDate']['value']\n",
    "    data['wiki']['deathDate'] = resp['results']['bindings'][0]['deathDate']['value']\n",
    "    \n",
    "    data['wiki']['occupations'] = []\n",
    "    for o in resp['results']['bindings']:\n",
    "        data['wiki']['occupations'].append(o['occupationLabel']['value'])\n",
    "        \n",
    "        \n",
    "# Gather VIAF data.\n",
    "# Run after locSoup.\n",
    "def parseVIAF(data):\n",
    "    url = data['viaf']['url']\n",
    "    response = requests.get(url).text\n",
    "    soup = BeautifulSoup(response)\n",
    "\n",
    "    viaf_key = soup.find('title').text\n",
    "\n",
    "#     Use VIAF Key to parse VIAF entity.\n",
    "#     Redirects.\n",
    "    url = f\"https://viaf.org/viaf/{viaf_key}/viaf.xml\"\n",
    "    response = requests.get(url).text\n",
    "\n",
    "#     Parse XML with namespace from string.\n",
    "    root = ET.fromstring(response)\n",
    "    namespace = re.match(r\"{(.*)}\", str(root.tag))\n",
    "    ns = {\"ns\":namespace.group(1)}\n",
    "\n",
    "#     Gather information.\n",
    "    titles = root.findall('.//ns:titles', ns)\n",
    "    \n",
    "    data['viaf']['works'] = []\n",
    "    \n",
    "    for w in titles:\n",
    "        work = w.findall('./ns:work', ns)\n",
    "        for t in work:\n",
    "            title = t.find('./ns:title', ns)\n",
    "            \n",
    "            data['viaf']['works'].append(title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-wells",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "extended-appreciation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 294 ms, sys: 30.5 ms, total: 324 ms\n",
      "Wall time: 6.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# locID for Lydia Child\n",
    "locID = \"n80001490\"\n",
    "\n",
    "# snacID\n",
    "snacID = '84910652'\n",
    "\n",
    "data = {}\n",
    "\n",
    "# Get LOC & SNAC data.\n",
    "data['loc'] = parseLOC(locID)\n",
    "data['snac'] = parseSNAC(snacID)\n",
    "\n",
    "# Get Wiki data.\n",
    "data['wiki'] = locSoup(locID)['wiki']\n",
    "sparqlWiki(data)\n",
    "\n",
    "# Get VIAF data.\n",
    "data['viaf'] = locSoup(locID)['viaf']\n",
    "parseVIAF(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-complement",
   "metadata": {},
   "source": [
    "## App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cosmetic-accuracy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n",
      "CPU times: user 63.3 ms, sys: 55.5 ms, total: 119 ms\n",
      "Wall time: 331 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# App configurations\n",
    "app = JupyterDash(__name__, \n",
    "                  external_stylesheets = [dbc.themes.SLATE],\n",
    "                  meta_tags=[\n",
    "                      {\"name\": \"viewport\", \"content\": \"width=device-width, initial-scale=1\"},\n",
    "                  ],\n",
    "                 )\n",
    "\n",
    "app.config.suppress_callback_exceptions = True\n",
    "\n",
    "app.layout = html.Div(\n",
    "    className = 'app-body',\n",
    "    children = [\n",
    "        \n",
    "        html.H1('Info Card'),\n",
    "        html.P('Description'),\n",
    "        \n",
    "        dcc.Dropdown(\n",
    "            id='entityID',\n",
    "             options = [\n",
    "                 {'label': 'Cheverus, Jean-Louis-Aimé- Madeleine Lefebvre de', 'value': 'n92060378'},\n",
    "                 {'label': 'Child, Lydia Maria', 'value': 'n80001490'}\n",
    "             ], \n",
    "             value = 'n92060378'),\n",
    "        \n",
    "        dcc.Checklist(\n",
    "            id = 'selector',\n",
    "            options=[\n",
    "                {'label': 'Library of Congress', 'value': 'LOC'},\n",
    "                {'label': 'SNAC', 'value': 'SNAC'},\n",
    "                {'label': 'WikiData', 'value': 'WIKI'},\n",
    "                {'label': 'VIAF', 'value': 'VIAF'}\n",
    "            ],\n",
    "            value=['LOC', 'WIKI']),\n",
    "        \n",
    "        html.Button('Submit', id='submit-button', n_clicks=0),\n",
    "        \n",
    "        html.Div(className = 'data-information', id = 'data-information'),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "###########################\n",
    "######### Callbacks #######\n",
    "###########################\n",
    "\n",
    "@app.callback(Output('data-information', 'children'), \n",
    "              [Input('submit-button', 'n_clicks'), Input('entityID', 'value'), Input('selector', 'value')])\n",
    "def collect_loc_and_derivatives(submit, entityID, selector):\n",
    "    \n",
    "    #     Only run if the n_click 'id' is triggered by the revision-button-container.\n",
    "    changed_id = [p['prop_id'] for p in dash.callback_context.triggered][0]\n",
    "        \n",
    "    if changed_id != 'submit-button.n_clicks':\n",
    "        raise PreventUpdate\n",
    "        \n",
    "    for s in selector:\n",
    "        if s == \"LOC\":\n",
    "            data['loc'] = parseLOC(entityID)\n",
    "            return html.P(data['loc'])\n",
    "            \n",
    "        elif s == \"WIKI\":\n",
    "            data['wiki'] = locSoup(locID)['wiki']\n",
    "            sparqlWiki(data)\n",
    "            return html.P(data['wiki'])\n",
    "            \n",
    "        \n",
    "#     try:\n",
    "#         print (n_clicks)\n",
    "        \n",
    "#     except:\n",
    "#         return dash.no_update\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(#mode = 'inline', \n",
    "                   debug = True) # mode = 'inline' for JupyterDash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-conjunction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
