{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "civic-bahamas",
   "metadata": {},
   "source": [
    "# Infocard Prototype\n",
    "\n",
    "This prototype seeks to sketch out possible interfaces that can pull data from names authority databases and supplement the Primary Source Coop.\n",
    "\n",
    "Cheverus\n",
    "\n",
    "Links:\n",
    "\n",
    "SNAC ID -> SNAC Bio, Resources\n",
    "\n",
    "LCNAF ID -> Wikidata Q ID, VIAF\n",
    "https://id.loc.gov/authorities/names/n80001490.html\n",
    "\n",
    "Wikidata -> Image Field (p18), Gender (p21), Occupation (p106), Position held (p39)\n",
    "\n",
    "Wikidata Query Service: https://query.wikidata.org/\n",
    "\n",
    "VIAF -> Works\n",
    "\n",
    "## Linked Open Data\n",
    "\n",
    "* Making documents discoverable\n",
    "* Internal Coop links amplify with Wikidata, etc.?\n",
    "* Reverse link (wikidata, etc. id to xml-id)\n",
    "* List of Coop references\n",
    "\n",
    "Wikidata congressmen during timeframe and find them in dJQA.\n",
    "\n",
    "## Notes\n",
    "\n",
    "* Messy\n",
    "    * There are series of responses required to get some data: LOC -> VIAF -> VIAF.xml\n",
    "    * Pro: LOC gets VIAF; Con: slows down responsivity\n",
    "    \n",
    "* To Do\n",
    "    * Return list of all documents that reference individual persRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "known-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re, warnings, pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import dash, dash_table\n",
    "from dash.dependencies import Input, Output, State\n",
    "from dash.exceptions import PreventUpdate\n",
    "import dash_core_components as dcc\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash_html_components as html\n",
    "from jupyter_dash import JupyterDash\n",
    "\n",
    "# Ignore simple warnings.\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "\n",
    "abs_dir = '/Users/quinn.wi/Documents/Data/JQA_pre-2021-04-14/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "proud-shannon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 676 ms, total: 1min 8s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "names_data = pd.read_excel(abs_dir + 'DJQA_Names-List_singleSheet.xlsx', index_col = None) \n",
    "\n",
    "names_data.columns = names_data.columns.str.replace('\\s', '_')\n",
    "\n",
    "# names_data = names_data.query('(Last_Name == \"Randolph\") & (First_Name == \"John\")')\n",
    "\n",
    "names_data = names_data.dropna(subset = ['LC_Name_Authority'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "little-cause",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 331 µs, sys: 17 µs, total: 348 µs\n",
      "Wall time: 345 µs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Last_Name</th>\n",
       "      <th>First_Name</th>\n",
       "      <th>Middle_Name</th>\n",
       "      <th>Maiden_Name</th>\n",
       "      <th>Variant_form_of_name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Suffix</th>\n",
       "      <th>Short-hand_option_for_name</th>\n",
       "      <th>Hyogebated-unique-string-of-characters</th>\n",
       "      <th>Birth_Date</th>\n",
       "      <th>...</th>\n",
       "      <th>notes_for_editorial_team</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Source</th>\n",
       "      <th>URL</th>\n",
       "      <th>LC_Name_Authority</th>\n",
       "      <th>SNAC</th>\n",
       "      <th>Identifier's_initials_and_date</th>\n",
       "      <th>project</th>\n",
       "      <th>Date_First_Mentioned</th>\n",
       "      <th>Second_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>Adams</td>\n",
       "      <td>Louisa</td>\n",
       "      <td>Catherine</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adams-louisa-catherine</td>\n",
       "      <td>1775</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wife of JQA</td>\n",
       "      <td>Adams Biographical Sketches at MHS website</td>\n",
       "      <td>http://www.masshist.org/2012/adams/biographies...</td>\n",
       "      <td>n 86022545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KNB 9/8/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Last_Name First_Name Middle_Name Maiden_Name  Variant_form_of_name Title  \\\n",
       "1419     Adams    Louisa    Catherine     Johnson                   NaN   NaN   \n",
       "\n",
       "     Suffix  Short-hand_option_for_name  \\\n",
       "1419    NaN                         NaN   \n",
       "\n",
       "     Hyogebated-unique-string-of-characters Birth_Date  ...  \\\n",
       "1419                 adams-louisa-catherine       1775  ...   \n",
       "\n",
       "     notes_for_editorial_team        Notes  \\\n",
       "1419                      NaN  wife of JQA   \n",
       "\n",
       "                                          Source  \\\n",
       "1419  Adams Biographical Sketches at MHS website   \n",
       "\n",
       "                                                    URL LC_Name_Authority  \\\n",
       "1419  http://www.masshist.org/2012/adams/biographies...        n 86022545   \n",
       "\n",
       "     SNAC Identifier's_initials_and_date  project Date_First_Mentioned  \\\n",
       "1419  NaN                   KNB 9/8/2018      NaN                  NaN   \n",
       "\n",
       "      Second_URL  \n",
       "1419         NaN  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "names_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-characteristic",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "earlier-reverse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 µs, sys: 24 µs, total: 39 µs\n",
      "Wall time: 19.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def parseLOC(identifier):\n",
    "#     Lookup URI.\n",
    "    url = f\"https://id.loc.gov/authorities/names/{identifier}.madsxml.xml\"\n",
    "    response = requests.get(url).text\n",
    "    \n",
    "#     Parse XML with namespace from string.\n",
    "    root = ET.fromstring(response)\n",
    "    namespace = re.match(r\"{(.*)}\", str(root.tag))\n",
    "    ns = {\"ns\":namespace.group(1)}\n",
    "    \n",
    "#     Gather information.\n",
    "    loc_xpath = {'Name': './/ns:name[@authority=\"naf\"]/ns:namePart', \n",
    "                 'Birth & Death Date': './/ns:name[@authority=\"naf\"]/ns:namePart[@type=\"date\"]', \n",
    "                 'Gendered Term': './/ns:genderTerm'}\n",
    "\n",
    "    loc_data = {}\n",
    "    loc_data['id'] = identifier\n",
    "    \n",
    "    for k, v in loc_xpath.items():\n",
    "        try:\n",
    "            loc_data[k] = root.find(v, ns).text\n",
    "        except:\n",
    "            loc_data[k] = 'NaN'\n",
    "    \n",
    "    return loc_data\n",
    "    \n",
    "\n",
    "# Read LOC html to get Wikidata & VIAF.\n",
    "def locSoup(identifier):\n",
    "    url = f\"https://id.loc.gov/authorities/names/{identifier}.html\"\n",
    "    response = requests.get(url).text\n",
    "    locSoup = BeautifulSoup(response)\n",
    "\n",
    "    wiki = locSoup.find('span', {'href': re.compile(r'http://www.wikidata.org/entity/.*')})['href']\n",
    "    wiki_id = re.search(r'.*/(Q.*)', wiki).group(1)\n",
    "    \n",
    "    viaf = locSoup.find('a', {'href': re.compile(r'http://viaf.org/viaf/.*')})['href']\n",
    "    \n",
    "    return {'wiki': {'id': wiki_id, 'url': wiki}, \n",
    "            'viaf': {'url': viaf}}\n",
    "    \n",
    "\n",
    "def parseSNAC(identifier):\n",
    "#     Lookup URI & get JSON format.\n",
    "    url = f\"https://snaccooperative.org/download/{identifier}?type=constellation_json\"\n",
    "    response = requests.get(url).json()\n",
    "\n",
    "    namePart = response['nameEntries'][0]['original']\n",
    "    birthDeathDate = re.search('\\d{4}-\\d{4}', namePart).group(0)\n",
    "    \n",
    "    return {'SNAC ID': identifier, 'Name': namePart, 'Birth & Death Date': birthDeathDate}\n",
    "\n",
    "# Use SPARQL to gather Wikidata.\n",
    "# Run this function after locSoup.\n",
    "def sparqlWiki(data):\n",
    "    wiki_key = data['wiki']['id']\n",
    "    url = 'https://query.wikidata.org/sparql'\n",
    "    \n",
    "    query = f\"\"\"\n",
    "\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "    SELECT ?personLabel ?genderLabel ?birthDate ?deathDate ?occupationLabel\n",
    "\n",
    "    WHERE \n",
    "    {{\n",
    "      wd:{wiki_key} rdfs:label ?person ;\n",
    "                wdt:P18 ?image ;\n",
    "                wdt:P21 ?gender ;\n",
    "                wdt:P569 ?birthDate ;\n",
    "                wdt:P570 ?deathDate ;\n",
    "                wdt:P106 ?occupationLabel .\n",
    "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "      FILTER ( LANG ( ?person ) = 'en' )\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    resp = requests.get(url, params = {'format': 'json', 'query': query}).json()\n",
    "    \n",
    "#     data['wiki']['image'] = resp['results']['bindings'][0]['image']['value']\n",
    "    data['wiki']['genderLabel'] = resp['results']['bindings'][0]['genderLabel']['value']\n",
    "    data['wiki']['birthDate'] = resp['results']['bindings'][0]['birthDate']['value']\n",
    "    data['wiki']['deathDate'] = resp['results']['bindings'][0]['deathDate']['value']\n",
    "    \n",
    "    data['wiki']['occupations'] = []\n",
    "    for o in resp['results']['bindings']:\n",
    "        data['wiki']['occupations'].append(o['occupationLabel']['value'])\n",
    "        \n",
    "        \n",
    "# Gather VIAF data.\n",
    "# Run after locSoup.\n",
    "def parseVIAF(data):\n",
    "    url = data['viaf']['url']\n",
    "    response = requests.get(url).text\n",
    "    soup = BeautifulSoup(response)\n",
    "\n",
    "    viaf_key = soup.find('title').text\n",
    "\n",
    "#     Use VIAF Key to parse VIAF entity.\n",
    "#     Redirects.\n",
    "    url = f\"https://viaf.org/viaf/{viaf_key}/viaf.xml\"\n",
    "    response = requests.get(url).text\n",
    "\n",
    "#     Parse XML with namespace from string.\n",
    "    root = ET.fromstring(response)\n",
    "    namespace = re.match(r\"{(.*)}\", str(root.tag))\n",
    "    ns = {\"ns\":namespace.group(1)}\n",
    "\n",
    "#     Gather information.\n",
    "    titles = root.findall('.//ns:titles', ns)\n",
    "    \n",
    "    data['viaf']['works'] = []\n",
    "    \n",
    "    for w in titles:\n",
    "        work = w.findall('./ns:work', ns)\n",
    "        for t in work:\n",
    "            title = t.find('./ns:title', ns)\n",
    "            \n",
    "            data['viaf']['works'].append(title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-wells",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "extended-appreciation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 387 ms, sys: 115 ms, total: 502 ms\n",
      "Wall time: 6.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# locID for Lydia Child\n",
    "locID = \"n80001490\"\n",
    "\n",
    "# snacID\n",
    "snacID = '84910652'\n",
    "\n",
    "data = {}\n",
    "\n",
    "# Get LOC & SNAC data.\n",
    "data['loc'] = parseLOC(locID)\n",
    "data['snac'] = parseSNAC(snacID)\n",
    "\n",
    "# Get Wiki data.\n",
    "data['wiki'] = locSoup(locID)['wiki']\n",
    "sparqlWiki(data)\n",
    "\n",
    "# Get VIAF data.\n",
    "data['viaf'] = locSoup(locID)['viaf']\n",
    "parseVIAF(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-complement",
   "metadata": {},
   "source": [
    "## App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cosmetic-accuracy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fcaa88e84f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.7 ms, sys: 3.86 ms, total: 24.6 ms\n",
      "Wall time: 326 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# App configurations\n",
    "app = JupyterDash(__name__, \n",
    "                  external_stylesheets = [dbc.themes.SLATE],\n",
    "                  meta_tags=[\n",
    "                      {\"name\": \"viewport\", \"content\": \"width=device-width, initial-scale=1\"},\n",
    "                  ],\n",
    "                 )\n",
    "\n",
    "# Empty dictionary to store query results.\n",
    "data = {}\n",
    "\n",
    "app.config.suppress_callback_exceptions = True\n",
    "\n",
    "app.layout = html.Div(\n",
    "    className = 'app-body',\n",
    "    children = [\n",
    "        \n",
    "        html.H1('Info Card'),\n",
    "        html.P('Description'),\n",
    "    \n",
    "        dcc.Dropdown(\n",
    "            id='entityID',\n",
    "             options = [\n",
    "                 {'label': 'Cheverus, Jean-Louis-Aimé- Madeleine Lefebvre de', 'value': 'n92060378'},\n",
    "                 {'label': 'Child, Lydia Maria', 'value': 'n80001490'}\n",
    "             ], \n",
    "             value = 'n92060378'),\n",
    "        \n",
    "        dcc.Checklist(\n",
    "            id = 'selector',\n",
    "            options=[\n",
    "                {'label': 'Library of Congress', 'value': 'LOC'},\n",
    "                {'label': 'SNAC', 'value': 'SNAC'},\n",
    "                {'label': 'WikiData (requires LoC input)', 'value': 'WIKI'},\n",
    "                {'label': 'VIAF (requires LoC input)', 'value': 'VIAF'}\n",
    "            ],\n",
    "            value=['LOC']),\n",
    "        \n",
    "        html.Button('Submit', id='submit-button', n_clicks=0),\n",
    "        \n",
    "        html.Div(className = 'data-information', id = 'data-information'),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "###########################\n",
    "######### Callbacks #######\n",
    "###########################\n",
    "\n",
    "@app.callback(Output('data-information', 'children'), \n",
    "              [Input('submit-button', 'n_clicks'), Input('entityID', 'value'), Input('selector', 'value')],\n",
    "              [State('data-information', 'children')])\n",
    "def collect_loc(submit, entityID, selector, children):\n",
    "    \n",
    "#     Only run if the n_click 'id' is triggered by the revision-button-container.\n",
    "    changed_id = [p['prop_id'] for p in dash.callback_context.triggered][0]\n",
    "        \n",
    "    if changed_id != 'submit-button.n_clicks':\n",
    "        raise PreventUpdate\n",
    "        \n",
    "    children = []\n",
    "    \n",
    "    for s in selector:\n",
    "        if s == \"LOC\":\n",
    "            data['loc'] = parseLOC(entityID)\n",
    "\n",
    "            loc_info = []\n",
    "            for k,v in data['loc'].items():\n",
    "                loc_info.append(k + ': ' + v)\n",
    "                loc_info.append(html.Br())\n",
    "            \n",
    "            loc_el = html.Div([\n",
    "                html.H3(\"Library of Congress\"),\n",
    "                html.P(loc_info)\n",
    "            ])\n",
    "\n",
    "    #             Format LOC data for HTML output.\n",
    "            children.append(loc_el)\n",
    "\n",
    "        elif s == \"SNAC\":\n",
    "            data['snac'] = parseSNAC(snacID)\n",
    "            \n",
    "            snac_info = []\n",
    "            for k,v in data['snac'].items():\n",
    "                snac_info.append(k + ': ' + v)\n",
    "                snac_info.append(html.Br())\n",
    "            \n",
    "            snac_el = html.Div([\n",
    "                html.H3(\"SNAC\"),\n",
    "                html.P(snac_info)\n",
    "            ])\n",
    "            \n",
    "            children.append(snac_el)\n",
    "\n",
    "        elif s == \"WIKI\":\n",
    "            data['wiki'] = locSoup(locID)['wiki']\n",
    "#             sparqlWiki(data)\n",
    "            \n",
    "            wiki_info = []\n",
    "            for k,v in data['wiki'].items():\n",
    "                wiki_info.append(k + ': ' + v)\n",
    "                wiki_info.append(html.Br())\n",
    "            \n",
    "            wiki_el = html.Div([\n",
    "                html.H3(\"WikiData\"),\n",
    "                html.P(wiki_info)\n",
    "            ])\n",
    "            \n",
    "            children.append(wiki_el)\n",
    "\n",
    "        elif s == \"VIAF\":\n",
    "            data['viaf'] = locSoup(locID)['viaf']\n",
    "#             parseVIAF(data)\n",
    "            \n",
    "            viaf_info = []\n",
    "            for k,v in data['viaf'].items():\n",
    "                viaf_info.append(k + ': ' + v)\n",
    "                viaf_info.append(html.Br())\n",
    "            \n",
    "            viaf_el = html.Div([\n",
    "                html.H3(\"VIAF\"),\n",
    "                html.P(viaf_info)\n",
    "            ])\n",
    "            \n",
    "            children.append(viaf_el)\n",
    "\n",
    "        else:\n",
    "            print( 'alert/message goes here' )\n",
    "    \n",
    "    return children\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(mode = 'inline', \n",
    "                   debug = True) # mode = 'inline' for JupyterDash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-average",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
