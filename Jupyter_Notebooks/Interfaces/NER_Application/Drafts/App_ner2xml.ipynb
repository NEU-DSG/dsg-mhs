{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application for Reading & Updating XML with NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, re, glob, datetime, csv, sys, os, base64, io, spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lxml import etree\n",
    "\n",
    "import dash, dash_table\n",
    "import dash_core_components as dcc\n",
    "from dash.dependencies import Input, Output, State\n",
    "from dash.exceptions import PreventUpdate\n",
    "import dash_html_components as html\n",
    "from jupyter_dash import JupyterDash\n",
    "\n",
    "# Import spaCy language model.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Ignore simple warnings.\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "\n",
    "# Declare directory location to shorten filepaths later.\n",
    "abs_dir = \"/Users/quinn.wi/Documents/GitHub/dsg-mhs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 1 µs, total: 7 µs\n",
      "Wall time: 9.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\"\n",
    "XML Parsing Function: Get Namespaces\n",
    "\"\"\"\n",
    "def get_namespace(root):\n",
    "    namespace = re.match(r\"{(.*)}\", str(root.tag))\n",
    "    ns = {\"ns\":namespace.group(1)}\n",
    "    return ns\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML Parsing Function: Retrieve XPaths\n",
    "\"\"\"\n",
    "def get_abridged_xpath(child):\n",
    "    if child.getparent().get('{http://www.w3.org/XML/1998/namespace}id') is not None:    \n",
    "        ancestor = child.getparent().tag\n",
    "        xml_id = child.getparent().get('{http://www.w3.org/XML/1998/namespace}id')\n",
    "\n",
    "        abridged_xpath = f'.//ns:body//{ancestor}[@xml:id=\"{xml_id}\"]/{child.tag}'\n",
    "        return abridged_xpath\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML Parsing Function: Convert to String\n",
    "\"\"\"\n",
    "def get_text(elem):\n",
    "    text_list = []\n",
    "    text = ''.join(etree.tostring(elem, encoding='unicode', method='text', with_tail=False))\n",
    "    text_list.append(re.sub(r'\\s+', ' ', text))\n",
    "    return ' '.join(text_list)\n",
    "\n",
    "        \n",
    "\"\"\"\n",
    "XML Parsing Function: Get Encoded Content\n",
    "\"\"\"    \n",
    "def get_encoding(elem):\n",
    "    encoding = etree.tostring(elem, pretty_print = True).decode('utf-8')\n",
    "    encoding = re.sub('\\s+', ' ', encoding) # remove additional whitespace\n",
    "    return encoding\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\"\"\"\n",
    "NER Function\n",
    "\"\"\"\n",
    "# spaCy\n",
    "def get_spacy_entities(text, subset_ner):\n",
    "    sp_entities_l = []\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in subset_ner.keys():\n",
    "            sp_entities_l.append((str(ent), ent.label_))\n",
    "        else:\n",
    "            pass\n",
    "    return sp_entities_l\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML & NER: Retrieve Contents\n",
    "\"\"\"\n",
    "def get_contents(ancestor, xpath_as_string, namespace, subset_ner):\n",
    "    \n",
    "    textContent = get_text(ancestor) # Get plain text.\n",
    "    encodedContent = get_encoding(ancestor) # Get encoded content.\n",
    "    sp_entities_l = get_spacy_entities(textContent, subset_ner) # Get named entities from plain text.\n",
    "\n",
    "    return (sp_entities_l, encodedContent)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML Parsing Function: Write New Encoding with Up-Conversion\n",
    "\"\"\"\n",
    "def make_ner_suggestions(previous_encoding, entity, label, subset_ner, kwic_range, banned_list):\n",
    "#     Regularize spacing & store data as new variable ('converted_encoding').\n",
    "    converted_encoding = re.sub('\\s+', ' ', previous_encoding, re.MULTILINE)\n",
    "    \n",
    "#     Create regex that replaces spaces with underscores if spaces occur within tags.\n",
    "#     This regex treats tags as a single token later.\n",
    "    tag_regex = re.compile('<(.*?)>')\n",
    "\n",
    "#     Accumulate underscores through iteration\n",
    "    for match in re.findall(tag_regex, previous_encoding):\n",
    "        replace_space = re.sub('\\s', '_', match)\n",
    "        converted_encoding = re.sub(match, replace_space, converted_encoding)\n",
    "    \n",
    "#     Up-convert entity (label remains unchanged).\n",
    "    label = subset_ner[label]    \n",
    "    converted_entity = ' '.join(['<w>' + e + '</w>' for e in entity.split(' ')])\n",
    "    \n",
    "#     Up-Converstion\n",
    "#     Tokenize encoding and text, appending <w> tags, and re-join.\n",
    "    converted_encoding = converted_encoding.split(' ')\n",
    "    for idx, item in enumerate(converted_encoding):\n",
    "        item = '<w>' + item + '</w>'\n",
    "        converted_encoding[idx] = item\n",
    "        \n",
    "    converted_encoding = ' '.join(converted_encoding)\n",
    "    \n",
    "#     Find converted entities and kwic-converted entities, even if there's additional encoding within entity.\n",
    "    try:\n",
    "        entity_regex = re.sub('<w>(.*)</w>', '(\\\\1)(.*?</w>)', converted_entity)\n",
    "        entity_match = re.search(entity_regex, converted_encoding)\n",
    "        \n",
    "        ban_decision = []\n",
    "        for i in banned_list:\n",
    "            if i in entity_match.group(0):\n",
    "                ban_decision.append('y')\n",
    "                \n",
    "        if 'y' in ban_decision:\n",
    "            return \"Already Encoded\"\n",
    "        \n",
    "#         If expanded regex is in previous encoding, find & replace it with new encoding.\n",
    "        elif entity_match:\n",
    "            new_encoding = re.sub(f'{entity_match.group(0)}',\n",
    "                                  f'<{label}>{entity_match.group(1)}</{label}>{entity_match.group(2)}',\n",
    "                                  converted_encoding)\n",
    "            \n",
    "#             Remove <w> tags to return to well-formed xml.\n",
    "            new_encoding = re.sub('<[/]?w>', '', new_encoding)\n",
    "#             Remove underscores.\n",
    "            new_encoding = re.sub('_', ' ', new_encoding)\n",
    "\n",
    "            return new_encoding\n",
    "\n",
    "        else:\n",
    "            return 'Error Making NER Suggestions'\n",
    "    \n",
    "#     Up-conversion works well because it 'breaks' if an entity already has been encoded:\n",
    "#     <w>Abel</w> (found entity) does not match <w><persRef_ref=\"abel-mary\">Mrs</w> <w>Abel</persRef></w>\n",
    "#     <persRef> breaks function and avoids duplicating entities.\n",
    "    \n",
    "    except:\n",
    "        return 'Error Occurred with Regex.'\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML: & NER: Create Dataframe of Entities\n",
    "\"\"\"\n",
    "def make_dataframe(child, df, ns, subset_ner, filename, descendant_order):\n",
    "    abridged_xpath = get_abridged_xpath(child)\n",
    "    entities, previous_encoding = get_contents(child, './/ns:.', ns, subset_ner)\n",
    "\n",
    "    df = df.append({\n",
    "        'file':re.sub('.*/(.*.xml)', '\\\\1', filename),\n",
    "        'descendant_order': descendant_order,\n",
    "#         'abridged_xpath':abridged_xpath,\n",
    "        'previous_encoding': previous_encoding,\n",
    "        'entities':entities,\n",
    "    },\n",
    "        ignore_index = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Parse Contents: XML Structure (ouput-data-upload)\n",
    "\"\"\"\n",
    "def parse_contents(contents, filename, date, ner_values):\n",
    "    ner_values = ner_values.split(',')\n",
    "    content_type, content_string = contents.split(',')\n",
    "    decoded = base64.b64decode(content_string).decode('utf-8')\n",
    "    \n",
    "    # Label dictionary.\n",
    "    label_dict = {'PERSON':'persName',\n",
    "                  'LOC':'placeName', # Non-GPE locations, mountain ranges, bodies of water.\n",
    "                  'GPE':'placeName', # Countries, cities, states.\n",
    "                  'FAC':'placeName', # Buildings, airports, highways, bridges, etc.\n",
    "                  'ORG':'orgName', # Companies, agencies, institutions, etc.\n",
    "                  'NORP':'name', # Nationalities or religious or political groups.\n",
    "                  'EVENT':'name', # Named hurricanes, battles, wars, sports events, etc.\n",
    "                  'WORK_OF_ART':'name', # Titles of books, songs, etc.\n",
    "                  'LAW':'name', # Named documents made into laws.\n",
    "                  'DATE':'date' # Absolute or relative dates or periods.\n",
    "                 }\n",
    "    \n",
    "    #### Subset label_dict with input values from Checklist *****\n",
    "    subset_ner = {k: label_dict[k] for k in ner_values}\n",
    "    \n",
    "#     Run XML Parser + NER here.\n",
    "    try:\n",
    "#         Assume that the user uploaded a CSV file\n",
    "        if 'csv' in filename:\n",
    "            df = pd.read_csv(\n",
    "                io.StringIO(decoded)\n",
    "            )\n",
    "            \n",
    "#         Assume that the user uploaded an XML file\n",
    "        elif 'xml' in filename:\n",
    "            xml_file = decoded.encode('utf-8')\n",
    "            \n",
    "            df = pd.DataFrame(columns = ['file', 'abridged_xpath', 'previous_encoding', 'entities'])\n",
    "            \n",
    "            root = etree.fromstring(xml_file)\n",
    "            ns = get_namespace(root)\n",
    "            \n",
    "#             Search through elements for entities.\n",
    "            desc_order = 0\n",
    "            for child in root.findall('.//ns:body//ns:div[@type=\"docbody\"]', ns):\n",
    "            \n",
    "                abridged_xpath = get_abridged_xpath(child)\n",
    "                \n",
    "                for descendant in child:\n",
    "                    desc_order = desc_order + 1\n",
    "                    df = make_dataframe(descendant, df, ns, subset_ner, filename, desc_order)\n",
    "                    df['abridged_xpath'] = abridged_xpath\n",
    "                \n",
    "#             Join data\n",
    "            df = df \\\n",
    "                .explode('entities') \\\n",
    "                .dropna()\n",
    "\n",
    "            df[['entity', 'label']] = pd.DataFrame(df['entities'].tolist(), index = df.index)\n",
    "            \n",
    "            df['new_encoding'] = df \\\n",
    "                .apply(lambda row: make_ner_suggestions(row['previous_encoding'],\n",
    "                                                        row['entity'],\n",
    "                                                        row['label'],\n",
    "                                                        subset_ner, 4, banned_list),\n",
    "                       axis = 1)\n",
    "\n",
    "            \n",
    "            # Add additional columns for user input.\n",
    "            df['accept_changes'] = ''\n",
    "            df['make_hand_edits'] = ''\n",
    "            \n",
    "#             Drop rows if 'new_encoding' value equals 'Already Encoded'.\n",
    "            df = df[df['new_encoding'] != 'Already Encoded']\n",
    "\n",
    "            \n",
    "    except Exception as e:\n",
    "        return html.Div([\n",
    "            f'There was an error processing this file: {e}.'\n",
    "    ])\n",
    "\n",
    "\n",
    "#     Return HTML with outputs.\n",
    "    return filename, date, df\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML & Regex: Up Conversion\n",
    "\n",
    "Function replaces all spaces between beginning and end tags with underscores.\n",
    "Then, function wraps each token (determined by whitespace) with word tags (<w>...</w>)\n",
    "\"\"\"\n",
    "def up_convert_encoding(column):\n",
    "#     Regularize spacing & store data as new variable ('converted_encoding').\n",
    "    converted_encoding = re.sub('\\s+', ' ', column, re.MULTILINE)\n",
    "    \n",
    "#     Create regex that replaces spaces with underscores if spaces occur within tags.\n",
    "#     This regex treats tags as a single token later.\n",
    "    tag_regex = re.compile('<(.*?)>')\n",
    "\n",
    "#     Accumulate underscores through iteration\n",
    "    for match in re.findall(tag_regex, column):\n",
    "        replace_space = re.sub('\\s', '_', match)\n",
    "        converted_encoding = re.sub(match, replace_space, converted_encoding)\n",
    "    \n",
    "#     Up-Converstion\n",
    "#     Tokenize encoding and text, appending <w> tags, and re-join.\n",
    "    converted_encoding = converted_encoding.split(' ')\n",
    "    for idx, item in enumerate(converted_encoding):\n",
    "        item = '<w>' + item + '</w>'\n",
    "        converted_encoding[idx] = item\n",
    "    converted_encoding = ' '.join(converted_encoding)\n",
    "    \n",
    "    return converted_encoding\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML Parsing Function: Suggest New Encoding with Hand Edits\n",
    "\n",
    "Similar to make_ner_suggestions(), this function folds in revision using regular expressions.\n",
    "The outcome is the previous encoding with additional encoded information determined by user input.\n",
    "\n",
    "Expected Columns:\n",
    "    previous_encoding\n",
    "    entities\n",
    "    accept_changes\n",
    "    make_hand_edits\n",
    "\"\"\"\n",
    "def revise_with_hand_edits(label_dict, make_hand_edits, \n",
    "                           label, entity, previous_encoding, new_encoding):\n",
    "    \n",
    "    label = label_dict[label]\n",
    "    \n",
    "#     Up convert PREVIOUS ENCODING: assumes encoder will supply new encoding and attribute with value.\n",
    "    converted_encoding = up_convert_encoding(previous_encoding)\n",
    "    converted_entity = ' '.join(['<w>' + e + '</w>' for e in entity.split(' ')])\n",
    "\n",
    "#     If there is a unique id to add & hand edits...\n",
    "    if make_hand_edits != '':\n",
    "        \n",
    "        entity_regex = re.sub('<w>(.*)</w>', '(\\\\1)(.*?</w>)', converted_entity)\n",
    "        entity_match = re.search(entity_regex, converted_encoding)\n",
    "\n",
    "        identifier_regex = re.search('<(.+)>(.+)</.+>', make_hand_edits, re.VERBOSE|re.DOTALL)\n",
    "\n",
    "        revised_encoding = re.sub(f'{entity_match.group(0)}',\n",
    "                                          f'<{label}>{entity_match.group(1)}</{label}>{entity_match.group(2)}',\n",
    "                                          converted_encoding)\n",
    "\n",
    "\n",
    "        revised_encoding = re.sub(f'<{label}>', f'<{identifier_regex.group(1)}>', revised_encoding)\n",
    "\n",
    "#         Clean up any additional whitespace and remove word tags.\n",
    "        revised_encoding = re.sub('\\s+', ' ', revised_encoding, re.MULTILINE)\n",
    "        revised_encoding = re.sub('<[/]?w>', '', revised_encoding)\n",
    "        \n",
    "        revised_encoding = re.sub('_', ' ', revised_encoding) # Remove any remaining underscores in tags.\n",
    "        revised_encoding = re.sub('“', '\"', revised_encoding) # Change quotation marks to correct unicode.\n",
    "        revised_encoding = re.sub('”', '\"', revised_encoding)\n",
    "        \n",
    "        return revised_encoding\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML & NER: Update/Inherit Accepted Changes\n",
    "Expects a dataframe (from a .csv) with these columns:\n",
    "    file\n",
    "    abridged_xpath\n",
    "    descendant_order\n",
    "    previous_encoding\n",
    "    entities\n",
    "    new_encoding\n",
    "    accept_changes\n",
    "    make_hand_edits\n",
    "\"\"\"\n",
    "def inherit_changes(label_dict, dataframe):\n",
    "    \n",
    "    dataframe = dataframe.fillna('')\n",
    "    for index, row in dataframe.iterrows():\n",
    "        \n",
    "#         If HAND changes are accepted...\n",
    "        if row['make_hand_edits'] != '':\n",
    "        \n",
    "            revised_by_hand = revise_with_hand_edits(label_dict, \n",
    "                                                     row['make_hand_edits'],\n",
    "                                                     row['label'], row['entity'], \n",
    "                                                     row['previous_encoding'], row['new_encoding'])\n",
    "\n",
    "            dataframe.loc[index, 'new_encoding'] = revised_by_hand\n",
    "            \n",
    "            try:\n",
    "                if dataframe.loc[index + 1, 'abridged_xpath'] == row['abridged_xpath'] \\\n",
    "                and dataframe.loc[index + 1, 'descendant_order'] == row['descendant_order']:\n",
    "                    dataframe.loc[index + 1, 'previous_encoding'] = row['new_encoding']\n",
    "                    \n",
    "                else:\n",
    "                    dataframe.loc[index, 'new_encoding'] = revised_by_hand\n",
    "                    \n",
    "                    \n",
    "            except KeyError as e:\n",
    "                dataframe.loc[index, 'new_encoding'] = revised_by_hand\n",
    "        \n",
    "#         If NER suggestions are accepted as-is...\n",
    "        elif row['accept_changes'] == 'y' and row['make_hand_edits'] == '':\n",
    "        \n",
    "            try:\n",
    "                if dataframe.loc[index + 1, 'abridged_xpath'] == row['abridged_xpath'] \\\n",
    "                and dataframe.loc[index + 1, 'descendant_order'] == row['descendant_order']:\n",
    "                    dataframe.loc[index + 1, 'previous_encoding'] = row['new_encoding']\n",
    "                \n",
    "                else:\n",
    "                    dataframe.loc[index, 'new_encoding'] = row['new_encoding']\n",
    "                    \n",
    "            except KeyError as e:\n",
    "                dataframe.loc[index, 'new_encoding'] = row['new_encoding']\n",
    "                \n",
    "#         If changes are rejected...\n",
    "        else:\n",
    "            try:\n",
    "                if dataframe.loc[index + 1, 'abridged_xpath'] == row['abridged_xpath'] \\\n",
    "                and dataframe.loc[index + 1, 'descendant_order'] == row['descendant_order']:\n",
    "                    dataframe.loc[index + 1, 'previous_encoding'] = dataframe.loc[index, 'previous_encoding']\n",
    "                    \n",
    "            except KeyError as e:\n",
    "                dataframe.loc[index, 'new_encoding'] = dataframe.loc[index, 'previous_encoding']\n",
    "\n",
    "#     Subset dataframe with finalized revisions.\n",
    "    dataframe = dataframe.groupby(['abridged_xpath', 'descendant_order']).tail(1)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML & NER: Write New XML File with Accepted Revisions\n",
    "Expects:\n",
    "    XML File with Original Encoding\n",
    "    CSV File with Accepted Changes\n",
    "    Label Dictionary\n",
    "\"\"\"\n",
    "def revise_xml(xml_contents, csv_df):\n",
    "#     Label dictionary.\n",
    "    label_dict = {'PERSON':'persName',\n",
    "                  'LOC':'placeName', # Non-GPE locations, mountain ranges, bodies of water.\n",
    "                  'GPE':'placeName', # Countries, cities, states.\n",
    "                  'FAC':'placeName', # Buildings, airports, highways, bridges, etc.\n",
    "                  'ORG':'orgName', # Companies, agencies, institutions, etc.\n",
    "                  'NORP':'name', # Nationalities or religious or political groups.\n",
    "                  'EVENT':'name', # Named hurricanes, battles, wars, sports events, etc.\n",
    "                  'WORK_OF_ART':'name', # Titles of books, songs, etc.\n",
    "                  'LAW':'name', # Named documents made into laws.\n",
    "                  'DATE':'date' # Absolute or relative dates or periods.\n",
    "                 }\n",
    "    \n",
    "#     First, update data to reflect accepted changes.\n",
    "    new_data = inherit_changes(label_dict, csv_df)\n",
    "    \n",
    "    xml_content_type, xml_content_string = xml_contents.split(',')\n",
    "    xml_decoded = base64.b64decode(xml_content_string).decode('utf-8')\n",
    "    xml_file = xml_decoded.encode('utf-8')\n",
    "    \n",
    "    root = etree.fromstring(xml_file)\n",
    "    ns = get_namespace(root)\n",
    "    \n",
    "    tree_as_string = etree.tostring(root, pretty_print = True).decode('utf-8')\n",
    "    tree_as_string = re.sub('\\s+', ' ', tree_as_string) # remove additional whitespace\n",
    "    \n",
    "#     Write accepted code into XML tree.\n",
    "    for index, row in new_data.iterrows():\n",
    "        original_encoding_as_string = row['previous_encoding']\n",
    "        \n",
    "        # Remove namespaces within tags to ensure regex matches accurately.\n",
    "        original_encoding_as_string = re.sub('^<(.*?)( xmlns.*?)>(.*)$',\n",
    "                                             '<\\\\1>\\\\3',\n",
    "                                             original_encoding_as_string)\n",
    "        \n",
    "        accepted_encoding_as_string = row['new_encoding']\n",
    "        accepted_encoding_as_string = re.sub('<(.*?)( xmlns.*?)>(.*)$',\n",
    "                                             '<\\\\1>\\\\3',\n",
    "                                             accepted_encoding_as_string) # Remove namespaces within tags.\n",
    "        \n",
    "        tree_as_string = re.sub(original_encoding_as_string,\n",
    "                                accepted_encoding_as_string,\n",
    "                                tree_as_string)\n",
    "\n",
    "        \n",
    "#     Check well-formedness (will fail if not well-formed)\n",
    "    doc = etree.fromstring(tree_as_string)\n",
    "    et = etree.ElementTree(doc)\n",
    "    \n",
    "#     Convert to string.\n",
    "    et = etree.tostring(et, encoding='unicode', method='xml', pretty_print = True)\n",
    "    return et"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n",
      "CPU times: user 25.1 ms, sys: 10 ms, total: 35.2 ms\n",
      "Wall time: 50.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# External JavaScript files\n",
    "external_scripts = [\n",
    "    'https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js',\n",
    "    {'src':'https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js'}\n",
    "]\n",
    "\n",
    "\n",
    "app = JupyterDash(__name__, \n",
    "                  external_scripts=external_scripts,)\n",
    "app.config.suppress_callback_exceptions = True\n",
    "\n",
    "\n",
    "# Preset variables.\n",
    "ner_labels = ['PERSON','LOC','GPE','FAC','ORG','NORP','EVENT','WORK_OF_ART','LAW','DATE']\n",
    "\n",
    "# Banned List (list of elements that already encode entities)\n",
    "banned_list = ['persRef', 'persName', 'date']\n",
    "\n",
    "# Layout.\n",
    "app.layout = html.Div([\n",
    "    \n",
    "#     Title\n",
    "    html.Div(\n",
    "        className=\"app-header\",\n",
    "        children = [\n",
    "            html.Div('NER + XML Reader', className = \"app-header--title\")\n",
    "        ]),\n",
    "\n",
    "#     Add or substract labels to list for NER to find. Complete list of NER labels: https://spacy.io/api/annotation\n",
    "    html.H2('Select Entities to Search For'),\n",
    "    dcc.Checklist(\n",
    "        id = 'ner-checklist',\n",
    "        options = [{\n",
    "            'label': i,\n",
    "            'value': i\n",
    "        } for i in ner_labels],\n",
    "        value = ['PERSON', 'LOC', 'GPE']\n",
    "    ),\n",
    "    \n",
    "    \n",
    "#     Upload Data Area.\n",
    "    html.H2('Upload File'),\n",
    "    dcc.Upload(\n",
    "        id = 'upload-data',\n",
    "        children = html.Div([\n",
    "            'Drag and Drop or ', html.A('Select File')\n",
    "        ]),\n",
    "        style={\n",
    "            'width': '95%',\n",
    "            'height': '60px',\n",
    "            'lineHeight': '60px',\n",
    "            'borderWidth': '1px',\n",
    "            'borderStyle': 'dashed',\n",
    "            'borderRadius': '5px',\n",
    "            'textAlign': 'center',\n",
    "            'margin': '10px'\n",
    "        },\n",
    "        multiple=True # Allow multiple files to be uploaded\n",
    "    ),\n",
    "    \n",
    "#     Store uploaded data.\n",
    "    dcc.Store(id = 'data-upload-store'),\n",
    "    \n",
    "#     Display pane for file information.\n",
    "    html.Div(id = 'file-information'),\n",
    "    \n",
    "#     Display pane for data as table.\n",
    "    dash_table.DataTable(id = 'data-table-container',\n",
    "                         row_selectable=\"single\",\n",
    "                         selected_rows = [0],\n",
    "                         editable = True,\n",
    "                         page_size=1,\n",
    "                        ),\n",
    "    \n",
    "#     Display pane for reading data from selected row & revision options.\n",
    "    html.Div(id = 'reading-container'),\n",
    "    html.Div(id = 'revision-radio-container', style = {'display': 'inline-block'}),\n",
    "    html.Div(id = 'revision-text-container', style = {'display': 'inline-block'}),\n",
    "    html.Div(id = 'revision-button-container'),\n",
    "    \n",
    "#     Store revised data.\n",
    "    dcc.Store(id = 'revisions-store'),\n",
    "    \n",
    "#     Div to hold button that will write and download XML file.\n",
    "    html.Div(id = 'write-button-container'),\n",
    "    \n",
    "    html.Div(id = 'download-button-container')\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "# Upload data & create table.\n",
    "@app.callback([Output('file-information', 'children'),\n",
    "               Output('data-upload-store', 'data')],\n",
    "              [Input('upload-data', 'contents'),\n",
    "               Input('ner-checklist', 'value')],\n",
    "              [State('upload-data', 'filename'),\n",
    "               State('upload-data', 'last_modified')])\n",
    "def upload_data(list_of_contents, ner_values, list_of_names, list_of_dates):\n",
    "    if list_of_contents is None:\n",
    "        raise PreventUpdate\n",
    "    \n",
    "#     Parse uploaded contents.\n",
    "    children = [\n",
    "        parse_contents(c, n, d, ner) for c, n, d, ner in\n",
    "        zip(list_of_contents, list_of_names, list_of_dates, ner_values)\n",
    "    ]\n",
    "\n",
    "    filename = children[0][0]\n",
    "    date = children[0][1]\n",
    "    data = children[0][2]\n",
    "    \n",
    "#     Extract file information.\n",
    "    file_information = html.Div([html.P(f'File name: {filename}'),\n",
    "                                 html.P(f'Last Modified: {datetime.datetime.fromtimestamp(date)}')])    \n",
    "    \n",
    "    return file_information, data.to_dict('rows')\n",
    "\n",
    "\n",
    "\n",
    "# Generate table with data from store.\n",
    "@app.callback([Output('data-table-container', 'data'),\n",
    "               Output('data-table-container', 'columns')],\n",
    "              Input('data-upload-store', 'data'))\n",
    "def populate_data_table(data):\n",
    "\n",
    "    df = pd.DataFrame(data)[['file', 'entity', 'label']]\n",
    "    cols = [{'name':i, 'id': i} for i in df.columns]\n",
    "\n",
    "    return df.to_dict('rows'), cols\n",
    "\n",
    "\n",
    "\n",
    "# Create reading pane & revision options once row from table is selected.\n",
    "@app.callback([Output('reading-container', 'children'),\n",
    "               Output('revision-radio-container', 'children'),\n",
    "               Output('revision-text-container', 'children'),\n",
    "               Output('revision-button-container', 'children')],\n",
    "              [Input('data-upload-store', 'data'),\n",
    "               Input('data-table-container', 'selected_rows')])\n",
    "def create_reading_and_revisions_pane(data, selected_rows):\n",
    "    if data is None:\n",
    "        raise PreventUpdate\n",
    "        \n",
    "    reading_df = pd.DataFrame(data).iloc[selected_rows]\n",
    "    \n",
    "#     Access previous and new encoding and convert to the \"code\" html element.\n",
    "    prev_encoding = html.Code(reading_df['previous_encoding'])\n",
    "    new_encoding = html.Code(reading_df['new_encoding'])\n",
    "    \n",
    "    reading_pane = html.Div([\n",
    "        html.H2('Suggested Revisions'),\n",
    "#         Create html table.\n",
    "        html.Table([\n",
    "#             Create headers.\n",
    "            html.Tr([\n",
    "                html.Th('Previous Encoding'),\n",
    "                html.Th('New Encoding')\n",
    "            ]),\n",
    "#             Create row values.\n",
    "            html.Tr([\n",
    "                html.Td(prev_encoding),\n",
    "                html.Td(new_encoding)\n",
    "            ])\n",
    "        ]),\n",
    "        \n",
    "        html.H2('Revisions Options'),\n",
    "    ])\n",
    "    \n",
    "#     reading_pane = html.Div([\n",
    "#         html.P(reading_df['previous_encoding'], id = 'old'),\n",
    "#         html.P(reading_df['new_encoding'], id = 'new'),\n",
    "        \n",
    "#         html.H2('Revisions Options'),\n",
    "#     ])\n",
    "    \n",
    "#     Create accept (as-is) or reject buttons.\n",
    "    revision_radio = dcc.RadioItems(\n",
    "            id = 'radioInput',\n",
    "            options = [\n",
    "                {'label':'Accept Changes As-Is', 'value':'y'},\n",
    "                {'label':'Reject Changes', 'value':''}\n",
    "            ],\n",
    "#             labelStyle = {'display':'inline-block'}\n",
    "        )\n",
    "        \n",
    "#     Create text area for manual changes.\n",
    "    revision_text = dcc.Input(id = 'textInput', type = 'text', \n",
    "                              placeholder = 'Hand type changes here', value = '', debounce = True)\n",
    "        \n",
    "#     Create button for committing changes.\n",
    "    revision_button = html.Button('Confirm Changes?', id = 'confirm-button', n_clicks = 0)\n",
    "    \n",
    "    return reading_pane, revision_radio, revision_text, revision_button\n",
    "    \n",
    "\n",
    "# Once a revisions is accepted, write row with instructions to dataframe.\n",
    "@app.callback(Output('revisions-store', 'data'),\n",
    "              [Input('revision-button-container', 'n_clicks'),\n",
    "               Input('data-upload-store', 'data'),\n",
    "               Input('data-table-container', 'selected_rows'),\n",
    "               Input('revision-radio-container', 'children'), \n",
    "               Input('revision-text-container', 'children')],\n",
    "              State('revisions-store', 'data'))\n",
    "def commit_revisions_to_dataframe(n_clicks, data, selected_rows,\n",
    "                                  radio_children, text_children, revisions):\n",
    "    \n",
    "#     Only run if the n_click 'id' is triggered by the revision-button-container.\n",
    "    changed_id = [p['prop_id'] for p in dash.callback_context.triggered][0]\n",
    "        \n",
    "    if changed_id != 'revision-button-container.n_clicks':\n",
    "        raise PreventUpdate\n",
    "    \n",
    "    revised_row = pd.DataFrame(data).iloc[selected_rows]\n",
    "        \n",
    "#     Check if radio_ and text_children each have a value by seeing if a 'value' key is nested in 'props'.\n",
    "    if 'value' in radio_children['props']:\n",
    "        radio_value = radio_children['props']['value']\n",
    "    else:\n",
    "        radio_value = ''\n",
    "    \n",
    "    if 'value' in text_children['props']:\n",
    "        text_value = text_children['props']['value']\n",
    "    else:\n",
    "        text_value = ''\n",
    "    \n",
    "#     Change individual cell value according to selected row & user-input.\n",
    "    revised_row['make_hand_edits'] = text_value\n",
    "    revised_row['accept_changes'] = radio_value\n",
    "\n",
    "#     Create or update revisions dataframe to store revisions.\n",
    "    if revisions is None:\n",
    "        revisions = pd.DataFrame(revised_row)\n",
    "    else:\n",
    "        revisions = pd.DataFrame(revisions)\n",
    "        revisions = revisions.append(revised_row, ignore_index = True)\n",
    "    \n",
    "    return revisions.to_dict('rows')\n",
    "\n",
    "\n",
    "# After last revision (or whenever one change completed), provide button to commit changes to XML.\n",
    "@app.callback(Output('write-button-container', 'children'),\n",
    "              Input('revisions-store', 'data'))\n",
    "def provide_button_to_download_revisions(data):\n",
    "    if data is None:\n",
    "        raise PreventUpdate\n",
    "    \n",
    "    return html.Button('Finished? Download Revised XML.', id = 'write-xml-button')\n",
    "\n",
    "\n",
    "# Run functions to revise XML and download new document.\n",
    "@app.callback(Output('download-button-container', 'children'),\n",
    "              [Input('write-button-container', 'n_clicks'),\n",
    "               Input('upload-data', 'contents'),\n",
    "               Input('revisions-store', 'data')],\n",
    "              State('upload-data', 'filename'))\n",
    "def provide_download_link(n_clicks, contents, revisions, filename):\n",
    "    write_id = [p['prop_id'] for p in dash.callback_context.triggered][0]\n",
    "        \n",
    "    if write_id != 'write-button-container.n_clicks':\n",
    "        raise PreventUpdate\n",
    "    \n",
    "    xml_contents = contents[0]\n",
    "    revisions = pd.DataFrame(revisions)\n",
    "    \n",
    "    final_revisions = revise_xml(xml_contents, revisions)\n",
    "    \n",
    "    path = f\"revised-{filename[0]}\"\n",
    "    with open(path, \"w\") as file:\n",
    "        file.write(final_revisions)\n",
    "\n",
    "    return f'{filename[0]} downloaded!'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#     app.run_server(mode = 'inline', debug = True) # mode = 'inline' for JupyterDash\n",
    "    app.run_server(debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/38037163/how-to-highlight-the-difference-of-two-texts-with-css\n",
    "\n",
    "# https://webdevtrick.com/javascript-highlight-text/\n",
    "\n",
    "# https://github.com/matthijsgroen/html-diff-js"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
