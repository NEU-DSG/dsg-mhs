{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50a331d0",
   "metadata": {},
   "source": [
    "# nerHelper -- part 2\n",
    "\n",
    "Takes accepted changes (csv) and writes them into xml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d0e366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, re, glob, datetime, csv, sys, os, base64, io, spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# I'm using lxml because it has getparent(), which is critical for accessing multiple xml:id of docs within a single file.\n",
    "from lxml import etree\n",
    "\n",
    "# I'm using ET in get_encoding() only.\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import dash, dash_table\n",
    "import dash_core_components as dcc\n",
    "from dash.dependencies import Input, Output, State\n",
    "from dash.exceptions import PreventUpdate\n",
    "import dash_html_components as html\n",
    "from jupyter_dash import JupyterDash\n",
    "\n",
    "# Import spaCy language model.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Ignore simple warnings.\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "\n",
    "# Declare directory location to shorten filepaths later.\n",
    "abs_dir = \"/Users/quinn.wi/Documents/GitHub/dsg-mhs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7abf1db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 6.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML Parsing Function: Get Namespaces\n",
    "\"\"\"\n",
    "def get_namespace(root):\n",
    "    namespace = re.match(r\"{(.*)}\", str(root.tag))\n",
    "    ns = {\"ns\":namespace.group(1)}\n",
    "    return ns\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML & Regex: Up Conversion\n",
    "\n",
    "Function replaces all spaces between beginning and end tags with underscores.\n",
    "Then, function wraps each token (determined by whitespace) with word tags (<w>...</w>)\n",
    "\"\"\"\n",
    "def up_convert_encoding(column):\n",
    "#     Regularize spacing & store data as new variable ('converted_encoding').\n",
    "    converted_encoding = re.sub('\\s+', ' ', column, re.MULTILINE)\n",
    "    \n",
    "#     Create regex that replaces spaces with underscores if spaces occur within tags.\n",
    "#     This regex treats tags as a single token later.\n",
    "    tag_regex = re.compile('<(.*?)>')\n",
    "\n",
    "#     Accumulate underscores through iteration\n",
    "    for match in re.findall(tag_regex, column):\n",
    "        replace_space = re.sub('\\s', '_', match)\n",
    "        converted_encoding = re.sub(match, replace_space, converted_encoding)\n",
    "    \n",
    "#     Up-Converstion\n",
    "#     Tokenize encoding and text, appending <w> tags, and re-join.\n",
    "    converted_encoding = converted_encoding.split(' ')\n",
    "    for idx, item in enumerate(converted_encoding):\n",
    "        item = '<w>' + item + '</w>'\n",
    "        converted_encoding[idx] = item\n",
    "    converted_encoding = ' '.join(converted_encoding)\n",
    "    \n",
    "    return converted_encoding\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML: Remove word tags and clean up\n",
    "\"\"\"\n",
    "def xml_cleanup(encoding):\n",
    "#     Clean up any additional whitespace and remove word tags.\n",
    "    encoding = re.sub('\\s+', ' ', encoding, re.MULTILINE)\n",
    "    encoding = re.sub('<[/]?w>', '', encoding)\n",
    "\n",
    "    encoding = re.sub('_', ' ', encoding) # Remove any remaining underscores in tags.\n",
    "    encoding = re.sub('“', '\"', encoding) # Change quotation marks to correct unicode.\n",
    "    encoding = re.sub('”', '\"', encoding)\n",
    "    \n",
    "    return encoding\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML Parsing Function: Suggest New Encoding with Hand Edits\n",
    "\n",
    "Similar to make_ner_suggestions(), this function folds in revision using regular expressions.\n",
    "The outcome is the previous encoding with additional encoded information determined by user input.\n",
    "\n",
    "Expected Columns:\n",
    "    previous_encoding\n",
    "    entities\n",
    "    uniq_id\n",
    "\"\"\"\n",
    "def revise_with_uniq_id(entity, uniq_id, converted_encoding, label):\n",
    "    converted_entity = ' '.join(['<w>' + e + '</w>' for e in entity.split(' ')])\n",
    "    \n",
    "    entity_regex = re.sub('<w>(.*)</w>', '(\\\\1)(.*?</w>)', converted_entity)\n",
    "    entity_match = re.search(entity_regex, converted_encoding)\n",
    "\n",
    "    revised_encoding = re.sub(f'{entity_match.group(0)}',\n",
    "                              f'<{label} ref=\"{uniq_id}\" type=\"nerHelper-added\">{entity_match.group(1)}</{label}>{entity_match.group(2)}',\n",
    "                              converted_encoding)\n",
    "        \n",
    "    revised_encoding = xml_cleanup(revised_encoding)\n",
    "        \n",
    "    return revised_encoding\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "XML Parsing Function: Suggest New Encoding with Hand Edits\n",
    "\n",
    "Similar to make_ner_suggestions(), this function folds in revision using regular expressions.\n",
    "The outcome is the previous encoding with additional encoded information determined by user input.\n",
    "\n",
    "Expected Columns:\n",
    "    previous_encoding\n",
    "    entities\n",
    "    uniq_id\n",
    "\"\"\"\n",
    "def revise_without_uniq_id(entity, converted_encoding, label):\n",
    "    converted_entity = ' '.join(['<w>' + e + '</w>' for e in entity.split(' ')])\n",
    "    entity_regex = re.sub('<w>(.*)</w>', '(\\\\1)(.*?</w>)', converted_entity)\n",
    "    entity_match = re.search(entity_regex, converted_encoding)\n",
    "\n",
    "    revised_encoding = re.sub(f'{entity_match.group(0)}',\n",
    "                              f'<{label} type=\"nerHelper-added\">{entity_match.group(1)}</{label}>{entity_match.group(2)}',\n",
    "                              converted_encoding)\n",
    "    \n",
    "    cleaned_revisions = xml_cleanup(revised_encoding)\n",
    "    \n",
    "    return cleaned_revisions\n",
    "\n",
    "\"\"\"\n",
    "XML & Regex: Choose revision function based on presence of uniq_id\n",
    "\"\"\"\n",
    "def choose_revision(entity, uniq_id, converted_encoding, label):\n",
    "    if uniq_id != '':\n",
    "        polished_revisions = revise_with_uniq_id(entity, uniq_id, converted_encoding, label)\n",
    "    elif uniq_id == '':\n",
    "        polished_revisions = revise_without_uniq_id(entity, converted_encoding, label)\n",
    "    else:\n",
    "        print ('breaking at choose_revision()')\n",
    "        \n",
    "    return polished_revisions\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML & NER: Update/Inherit Accepted Changes\n",
    "Expects a dataframe (from a .csv) with these columns:\n",
    "    file\n",
    "    abridged_xpath\n",
    "    descendant_order\n",
    "    previous_encoding\n",
    "    entities\n",
    "    new_encoding\n",
    "    uniq_id\n",
    "\"\"\"\n",
    "def inherit_changes(label_dict, dataframe):\n",
    "    print ('starting inherit_changes()...')\n",
    "    \n",
    "    dataframe = dataframe.fillna('')\n",
    "    for index, row in dataframe.iterrows():\n",
    "        label = label_dict[row['label']]\n",
    "        entity = row['entity']\n",
    "        uniq_id = row['uniq_id']\n",
    "    \n",
    "        if row['accept'] == 'y': # if changes are accepted...\n",
    "            print ('changes accepted...')\n",
    "            \n",
    "#             Check if there's a preceding row.\n",
    "            try:\n",
    "                dataframe.loc[index - 1, 'new_encoding']\n",
    "\n",
    "        #         If the current row is handling same element as the preceding row...\n",
    "                if (row['abridged_xpath'] == dataframe.loc[index - 1, 'abridged_xpath']) \\\n",
    "                and (row['descendant_order']== dataframe.loc[index - 1, 'descendant_order']):\n",
    "                    print ('previous elem is the same')\n",
    "\n",
    "#                     Up convert encoding.\n",
    "                    converted_encoding = up_convert_encoding(dataframe.loc[index - 1, 'new_encoding']) # access preceding row's new_encoding for most recently updated changes to elem.\n",
    "\n",
    "                    polished_revisions = choose_revision(entity, uniq_id, converted_encoding, label)\n",
    "\n",
    "                    dataframe.loc[index, 'new_encoding'] = polished_revisions\n",
    "\n",
    "        #         If the current row is handling a different row...\n",
    "                else:\n",
    "                    print ('previous elem is NOT the same')\n",
    "        #             Up convert current row's \"previous encoding\"\n",
    "                    converted_encoding = up_convert_encoding(row['previous_encoding'])\n",
    "\n",
    "                    polished_revisions = choose_revision(entity, uniq_id, converted_encoding, label)\n",
    "\n",
    "                    dataframe.loc[index, 'new_encoding'] = polished_revisions\n",
    "                    \n",
    "            except KeyError: # there's not a preceding row.\n",
    "                print ('accepting changes, there is no preceding row...')\n",
    "                converted_encoding = up_convert_encoding(row['previous_encoding'])\n",
    "\n",
    "                polished_revisions = choose_revision(entity, uniq_id, converted_encoding, label)\n",
    "\n",
    "                dataframe.loc[index, 'new_encoding'] = polished_revisions\n",
    "\n",
    "#         If changes aren't accepted, \n",
    "        else:\n",
    "            print ('changes not accepted')\n",
    "#             Check for most recent changes.\n",
    "            try:\n",
    "                dataframe.loc[index - 1, 'new_encoding']\n",
    "\n",
    "        #         If the current row is handling same element as the preceding row...\n",
    "                if (row['abridged_xpath'] == dataframe.loc[index - 1, 'abridged_xpath']) \\\n",
    "                and (row['descendant_order']== dataframe.loc[index - 1, 'descendant_order']):\n",
    "                    \n",
    "#                     If the same elem as preceding, adopt preceding's changes (without accepting current row's).\n",
    "                    dataframe.loc[index, 'new_encoding'] = dataframe.loc[index - 1, 'new_encoding']\n",
    "                \n",
    "                else:\n",
    "#                     if row is handling elem for first time and changes rejected, then keep previous_encoding as-is.\n",
    "                    dataframe.loc[index, 'new_encoding'] = dataframe.loc[index, 'previous_encoding']\n",
    "    \n",
    "            except KeyError:\n",
    "#                 If no preceding row and changes rejected, keep previous_encoding as-is.\n",
    "                dataframe.loc[index, 'new_encoding'] = dataframe.loc[index, 'previous_encoding']\n",
    "            \n",
    "#     Subset dataframe with finalized revisions.\n",
    "    dataframe = dataframe.groupby(['abridged_xpath', 'descendant_order']).tail(1)\n",
    "    return dataframe\n",
    "        \n",
    "\n",
    "\"\"\"\n",
    "XML: Write <change> to <revisionDesc>\n",
    "Expects:\n",
    "    XML File (xml_contents in revise_xml())\n",
    "    \n",
    "Output:\n",
    "    Writes changes directly to xml structure (root)\n",
    "\"\"\"\n",
    "def append_change_to_revisionDesc(root, ns):\n",
    "#     Create a change element for revisionDesc.\n",
    "#     If revisionDesc already exists...\n",
    "    if root.find('.//ns:teiHeader/ns:revisionDesc', ns):\n",
    "        revision_desc = root.find('.//ns:teiHeader/ns:revisionDesc', ns)\n",
    "\n",
    "        new_change = etree.SubElement(revision_desc, 'change',\n",
    "                                      when = str(datetime.datetime.now().strftime(\"%Y-%m-%d\")),\n",
    "                                      who = '#nerHelper')\n",
    "                                      \n",
    "        new_change.text = f\"Entities added by NER (spaCy: {spacy.__version__}) application.\"\n",
    "#     Else, create revisionDesc with SubElement, then change.\n",
    "    else:\n",
    "        teiHeader = root.find('.//ns:teiHeader', ns)\n",
    "        revision_desc = etree.SubElement(teiHeader, 'revisionDesc')\n",
    "        new_change = etree.SubElement(revision_desc, 'change',\n",
    "                                      when = str(datetime.datetime.now().strftime(\"%Y-%m-%d\")),\n",
    "                                      who = '#nerHelper')\n",
    "        new_change.text = f\"Entities added by NER (spaCy: {spacy.__version__}) application.\"\n",
    "        \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML: Write <application> to <appInfo>\n",
    "Expects:\n",
    "    XML File (xml_contents in revise_xml())\n",
    "    \n",
    "Output:\n",
    "    Writes changes directly to xml structure (root)\n",
    "\"\"\"\n",
    "def append_app_to_appInfo(root, ns):\n",
    "#     If <appInfo> already exists...\n",
    "    if root.find('.//ns:teiHeader//ns:appInfo', ns):\n",
    "        app_info = root.find('.//ns:teiHeader//ns:appInfo', ns)\n",
    "\n",
    "        ner_app_info = etree.SubElement(app_info, 'application',\n",
    "                                        ident = 'nerHelper',\n",
    "                                        version = \"0.1\")\n",
    "\n",
    "        # Without saving a variable.\n",
    "        etree.SubElement(ner_app_info, 'label').text = 'nerHelper App'\n",
    "        etree.SubElement(ner_app_info, 'p').text = f'Entities added with spaCy-{spacy.__version__}.'\n",
    "        \n",
    "#     If <appInfo> missing BUT <encodingDesc> exists...\n",
    "    elif root.find('.//ns:teiHeader/ns:encodingDesc', ns):\n",
    "        encoding_desc = root.find('.//ns:teiHeader/ns:encodingDesc', ns)\n",
    "        \n",
    "        app_info = etree.SubElement(encoding_desc, 'appInfo')\n",
    "\n",
    "        ner_app_info = etree.SubElement(app_info, 'application',\n",
    "                                ident = 'nerHelper',\n",
    "                                version = \"0.1\")\n",
    "        \n",
    "        etree.SubElement(ner_app_info, 'label').text = 'nerHelper App'\n",
    "        etree.SubElement(ner_app_info, 'p').text = f'Entities added with spaCy-{spacy.__version__}.'\n",
    "        \n",
    "#     Else <appInfo> and <encodingDesc> missing...\n",
    "    else:\n",
    "        teiHeader = root.find('.//ns:teiHeader', ns)\n",
    "        \n",
    "        encoding_desc = etree.SubElement(teiHeader, 'encodingDesc')\n",
    "        \n",
    "        app_info = etree.SubElement(encoding_desc, 'appInfo')\n",
    "\n",
    "        ner_app_info = etree.SubElement(app_info, 'application',\n",
    "                                ident = 'nerHelper',\n",
    "                                version = \"0.1\")\n",
    "        \n",
    "        etree.SubElement(ner_app_info, 'label').text = 'nerHelper App'\n",
    "        etree.SubElement(ner_app_info, 'p').text = f'Entities added with spaCy-{spacy.__version__}.'\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML & NER: Write New XML File with Accepted Revisions\n",
    "Expects:\n",
    "    XML File with Original Encoding\n",
    "    CSV File with Accepted Changes\n",
    "    Label Dictionary\n",
    "\"\"\"\n",
    "def revise_xml(xml_contents, csv_df):\n",
    "    print ('starting revise_xml()...')\n",
    "#     Label dictionary.\n",
    "    label_dict = {'PERSON':'persRef',\n",
    "                  'LOC':'placeName', # Non-GPE locations, mountain ranges, bodies of water.\n",
    "                  'GPE':'placeName', # Countries, cities, states.\n",
    "                  'FAC':'placeName', # Buildings, airports, highways, bridges, etc.\n",
    "                  'ORG':'orgName', # Companies, agencies, institutions, etc.\n",
    "                  'NORP':'name', # Nationalities or religious or political groups.\n",
    "                  'EVENT':'name', # Named hurricanes, battles, wars, sports events, etc.\n",
    "                  'WORK_OF_ART':'name', # Titles of books, songs, etc.\n",
    "                  'LAW':'name', # Named documents made into laws.\n",
    "                  'DATE':'date' # Absolute or relative dates or periods.\n",
    "                 }\n",
    "    \n",
    "#     First, update data to reflect accepted changes.\n",
    "    new_data = inherit_changes(label_dict, csv_df)\n",
    "    print ('\\tchanges inherited...')\n",
    "    \n",
    "    xml_content_type, xml_content_string = xml_contents.split(',')\n",
    "    xml_decoded = base64.b64decode(xml_content_string).decode('utf-8')\n",
    "    xml_file = xml_decoded.encode('utf-8')\n",
    "    print ('\\txml file read...')\n",
    "    \n",
    "#     root = ET.fromstring(xml_file)\n",
    "    root = etree.fromstring(xml_file)\n",
    "    ns = get_namespace(root)\n",
    "    \n",
    "#     Add <change> to <revisionDesc> and add <application> to <appInfo>\n",
    "    append_change_to_revisionDesc(root, ns)\n",
    "    append_app_to_appInfo(root, ns) # Does not need to save as variable; changes written to root.\n",
    "    print ('\\trevisionDesc updated...')\n",
    "    \n",
    "    \n",
    "#     Convert XML structure to string for regex processing.\n",
    "    tree_as_string = ET.fromstring(xml_file)\n",
    "    tree_as_string = ET.tostring(tree_as_string, method = 'xml').decode('utf-8')\n",
    "    tree_as_string = re.sub('\\s+', ' ', tree_as_string)\n",
    "    tree_as_string = re.sub('ns0:', '', tree_as_string)\n",
    "    print ('\\txml tree converted to string...')\n",
    "    \n",
    "    \n",
    "#     Write accepted code into XML tree.\n",
    "    for index, row in new_data.iterrows():\n",
    "        original_encoding_as_string = row['previous_encoding']\n",
    "        \n",
    "        # Remove namespaces within tags to ensure regex matches accurately.\n",
    "        original_encoding_as_string = re.sub('^<(.*?)( xmlns.*?)>(.*)$',\n",
    "                                             '<\\\\1>\\\\3',\n",
    "                                             original_encoding_as_string)\n",
    "        \n",
    "#         Remove namespaces.\n",
    "        original_encoding_as_string = re.sub('ns0:', '', original_encoding_as_string)\n",
    "        \n",
    "        accepted_encoding_as_string = row['new_encoding']\n",
    "        accepted_encoding_as_string = re.sub('<(.*?)( xmlns.*?)>(.*)$',\n",
    "                                             '<\\\\1>\\\\3',\n",
    "                                             accepted_encoding_as_string) # Remove namespaces within tags.\n",
    "        \n",
    "#         Remove namespaces.\n",
    "        accepted_encoding_as_string = re.sub('ns0:', '', accepted_encoding_as_string)\n",
    "        \n",
    "        tree_as_string = re.sub(original_encoding_as_string,\n",
    "                                accepted_encoding_as_string,\n",
    "                                tree_as_string)\n",
    "\n",
    "#         Remove namespaces.\n",
    "        tree_as_string = re.sub('ns0:', '', tree_as_string)\n",
    "    \n",
    "    print ('\\txml doc. revised with accepted changes...')\n",
    "        \n",
    "#     Check well-formedness (will fail if not well-formed)\n",
    "    doc = etree.fromstring(tree_as_string)\n",
    "    et = etree.ElementTree(doc)\n",
    "    \n",
    "#     Convert to string.\n",
    "    et = etree.tostring(et, encoding='unicode', method='xml', pretty_print = True)\n",
    "    print ('\\txml doc. well-formed and converted to string...')\n",
    "    return et\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML: Write Schema Information before Root\n",
    "Input: \n",
    "    - Revised XML document (return variable from revise_xml())\n",
    "    - XML File with Original Encoding\n",
    "\"\"\"\n",
    "def write_schema_information(xml_contents, final_revisions):\n",
    "    print ('starting write_schema_information()...')\n",
    "    xml_content_type, xml_content_string = xml_contents.split(',')\n",
    "    xml_decoded = base64.b64decode(xml_content_string).decode('utf-8')\n",
    "    \n",
    "#     xml_file = xml_decoded.encode('utf-8').decode('utf-8')\n",
    "    xml_file = xml_cleanup(xml_decoded)\n",
    "    xml_file = re.sub('\\s+', ' ', xml_file)\n",
    "    print ('\\txml file cleaned of extra spaces...')\n",
    "    \n",
    "    schema_match = re.search('(<?.*)(<TEI.*)', xml_file)\n",
    "    schema_match = schema_match.group(1)\n",
    "    \n",
    "    completed_document = schema_match + final_revisions\n",
    "    print ('\\txml schema included in revised doc...')\n",
    "\n",
    "    return completed_document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdaa821",
   "metadata": {},
   "source": [
    "## APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32460c8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n",
      "\n",
      "\n",
      "starting revise_xml()...\n",
      "starting inherit_changes()...\n",
      "changes accepted...\n",
      "accepting changes, there is no preceding row...\n",
      "changes accepted...\n",
      "previous elem is NOT the same\n",
      "changes not accepted\n",
      "changes accepted...\n",
      "previous elem is NOT the same\n",
      "changes accepted...\n",
      "previous elem is NOT the same\n",
      "\tchanges inherited...\n",
      "\txml file read...\n",
      "\trevisionDesc updated...\n",
      "\txml tree converted to string...\n",
      "\txml doc. revised with accepted changes...\n",
      "\txml doc. well-formed and converted to string...\n",
      "starting write_schema_information()...\n",
      "\txml file cleaned of extra spaces...\n",
      "\txml schema included in revised doc...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "app = JupyterDash(__name__) \n",
    "#                   external_scripts = external_scripts)\n",
    "\n",
    "app.config.suppress_callback_exceptions = True\n",
    "\n",
    "\n",
    "# Preset variables.\n",
    "ner_labels = ['PERSON','LOC','GPE','FAC','ORG','NORP','EVENT','WORK_OF_ART','LAW','DATE']\n",
    "\n",
    "# Banned List (list of elements that already encode entities)\n",
    "banned_list = ['persRef', 'date']\n",
    "\n",
    "# Layout.\n",
    "app.layout = html.Div([\n",
    "    \n",
    "#     Title\n",
    "    html.Header(\n",
    "        className=\"app-header\",\n",
    "        children = [\n",
    "            html.Div('nerHelper Application', className = \"app-header--title\")\n",
    "        ]),\n",
    "    \n",
    "    \n",
    "#     Upload Data Area.\n",
    "    html.H2('Upload XML File'),\n",
    "    dcc.Upload(\n",
    "        className = 'upload-xml',\n",
    "        id = 'upload-xml',\n",
    "        children = html.Div([\n",
    "            'Drag and Drop or ', html.A('Select File')\n",
    "        ]),\n",
    "        style={\n",
    "            'width': '95%',\n",
    "            'height': '60px',\n",
    "            'lineHeight': '60px',\n",
    "            'borderWidth': '1px',\n",
    "            'borderStyle': 'dashed',\n",
    "            'borderRadius': '5px',\n",
    "            'textAlign': 'center',\n",
    "            'margin': '10px'\n",
    "        },\n",
    "        multiple=False # Allow multiple files to be uploaded\n",
    "    ),\n",
    "    \n",
    "#     Store uploaded data.\n",
    "    dcc.Store(id = 'xml-upload-store'),\n",
    "\n",
    "    \n",
    "#     Display pane for file information.\n",
    "    html.Div(className = 'xml-information', id = 'xml-information'),\n",
    " \n",
    "      \n",
    "#     Upload Data Area.\n",
    "    html.H2('Upload CSV File'),\n",
    "    dcc.Upload(\n",
    "        className = 'upload-csv',\n",
    "        id = 'upload-csv',\n",
    "        children = html.Div([\n",
    "            'Drag and Drop or ', html.A('Select File')\n",
    "        ]),\n",
    "        style={\n",
    "            'width': '95%',\n",
    "            'height': '60px',\n",
    "            'lineHeight': '60px',\n",
    "            'borderWidth': '1px',\n",
    "            'borderStyle': 'dashed',\n",
    "            'borderRadius': '5px',\n",
    "            'textAlign': 'center',\n",
    "            'margin': '10px'\n",
    "        },\n",
    "        multiple=False # Allow multiple files to be uploaded\n",
    "    ),\n",
    "    \n",
    "#     Store uploaded data.\n",
    "    dcc.Store(id = 'csv-upload-store'),\n",
    "    \n",
    "    html.Div(className = 'csv-information', id = 'csv-information'),\n",
    "    \n",
    "      \n",
    "#     Display pane for data as table.\n",
    "    dash_table.DataTable(id = 'data-table-container',\n",
    "                         row_selectable=\"single\",\n",
    "                         selected_rows = [0],\n",
    "                         editable = True,\n",
    "                         page_size=10,\n",
    "                        ),\n",
    "\n",
    "    \n",
    "    html.Div(id = 'download-button-container'),\n",
    "    \n",
    "    html.Div(id = 'file-downloaded-container')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "######### Callbacks ################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "\n",
    "# Upload XML\n",
    "@app.callback([Output('xml-upload-store', 'data'),\n",
    "               Output('xml-information', 'children')],\n",
    "              Input('upload-xml', 'contents'), \n",
    "              State('upload-xml', 'filename'))\n",
    "def upload_xml(contents, filename):\n",
    "    \n",
    "    file_name = html.P(f'File name: {filename}')\n",
    "    \n",
    "    return contents, file_name\n",
    "\n",
    "\n",
    "# Upload CSV & display data table.\n",
    "@app.callback([Output('csv-upload-store', 'data'),\n",
    "               Output('csv-information', 'children')],\n",
    "#               Output('data-table-container', 'data'), Output('data-table-container', 'columns')],\n",
    "              Input('upload-csv', 'contents'),\n",
    "              State('upload-csv', 'filename'))\n",
    "def upload_csv(contents, filename):\n",
    "    \n",
    "    if not contents:\n",
    "        raise PreventUpdate\n",
    "    \n",
    "    file_name = html.P(f'File name: {filename}')\n",
    "    \n",
    "    content_type, content_string = contents.split(',')\n",
    "    decoded = base64.b64decode(content_string)\n",
    "    \n",
    "    try:\n",
    "        if 'csv' in filename:\n",
    "        # Assume that the user uploaded a CSV file\n",
    "            df = pd.read_csv(io.StringIO(decoded.decode('utf-8')))\n",
    "            cols = [{'name':i, 'id': i} for i in df.columns]\n",
    "            \n",
    "        elif 'xls' in filename:\n",
    "        # Assume that the user uploaded an excel file\n",
    "            print ('csv file is excel spreadsheet...')\n",
    "            df = pd.read_excel(io.BytesIO(decoded), index_col = 0)\n",
    "            cols = [{'name':i, 'id': i} for i in df.columns]\n",
    "            \n",
    "        return contents, file_name #, df.to_dict('rows'), cols\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "\n",
    "\n",
    "# Supply download button once both files are uploaded.\n",
    "@app.callback(Output('download-button-container', 'children'),\n",
    "              [Input('xml-upload-store', 'data'),\n",
    "               Input('csv-upload-store', 'data')])\n",
    "def confirm_revision_rewrite(xml_content, csv_content):\n",
    "    \n",
    "    if xml_content and csv_content:\n",
    "        \n",
    "        return html.Button('Download Revised XML.', id = 'download-button', className = 'download-button')\n",
    "\n",
    "\n",
    "# Write and download revised xml.\n",
    "@app.callback(Output('file-downloaded-container', 'children'), \n",
    "              Input('download-button-container', 'n_clicks'),\n",
    "              [State('xml-upload-store', 'data'), \n",
    "               State('csv-upload-store', 'data'), \n",
    "               State('upload-csv', 'filename'),\n",
    "               State('upload-xml', 'filename')])\n",
    "def write_revised_xml(n_clicks, xml_contents, csv_contents, csv_filename, xml_filename):\n",
    "    download_id = [p['prop_id'] for p in dash.callback_context.triggered][0]\n",
    "    \n",
    "    if download_id != 'download-button-container.n_clicks':\n",
    "        raise PreventUpdate\n",
    "    \n",
    "    content_type, content_string = csv_contents.split(',')\n",
    "    decoded = base64.b64decode(content_string)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        if 'csv' in csv_filename:\n",
    "        # Assume that the user uploaded a CSV file\n",
    "            df = pd.read_csv(io.StringIO(decoded.decode('utf-8')))\n",
    "            cols = [{'name':i, 'id': i} for i in df.columns]\n",
    "            \n",
    "        elif 'xls' in csv_filename:\n",
    "        # Assume that the user uploaded an excel file\n",
    "            df = pd.read_excel(io.BytesIO(decoded), index_col = 0)\n",
    "            cols = [{'name':i, 'id': i} for i in df.columns]\n",
    "            \n",
    "        else:\n",
    "            raise PreventUpdate\n",
    "            \n",
    "        revisions = revise_xml(xml_contents, df)\n",
    "\n",
    "        completed_file = write_schema_information(xml_contents, revisions) # not working\n",
    "\n",
    "        path = f\"revised-{xml_filename}\"\n",
    "        with open(path, \"w\") as file:\n",
    "            file.write(completed_file)\n",
    "\n",
    "        return html.P(f'revised-{xml_filename}! Please review the XML document for well-formedness.')\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#     app.run_server(mode = 'inline', debug = True) # mode = 'inline' for JupyterDash\n",
    "    app.run_server(debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0aeba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
