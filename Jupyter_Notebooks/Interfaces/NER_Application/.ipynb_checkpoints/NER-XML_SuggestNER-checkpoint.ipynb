{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations to Sync Up XML & NER\n",
    "\n",
    "These functions will make encoding suggestions and, if accepted, will completely re-write XML documents. Only run after version control or backup.\n",
    "\n",
    "* make_ner_suggestions(): ensure well-formed\n",
    "\n",
    "With suggested encoding as is (\"exploded\" entities), writing will after to be recursive...\n",
    "1. Previous encoding becomes new encoding with first change.\n",
    "2. New encoding (1 change) becomes new encoding with second change.\n",
    "3. New encoding (n changes) becomes new encoding with n+1 change.\n",
    "    \n",
    "The most recent change becomes the working text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, re, glob, datetime, csv, sys, os, base64, io\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lxml import etree\n",
    "\n",
    "# Import spaCy language model.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Ignore simple warnings.\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "\n",
    "# Declare directory location to shorten filepaths later.\n",
    "abs_dir = \"/Users/quinn.wi/Documents/SemanticData/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Functions\n",
    "\n",
    "#### Functions for Suggesting New Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\"\n",
    "XML Parsing Function: Get Namespaces\n",
    "\"\"\"\n",
    "def get_namespace(root):\n",
    "    namespace = re.match(r\"{(.*)}\", str(root.tag))\n",
    "    ns = {\"ns\":namespace.group(1)}\n",
    "    return ns\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML Parsing Function: Retrieve XPaths\n",
    "\"\"\"\n",
    "def get_abridged_xpath(elem):\n",
    "    while elem.getparent().get('{http://www.w3.org/XML/1998/namespace}id') is None:\n",
    "        elem = elem.getparent()\n",
    "        \n",
    "        if elem.getparent().get('{http://www.w3.org/XML/1998/namespace}id') is not None:    \n",
    "            ancestor = elem.getparent().tag\n",
    "            xml_id = elem.getparent().get('{http://www.w3.org/XML/1998/namespace}id')\n",
    "            \n",
    "            abridged_xpath = f'.//ns:body//{ancestor}[@xml:id=\"{xml_id}\"]'\n",
    "            return abridged_xpath\n",
    "        \n",
    "\n",
    "\"\"\"\n",
    "XML Parsing Function: Convert to String\n",
    "\"\"\"\n",
    "def get_text(elem):\n",
    "    text_list = []\n",
    "    text = ''.join(etree.tostring(elem, encoding='unicode', method='text', with_tail=False))\n",
    "    text_list.append(re.sub(r'\\s+', ' ', text))\n",
    "    return ' '.join(text_list)\n",
    "\n",
    "        \n",
    "\"\"\"\n",
    "XML Parsing Function: Get Encoded Content\n",
    "\"\"\"    \n",
    "def get_encoding(elem):\n",
    "    encoding = etree.tostring(elem, pretty_print = True).decode('utf-8')\n",
    "    encoding = re.sub('\\s+', ' ', encoding) # remove additional whitespace\n",
    "    return encoding\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML Parsing Function: Intersperse Entity with Likely TEI Information for Capacious Regex\n",
    "\"\"\"\n",
    "def intersperse(lst, item):\n",
    "    result = [item] * (len(lst) * 2 - 0)\n",
    "    result[0::2] = lst\n",
    "    return result\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML Parsing Function: Write New Encoding\n",
    "\"\"\"\n",
    "def make_ner_suggestions(previous_encoding, entities, label_dict):\n",
    "    previous_encoding = re.sub('\\s+', ' ', previous_encoding, re.MULTILINE)\n",
    "    entity = entities[0]\n",
    "    label = label_dict[entities[1]]\n",
    "    \n",
    "    try:\n",
    "    #     Create regex that anticipates additional encoding anywhere in tag content.\n",
    "    #     Break up entity by character to intersperse possible TEI interruptions.\n",
    "        expanded_entity = [c for c in entity]\n",
    "        expanded_regex = '[' + \"|\".join(['<.*>', '</.*>', '\\s*']) + ']*'\n",
    "\n",
    "    #     Intersperse possible encoding within entity.\n",
    "        expanded_regex =  r''.join(intersperse(expanded_entity, expanded_regex))\n",
    "        match = re.search(expanded_regex, previous_encoding, re.VERBOSE|re.DOTALL)\n",
    "\n",
    "    #     If expanded regex is in previous encoding, find & replace it with new encoding.\n",
    "        if match:\n",
    "            new_encoding = re.sub(f'{match.group(0)}',\n",
    "                                  f'<{label}>{match.group(0)}</{label}>',\n",
    "                                  previous_encoding)\n",
    "\n",
    "            return new_encoding # Check if encoding is well formed?\n",
    "\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    except:\n",
    "        return 'Error Occurred with Regex.'\n",
    "        \n",
    "        \n",
    "\n",
    "\"\"\"\n",
    "NER Function\n",
    "\"\"\"\n",
    "# spaCy\n",
    "def get_spacy_entities(text, label_dict):\n",
    "    sp_entities_l = []\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in label_dict.keys():\n",
    "            sp_entities_l.append((str(ent), ent.label_))\n",
    "        else:\n",
    "            pass\n",
    "    return sp_entities_l\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML & NER: Retrieve Contents\n",
    "\"\"\"\n",
    "def get_contents(ancestor, xpath_as_string, namespace):\n",
    "    \n",
    "    textContent = get_text(ancestor) # Get plain text.\n",
    "    encodedContent = get_encoding(ancestor) # Get encoded content.\n",
    "    sp_entities_l = get_spacy_entities(textContent, label_dict) # Get named entities from plain text.\n",
    "    \n",
    "    return (sp_entities_l, encodedContent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for Re-Writing XML with Accepted Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 7.15 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\"\n",
    "XML Parsing Function: Suggest New Encoding with Hand Edits\n",
    "\n",
    "Similar to make_ner_suggestions(), this function folds in revision using regular expressions.\n",
    "The outcome is the previous encoding with additional encoded information determined by user input.\n",
    "\n",
    "Expected Columns:\n",
    "    previous_encoding\n",
    "    entities\n",
    "    accept_change\n",
    "    make_hand_edits\n",
    "    add_unique_identifier\n",
    "\"\"\"\n",
    "def revise_with_hand_edits(label_dict, row):\n",
    "    previous_encoding = re.sub('\\s+', ' ', row['previous_encoding'], re.MULTILINE)\n",
    "    \n",
    "#     Using re.sub because pandas is converting tuple to string.\n",
    "    entity = re.sub(\"\\(\\'(.*)\\',\\'(.*)'\\)\", '\\g<1>', row['entities'])\n",
    "    label = label_dict[re.sub(\"\\(\\'(.*)\\',\\'(.*)'\\)\", '\\g<2>', row['entities'])]\n",
    "\n",
    "#     Create regex that anticipates additional encoding anywhere in tag content.\n",
    "#     Break up entity by character to intersperse possible TEI interruptions.\n",
    "    expanded_entity = [c for c in entity]\n",
    "    expanded_regex = '[' + \"|\".join(['<.*>', '</.*>', '\\s*']) + ']*'\n",
    "\n",
    "#     Intersperse possible encoding within entity.\n",
    "#     row['previous_encoding'] requires [0] to grab contents.\n",
    "    expanded_regex =  r''.join(intersperse(expanded_entity, expanded_regex))\n",
    "    match = re.search(expanded_regex, previous_encoding, re.VERBOSE|re.DOTALL)\n",
    "    \n",
    "#     If expanded regex is in previous encoding, find & replace it with new encoding.\n",
    "    if match != None:\n",
    "\n",
    "#             If there is a unique id to add & hand edits...\n",
    "        if row['add_unique_identifier'] != '' and row['make_hand_edits'] != '':\n",
    "            identifier_regex = re.search('(<.+)>.+</.+>', row['make_hand_edits'], re.VERBOSE|re.DOTALL)\n",
    "            new_edit = identifier_regex.group(1) + 'xml:id=\"{}\"'.format(row['add_unique_identifier'])\n",
    "\n",
    "            new_match = re.sub(f'{identifier_regex.group(1)}',\n",
    "                               f'{new_edit}',\n",
    "                               row['make_hand_edits'])\n",
    "            \n",
    "            revised_encoding = re.sub(f'{match.group(0)}',\n",
    "                          new_match + ' ',\n",
    "                          row['previous_encoding'])\n",
    "\n",
    "    #             Clean up any additional whitespace.\n",
    "            revised_encoding = re.sub('\\s+', ' ', revised_encoding, re.MULTILINE)\n",
    "\n",
    "            return revised_encoding # Check if encoding is well formed?\n",
    "\n",
    "\n",
    "\n",
    "#             If there are ONLY unique ids to add an NO hand edits...\n",
    "        elif row['add_unique_identifier'] != '' and row['make_hand_edits'] == '':\n",
    "            identifier_regex = re.search('(<.+)>.+</.+>', match.group(0), re.VERBOSE|re.DOTALL)\n",
    "            new_edit = identifier_regex.group(1) + 'xml:id=\"{}\"'.format(row['add_unique_identifier'])\n",
    "\n",
    "            new_match = re.sub(f'{identifier_regex.group(1)}',\n",
    "                               f'{new_edit}',\n",
    "                               identifier_regex.group(0))\n",
    "            \n",
    "            revised_encoding = re.sub(f'{match.group(0)}',\n",
    "                                      new_match + ' ',\n",
    "                                      row['previous_encoding'])\n",
    "\n",
    "    #             Clean up any additional whitespace.\n",
    "            revised_encoding = re.sub('\\s+', ' ', revised_encoding, re.MULTILINE)\n",
    "\n",
    "            return revised_encoding # Check if encoding is well formed?\n",
    "    \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML & NER: Update/Inherit Accepted Changes\n",
    "Expects a dataframe (from a .csv) with these columns:\n",
    "    file\n",
    "    abridged_xpath\n",
    "    previous_encoding\n",
    "    entities\n",
    "    new_encoding\n",
    "    accept_change\n",
    "    make_hand_edits\n",
    "    add_unique_identifier\n",
    "\"\"\"\n",
    "def inherit_changes(label_dict, dataframe):\n",
    "    for index, row in dataframe.iterrows():\n",
    "        \n",
    "#         If HAND changes are accepted...\n",
    "        if row['accept_change'] == 'y' and (row['make_hand_edits'] != '' or row['add_unique_identifier'] != ''):\n",
    "        \n",
    "            revised_by_hand = revise_with_hand_edits(label_dict, row)\n",
    "            dataframe.loc[index, 'new_encoding'] = revised_by_hand\n",
    "            \n",
    "            try:\n",
    "                if dataframe.loc[index + 1, 'abridged_xpath'] == row['abridged_xpath']:\n",
    "                    dataframe.loc[index + 1, 'previous_encoding'] = row['new_encoding']\n",
    "            except KeyError as e:\n",
    "                dataframe.loc[index, 'new_encoding'] = revised_by_hand\n",
    "        \n",
    "#         If NER suggestions are accepted as-is...\n",
    "        elif row['accept_change'] == 'y' and row['make_hand_edits'] == '' and row['add_unique_identifier'] == '':\n",
    "        \n",
    "            try:\n",
    "                if dataframe.loc[index + 1, 'abridged_xpath'] == row['abridged_xpath']:\n",
    "                    dataframe.loc[index + 1, 'previous_encoding'] = row['new_encoding']\n",
    "            except KeyError as e:\n",
    "                dataframe.loc[index, 'new_encoding'] = row['new_encoding']\n",
    "                \n",
    "#         If changes are rejected...\n",
    "        else:\n",
    "            try:\n",
    "                if dataframe.loc[index + 1, 'abridged_xpath'] == row['abridged_xpath']:\n",
    "                    dataframe.loc[index + 1, 'previous_encoding'] = dataframe.loc[index, 'previous_encoding']\n",
    "            except KeyError as e:\n",
    "                dataframe.loc[index, 'new_encoding'] = dataframe.loc[index, 'previous_encoding']\n",
    "\n",
    "        \n",
    "    dataframe = dataframe.groupby('abridged_xpath').tail(1)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "XML & NER: Write New XML File with Accepted Revisions\n",
    "Expects:\n",
    "    XML File with Original Encoding\n",
    "    CSV File with Accepted Changes\n",
    "    Label Dictionary\n",
    "\"\"\"\n",
    "def revise_xml(xml_in, csv_df, label_dict):\n",
    "    with open(input_filename, 'r') as xml_in: #, open(output_filename, 'wb') as xml_out:\n",
    "    #     First, update data to reflect accepted changes.\n",
    "        new_data = inherit_changes(label_dict, csv_df)\n",
    "\n",
    "        tree = etree.parse(xml_in)\n",
    "        root = tree.getroot()\n",
    "        ns = get_namespace(root)\n",
    "\n",
    "        tree_as_string = etree.tostring(tree, pretty_print = True).decode('utf-8')\n",
    "        tree_as_string = re.sub('\\s+', ' ', tree_as_string) # remove additional whitespace\n",
    "\n",
    "    #     Declare accepted encoding to be written.\n",
    "    #     For each entry in file...\n",
    "        for child in root.findall('.//ns:p', ns):\n",
    "\n",
    "    #         Store original encoding.\n",
    "            original_encoding_as_string = get_encoding(child)\n",
    "    #         Removing namespace information embedded in <p> tags.\n",
    "            original_encoding_as_string = re.sub('(<p)(.*1.0\")(>)',\n",
    "                                                 '\\\\1\\\\3',\n",
    "                                                 original_encoding_as_string)\n",
    "\n",
    "    #         Get xpath of child and write full xpath with namespaces using dictionary\n",
    "            abridged_xpath = get_abridged_xpath(child)\n",
    "            for key, value in ns.items():\n",
    "                full_xpath = re.sub('(.*)(xml:)(.*)', '\\\\1{http://www.w3.org/XML/1998/namespace}\\\\3', abridged_xpath)\n",
    "\n",
    "            accepted_encoding_as_string = new_data.loc[new_data['abridged_xpath'] == abridged_xpath, 'new_encoding'][1]\n",
    "            accepted_encoding_as_string = re.sub('(<p)(.*1.0\")(>)',\n",
    "                                                 '\\\\1\\\\3',\n",
    "                                                 accepted_encoding_as_string)\n",
    "\n",
    "\n",
    "            tree_as_string = re.sub(original_encoding_as_string,\n",
    "                                    accepted_encoding_as_string,\n",
    "                                    tree_as_string)\n",
    "\n",
    "    #     Check well-formedness (will fail if not well-formed)\n",
    "        doc = etree.fromstring(tree_as_string)\n",
    "\n",
    "    #     Write changed XML.\n",
    "        et = etree.ElementTree(doc)\n",
    "        return (et)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Suggest NER\n",
    "\n",
    "\n",
    "#### Intakes XML File & Produces CSV with Suggested Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.8 ms, sys: 5.47 ms, total: 64.3 ms\n",
      "Wall time: 64.6 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>abridged_xpath</th>\n",
       "      <th>previous_encoding</th>\n",
       "      <th>entities</th>\n",
       "      <th>new_encoding</th>\n",
       "      <th>accept_change</th>\n",
       "      <th>make_hand_edits</th>\n",
       "      <th>add_unique_identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_xml-before.xml</td>\n",
       "      <td>.//ns:body//{http://www.tei-c.org/ns/1.0}div[@...</td>\n",
       "      <td>&lt;p xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns:m...</td>\n",
       "      <td>(W. A. Schoolfield, PERSON)</td>\n",
       "      <td>&lt;p xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns:m...</td>\n",
       "      <td>y</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_xml-before.xml</td>\n",
       "      <td>.//ns:body//{http://www.tei-c.org/ns/1.0}div[@...</td>\n",
       "      <td>&lt;p xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns:m...</td>\n",
       "      <td>(Abel, PERSON)</td>\n",
       "      <td>&lt;p xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns:m...</td>\n",
       "      <td>y</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file                                     abridged_xpath  \\\n",
       "0  test_xml-before.xml  .//ns:body//{http://www.tei-c.org/ns/1.0}div[@...   \n",
       "0  test_xml-before.xml  .//ns:body//{http://www.tei-c.org/ns/1.0}div[@...   \n",
       "\n",
       "                                   previous_encoding  \\\n",
       "0  <p xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns:m...   \n",
       "0  <p xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns:m...   \n",
       "\n",
       "                      entities  \\\n",
       "0  (W. A. Schoolfield, PERSON)   \n",
       "0               (Abel, PERSON)   \n",
       "\n",
       "                                        new_encoding accept_change  \\\n",
       "0  <p xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns:m...             y   \n",
       "0  <p xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns:m...             y   \n",
       "\n",
       "  make_hand_edits add_unique_identifier  \n",
       "0                                        \n",
       "0                                        "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# filename = abs_dir + 'Data/TestEncoding/EditingData/JQADiaries-v33-1821-12-p001 copy.xml'\n",
    "filename = abs_dir + 'Data/TestEncoding/EditingData/test_xml-before.xml'\n",
    "\n",
    "# Add or substract labels to list for NER to find.\n",
    "# Complete list of NER labels: https://spacy.io/api/annotation\n",
    "label_dict = {\n",
    "    'PERSON':'persName',\n",
    "    'LOC':'placeName', # Non-GPE locations, mountain ranges, bodies of water.\n",
    "#     'GPE':'placeName', # Countries, cities, states.\n",
    "#     'FAC':'placeName', # Buildings, airports, highways, bridges, etc.\n",
    "#     'ORG':'orgName', # Companies, agencies, institutions, etc.\n",
    "#     'NORP':'name', # Nationalities or religious or political groups.\n",
    "#     'EVENT':'name', # Named hurricanes, battles, wars, sports events, etc.\n",
    "#     'WORK_OF_ART':'name', # Titles of books, songs, etc.\n",
    "#     'LAW':'name', # Named documents made into laws.\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns = ['file', 'abridged_xpath', 'previous_encoding', 'entities'])\n",
    "\n",
    "\n",
    "with open(filename, 'r') as xml_file:\n",
    "    tree = etree.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    ns = get_namespace(root)\n",
    "    \n",
    "    for child in root.findall('.//ns:p', ns):\n",
    "        \n",
    "        abridged_xpath = get_abridged_xpath(child)\n",
    "        entities, previous_encoding = get_contents(child, './/ns:p', ns)        \n",
    "        \n",
    "        df = df.append({\n",
    "            'file':re.sub('.*/(.*.xml)', '\\\\1', filename),\n",
    "            'abridged_xpath':abridged_xpath,\n",
    "            'previous_encoding': previous_encoding,\n",
    "            'entities':entities\n",
    "        },\n",
    "            ignore_index = True)\n",
    "        \n",
    "df = df \\\n",
    "    .explode('entities') \\\n",
    "    .dropna()\n",
    "\n",
    "df['new_encoding'] = df \\\n",
    "    .apply(lambda row: make_ner_suggestions(row['previous_encoding'], row['entities'], label_dict), axis = 1)\n",
    "\n",
    "\n",
    "# Add additional columns for user input.\n",
    "df['accept_change'] = 'y'  # Temporarily accepting all changes for testing.\n",
    "df['make_hand_edits'] = ''\n",
    "df['add_unique_identifier'] = ''\n",
    "\n",
    "df.to_csv(abs_dir + 'Data/TestEncoding/EditingData/make_ner_suggestions.csv', sep = ',', index = False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Make NER Edits\n",
    "\n",
    "#### Intakes CSV & Re-Writes XML Chunks According to User Input Added to CSV\n",
    "\n",
    "#### Manually Accept/Reject Changes First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8)\n",
      "CPU times: user 7.93 ms, sys: 1.45 ms, total: 9.37 ms\n",
      "Wall time: 8.27 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>abridged_xpath</th>\n",
       "      <th>previous_encoding</th>\n",
       "      <th>entities</th>\n",
       "      <th>new_encoding</th>\n",
       "      <th>accept_change</th>\n",
       "      <th>make_hand_edits</th>\n",
       "      <th>add_unique_identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_xml-before.xml</td>\n",
       "      <td>.//ns:body//{http://www.tei-c.org/ns/1.0}div[@...</td>\n",
       "      <td>&lt;p xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns:m...</td>\n",
       "      <td>('Abel', 'PERSON')</td>\n",
       "      <td>&lt;p xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns:m...</td>\n",
       "      <td>n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file                                     abridged_xpath  \\\n",
       "1  test_xml-before.xml  .//ns:body//{http://www.tei-c.org/ns/1.0}div[@...   \n",
       "\n",
       "                                   previous_encoding            entities  \\\n",
       "1  <p xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns:m...  ('Abel', 'PERSON')   \n",
       "\n",
       "                                        new_encoding accept_change  \\\n",
       "1  <p xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns:m...             n   \n",
       "\n",
       "  make_hand_edits add_unique_identifier  \n",
       "1                                        "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "csv_df = pd.read_csv(abs_dir + 'Data/TestEncoding/EditingData/make_ner_suggestions.csv', sep = ',').fillna('')\n",
    "\n",
    "csv_df.loc[1, 'accept_change'] = 'n'\n",
    "\n",
    "new_data = inherit_changes(label_dict, csv_df)\n",
    "\n",
    "print (new_data.shape)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditions of Accepting Changes & Encoding Inheritance\n",
    "\n",
    "In inherit_changes(), include decision tree if there are hand edits to be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.2 ms, sys: 880 µs, total: 15.1 ms\n",
      "Wall time: 14.5 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>abridged_xpath</th>\n",
       "      <th>previous_encoding</th>\n",
       "      <th>new_encoding</th>\n",
       "      <th>accept_change</th>\n",
       "      <th>entities</th>\n",
       "      <th>make_hand_edits</th>\n",
       "      <th>add_unique_identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>k</td>\n",
       "      <td>y</td>\n",
       "      <td>('a','LOC')</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>k</td>\n",
       "      <td>l</td>\n",
       "      <td>n</td>\n",
       "      <td>('a','LOC')</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>k</td>\n",
       "      <td>m</td>\n",
       "      <td>y</td>\n",
       "      <td>('a','LOC')</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>('b','LOC')</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>y</td>\n",
       "      <td>('b','LOC')</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>y</td>\n",
       "      <td>('b','LOC')</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>q c</td>\n",
       "      <td>y</td>\n",
       "      <td>('c','LOC')</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>q c</td>\n",
       "      <td>r</td>\n",
       "      <td>y</td>\n",
       "      <td>('c','LOC')</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>d</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>('d','LOC')</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>s</td>\n",
       "      <td>Going to &lt;placeNamexml:id=\"boston-1\"&gt;Boston&lt;/p...</td>\n",
       "      <td>y</td>\n",
       "      <td>('Boston','LOC')</td>\n",
       "      <td>&lt;placeName&gt;Boston&lt;/placeName&gt;</td>\n",
       "      <td>boston-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file  abridged_xpath previous_encoding  \\\n",
       "0     0               1                 a   \n",
       "1     0               1                 k   \n",
       "2     0               1                 k   \n",
       "3     0               2                 b   \n",
       "4     0               2                 b   \n",
       "5     0               2                 o   \n",
       "6     0               3                 c   \n",
       "7     0               3               q c   \n",
       "8     0               4                 d   \n",
       "9     0               4                 s   \n",
       "\n",
       "                                        new_encoding accept_change  \\\n",
       "0                                                  k             y   \n",
       "1                                                  l             n   \n",
       "2                                                  m             y   \n",
       "3                                                  n             n   \n",
       "4                                                  o             y   \n",
       "5                                                  p             y   \n",
       "6                                                q c             y   \n",
       "7                                                  r             y   \n",
       "8                                                  s             y   \n",
       "9  Going to <placeNamexml:id=\"boston-1\">Boston</p...             y   \n",
       "\n",
       "           entities                make_hand_edits add_unique_identifier  \n",
       "0       ('a','LOC')                                                       \n",
       "1       ('a','LOC')                                                       \n",
       "2       ('a','LOC')                                                       \n",
       "3       ('b','LOC')                                                       \n",
       "4       ('b','LOC')                                                       \n",
       "5       ('b','LOC')                                                       \n",
       "6       ('c','LOC')                                                       \n",
       "7       ('c','LOC')                                                       \n",
       "8       ('d','LOC')                                                       \n",
       "9  ('Boston','LOC')  <placeName>Boston</placeName>              boston-1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test = pd.DataFrame({'file':[0,0,0,0,0,0,0,0,0,0],\n",
    "                     'abridged_xpath':[1, 1, 1, 2, 2, 2, 3, 3, 4, 4],\n",
    "                     'previous_encoding':['a', 'a', 'a', 'b', 'b', 'b', 'c', 'c', 'd', 'Going to Boston for the holiday'],\n",
    "                     'new_encoding':['k','l','m','n', 'o','p','q c', 'r', 's', 't'],\n",
    "                     'accept_change':['y','n','y','n','y','y','y','y','y','y'],\n",
    "                     'entities':[\"('a','LOC')\", \"('a','LOC')\", \"('a','LOC')\", \"('b','LOC')\", \"('b','LOC')\", \"('b','LOC')\", \"('c','LOC')\", \"('c','LOC')\", \"('d','LOC')\", \"('Boston','LOC')\"],\n",
    "                     'make_hand_edits':['','','','','','','','','','<placeName>Boston</placeName>'],\n",
    "                     'add_unique_identifier':['','','','','','','','','','boston-1']})\n",
    "\n",
    "\n",
    "inherit_changes(label_dict, test)\n",
    "\n",
    "# Shouldn't accepted changes (no edits) wrap found entity in tags?\n",
    "# No, because inherit_changes does not re-write xml UNLESS there are handmade edits.\n",
    "# Entity to encoding changes happens in make_ner_suggestions(), which is separate from inherit_changes().\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Write Changes to XML\n",
    "\n",
    "Validating XML to schema after changes possible with accessible schema: http://emredjan.github.io/blog/2017/04/08/validating-xml/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.8 ms, sys: 3.33 ms, total: 17.1 ms\n",
      "Wall time: 14.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# App Required Inputs (Drag and Drop Files).\n",
    "input_filename = abs_dir + 'Data/TestEncoding/EditingData/test_xml-before.xml'\n",
    "csv_df = pd.read_csv(abs_dir + 'Data/TestEncoding/EditingData/make_ner_suggestions.csv', sep = ',').fillna('')\n",
    "\n",
    "csv_df.loc[1, 'accept_change'] = 'n' # Making temporary changes to avoid opening/saving file each time.\n",
    "\n",
    "# App Created Output.\n",
    "output_filename = abs_dir + 'Data/TestEncoding/EditingData/test_xml-after.xml'\n",
    "\n",
    "with open(output_filename, 'wb') as xml_out:\n",
    "    revised_tree = revise_xml(input_filename, csv_df, label_dict)\n",
    "    revised_tree.write(xml_out, encoding = 'utf-8', pretty_print = True, xml_declaration = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<?xml-model href=\"http://www.masshist.org/publications/pub/schema/codem-0.2-djqa.rng\" type=\"application/xml\" schematypens=\"http://relaxng.org/ns/structure/1.0\"?>\\n<TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns:mhs=\"http://www.masshist.org/ns/1.0\" xmlns:tei=\"http://www.tei-c.org/ns/1.0\" xml:id=\"v23-1821-05\"> <teiHeader> <fileDesc> <titleStmt> <title>Test Encoding: Copy-Pasted Contents from Three Editions</title> </titleStmt> </fileDesc> </teiHeader> <text> <body> <div type=\"entry\" xml:id=\"jqadiaries-v23-1821-05-01\"> <head>1 May 1821</head> <bibl> <author>JQA</author> <date type=\"creation\" when=\"1821-05-01\"/> <editor role=\"transcription\">Neal Millikan</editor> </bibl> <div type=\"docbody\"> <opener> <dateline>Washington May 22 1832</dateline> <salute>My Dear Sir</salute> </opener> <dateline><hi rend=\"italic\">May 1821.</hi></dateline> <p><date>1 V:15.</date> Tuesday. <persName>W. A. Schoolfield </persName>at the Office. About Slaves. Weekly tea-party resumed. I send you a list of the stockholders of the Bank of the U. States \\xe2\\x80\\x93 foreign and domestic and am very sorry that I <unclear cert=\"low\">suffered</unclear> the promise I made to you in Baltimore to escape from my mind until it was brought back by your letter \\xe2\\x80\\x93 my apology is the pressure of many engagements \\xe2\\x80\\x93 and I hope the delay has not produced inconvenience. I am often accused by <persRef ref=\"richards-robert\">my husband</persRef> of being very deep in my plans and of not always telling at once what they are. <persRef ref=\"abel-mary\">Mrs Abel</persRef> is winning the confidence of people so that we shall have no difficulty in introducing our wares.</p> <closer> <salute>I am dear sir / very truly your / friend </salute> <signed>R. B. Taney</signed> </closer> </div> </div> </body> </text> </TEI>\\n'\n"
     ]
    }
   ],
   "source": [
    "# print (revised_tree.tostring(root, pretty_print=True))\n",
    "\n",
    "print (etree.tostring(revised_tree, encoding='utf8', method='xml', pretty_print = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<?xml-model href=\"http://www.masshist.org/publications/pub/schema/codem-0.2-djqa.rng\" type=\"application/xml\" schematypens=\"http://relaxng.org/ns/structure/1.0\"?>\\n<TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns:mhs=\"http://www.masshist.org/ns/1.0\" xmlns:tei=\"http://www.tei-c.org/ns/1.0\" xml:id=\"v23-1821-05\"> <teiHeader> <fileDesc> <titleStmt> <title>Test Encoding: Copy-Pasted Contents from Three Editions</title> </titleStmt> </fileDesc> </teiHeader> <text> <body> <div type=\"entry\" xml:id=\"jqadiaries-v23-1821-05-01\"> <head>1 May 1821</head> <bibl> <author>JQA</author> <date type=\"creation\" when=\"1821-05-01\"/> <editor role=\"transcription\">Neal Millikan</editor> </bibl> <div type=\"docbody\"> <opener> <dateline>Washington May 22 1832</dateline> <salute>My Dear Sir</salute> </opener> <dateline><hi rend=\"italic\">May 1821.</hi></dateline> <p><date>1 V:15.</date> Tuesday. W. A. Schoolfield at the Office. About Slaves. Weekly tea-party resumed. I send you a list of the stockholders of the Bank of the U. States \\xe2\\x80\\x93 foreign and domestic and am very sorry that I <unclear cert=\"low\">suffered</unclear> the promise I made to you in Baltimore to escape from my mind until it was brought back by your letter \\xe2\\x80\\x93 my apology is the pressure of many engagements \\xe2\\x80\\x93 and I hope the delay has not produced inconvenience. I am often accused by <persRef ref=\"richards-robert\">my husband</persRef> of being very deep in my plans and of not always telling at once what they are. <persRef ref=\"abel-mary\">Mrs Abel</persRef> is winning the confidence of people so that we shall have no difficulty in introducing our wares.</p> <closer> <salute>I am dear sir / very truly your / friend </salute> <signed>R. B. Taney</signed> </closer> </div> </div> </body> </text> </TEI>\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "xml_in = revised_tree\n",
    "\n",
    "\n",
    "\n",
    "new_data = inherit_changes(label_dict, csv_df)\n",
    "\n",
    "root = xml_in.getroot()\n",
    "ns = get_namespace(root)\n",
    "\n",
    "tree_as_string = etree.tostring(tree, pretty_print = True).decode('utf-8')\n",
    "tree_as_string = re.sub('\\s+', ' ', tree_as_string) # remove additional whitespace\n",
    "\n",
    "#     Declare accepted encoding to be written.\n",
    "#     For each entry in file...\n",
    "for child in root.findall('.//ns:p', ns):\n",
    "\n",
    "#         Store original encoding.\n",
    "    original_encoding_as_string = get_encoding(child)\n",
    "#         Removing namespace information embedded in <p> tags.\n",
    "    original_encoding_as_string = re.sub('(<p)(.*1.0\")(>)',\n",
    "                                         '\\\\1\\\\3',\n",
    "                                         original_encoding_as_string)\n",
    "\n",
    "#         Get xpath of child and write full xpath with namespaces using dictionary\n",
    "    abridged_xpath = get_abridged_xpath(child)\n",
    "#     for key, value in ns.items():\n",
    "#         full_xpath = re.sub('(.*)(xml:)(.*)', '\\\\1{http://www.w3.org/XML/1998/namespace}\\\\3', abridged_xpath)\n",
    "\n",
    "    accepted_encoding_as_string = new_data.loc[new_data['abridged_xpath'] == abridged_xpath, 'new_encoding'][1]\n",
    "    accepted_encoding_as_string = re.sub('(<p)(.*1.0\")(>)',\n",
    "                                         '\\\\1\\\\3',\n",
    "                                         accepted_encoding_as_string)\n",
    "\n",
    "\n",
    "    tree_as_string = re.sub(original_encoding_as_string,\n",
    "                            accepted_encoding_as_string,\n",
    "                            tree_as_string)\n",
    "\n",
    "#     Check well-formedness (will fail if not well-formed)\n",
    "doc = etree.fromstring(tree_as_string)\n",
    "\n",
    "#     Write changed XML.\n",
    "et = etree.ElementTree(doc)\n",
    "et = etree.tostring(et, encoding='utf8', method='xml', pretty_print = True)\n",
    "\n",
    "et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
