{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Models Builder\n",
    "\n",
    "This notebook compares the effectiveness of different NER libraries. By comparing each library's results to the names authority list, it should be possible to determine which library works best with the corpus.\n",
    "\n",
    "#### Sources:\n",
    "\n",
    "Christina, \"[Named Entity Recognition in Python with Stanford-NER and Spacy](https://lvngd.com/blog/named-entity-recognition-in-python-with-stanford-ner-and-spacy/),\" <i>LVNGD</i>, Accessed 10/04/2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries.\n",
    "import re, warnings, glob, csv, sys, os, nltk, spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import xml.etree.ElementTree as ET\n",
    "from itertools import chain\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk, Tree\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "\n",
    "# Declare directory location to shorten filepaths later.\n",
    "abs_dir = \"/Users/quinn.wi/Documents/SemanticData/\"\n",
    "\n",
    "\n",
    "# Import StanfordNER model & jar.\n",
    "PATH_TO_MODEL = '/Users/quinn.wi/stanfordNLP/stanford-ner-4.0.0/classifiers/english.all.3class.distsim.crf.ser.gz'\n",
    "\n",
    "PATH_TO_JAR = '/Users/quinn.wi/stanfordNLP/stanford-ner-4.0.0/stanford-ner-4.0.0.jar'\n",
    "\n",
    "# Instantiate StanfordNERTagger.\n",
    "tagger = StanfordNERTagger(model_filename = PATH_TO_MODEL,\n",
    "                           path_to_jar = PATH_TO_JAR,\n",
    "                           encoding = 'utf-8')\n",
    "\n",
    "# Instantiate Custom StanfordNER.\n",
    "custom_model = '/Users/quinn.wi/stanfordNLP/stanford-ner-4.0.0/jqa-ner-model.ser.gz'\n",
    "\n",
    "custom_ner_tagger = StanfordNERTagger(custom_model,\n",
    "                                      path_to_jar = PATH_TO_JAR,\n",
    "                                      encoding='utf8')\n",
    "\n",
    "# Ignore warnings related to deprecated functions.\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "\n",
    "# Import spaCy language model.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Import custom spaCy model.\n",
    "jqa_spacy = spacy.load(abs_dir + 'Output/NER/ner-spacyCustom-training-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse XML for Encoded Entities\n",
    "\n",
    "#### Define functions and declare variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 88 µs, sys: 2 µs, total: 90 µs\n",
      "Wall time: 90.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Declare regex to simplify file paths below\n",
    "regex = re.compile(r'.*/(.*).xml')\n",
    "\n",
    "# Get plain text of every element (designated by first argument).\n",
    "def get_textContent(ancestor, xpath_as_string, namespace):\n",
    "    text_list = []\n",
    "    for elem in ancestor.findall(xpath_as_string, namespace):\n",
    "        text = ''.join(ET.tostring(elem, encoding='unicode', method='text'))\n",
    "\n",
    "#         Add text (cleaned of additional whitespace) to text_list.\n",
    "        text_list.append(re.sub(r'\\s+', ' ', text))\n",
    "\n",
    "#     Return concetanate text list.\n",
    "    return ' '.join(text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose dataset ('all' or 'testing') and run functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.22 s, sys: 10.4 ms, total: 1.23 s\n",
      "Wall time: 1.24 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>entry</th>\n",
       "      <th>text</th>\n",
       "      <th>element</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-02</td>\n",
       "      <td>B 2 VII:15. Heard Lynd at the Capitol. At Bake...</td>\n",
       "      <td>persName</td>\n",
       "      <td>Lynd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-02</td>\n",
       "      <td>B 2 VII:15. Heard Lynd at the Capitol. At Bake...</td>\n",
       "      <td>persName</td>\n",
       "      <td>Baker’s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-02</td>\n",
       "      <td>B 2 VII:15. Heard Lynd at the Capitol. At Bake...</td>\n",
       "      <td>persName</td>\n",
       "      <td>Matthew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-02</td>\n",
       "      <td>B 2 VII:15. Heard Lynd at the Capitol. At Bake...</td>\n",
       "      <td>persName</td>\n",
       "      <td>Garnett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-02</td>\n",
       "      <td>B 2 VII:15. Heard Lynd at the Capitol. At Bake...</td>\n",
       "      <td>persName</td>\n",
       "      <td>G. Hay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   file                      entry  \\\n",
       "0  TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-02   \n",
       "1  TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-02   \n",
       "2  TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-02   \n",
       "3  TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-02   \n",
       "4  TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-02   \n",
       "\n",
       "                                                text   element   entity  \n",
       "0  B 2 VII:15. Heard Lynd at the Capitol. At Bake...  persName     Lynd  \n",
       "1  B 2 VII:15. Heard Lynd at the Capitol. At Bake...  persName  Baker’s  \n",
       "2  B 2 VII:15. Heard Lynd at the Capitol. At Bake...  persName  Matthew  \n",
       "3  B 2 VII:15. Heard Lynd at the Capitol. At Bake...  persName  Garnett  \n",
       "4  B 2 VII:15. Heard Lynd at the Capitol. At Bake...  persName   G. Hay  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Choose either all .xml files or training set by select dataset = 'all' or 'training'.\n",
    "# Selection will parse the XML for different elements.\n",
    "\n",
    "# dataset = 'all'\n",
    "dataset = 'testing'\n",
    "\n",
    "\n",
    "# Conditionally choose directory and create dataframe.\n",
    "if dataset == 'all':\n",
    "    # Gather all .xml files using glob.\n",
    "    list_of_files = glob.glob(abs_dir + \"Data/JQA/*/*.xml\")\n",
    "    \n",
    "    # Create dataframe to store results.\n",
    "    entities = pd.DataFrame(columns = ['file', 'entry', 'text',\n",
    "                                       'element', 'refKey', 'entity'])\n",
    "\n",
    "elif dataset == \"testing\":\n",
    "    # Or, use training document(s) alone.\n",
    "#     list_of_files = glob.glob(abs_dir + \"Data/TestEncoding/TestingData/*.xml\")\n",
    "    list_of_files = glob.glob(abs_dir + \"Data/TestEncoding/TestingData/*.xml\")\n",
    "    \n",
    "    # Create dataframe to store results.\n",
    "    entities = pd.DataFrame(columns = ['file', 'entry', 'text',\n",
    "                                       'element', 'entity'])\n",
    "\n",
    "else:\n",
    "    print ('Dataset not found.')\n",
    "\n",
    "    \n",
    "# Loop through each file within a directory.\n",
    "for file in list_of_files:\n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "    namespace = re.match(r\"{(.*)}\", str(root.tag))\n",
    "    ns = {\"ns\":namespace.group(1)}\n",
    "    reFile = str(regex.match(file).group(1))\n",
    "    \n",
    "    for eachDoc in root.findall('.//ns:div/[@type=\"entry\"]', ns):\n",
    "        entry = eachDoc.get('{http://www.w3.org/XML/1998/namespace}id')\n",
    "        text = get_textContent(eachDoc, './ns:div/[@type=\"docbody\"]/ns:p', ns)\n",
    "        \n",
    "        if dataset == 'all':\n",
    "            for elem in eachDoc.findall('.//ns:p//ns:persRef/[@ref]', ns):\n",
    "                name = elem.text\n",
    "                try:\n",
    "                    entity = re.sub(r'\\s+', ' ', name)\n",
    "                except TypeError:\n",
    "                    entity = name\n",
    "\n",
    "                entities = entities.append({'file':reFile,\n",
    "                                'entry':entry,\n",
    "                                'text':text,\n",
    "                                'element':re.sub(r'.*}(.*)', '\\\\1', elem.tag),\n",
    "                                'refKey':elem.get('ref'),\n",
    "                                'entity':entity},\n",
    "                               ignore_index = True)\n",
    "\n",
    "        elif dataset == 'testing':\n",
    "            for xpath in ['.//ns:p//ns:persName', './/ns:p//ns:placeName']:\n",
    "                for elem in eachDoc.findall(xpath, ns):\n",
    "                    name = elem.text\n",
    "                    try:\n",
    "                        entity = re.sub(r'\\s+', ' ', name)\n",
    "                    except TypeError:\n",
    "                        entity = name\n",
    "\n",
    "                    entities = entities.append({'file':reFile,\n",
    "                                    'entry':entry,\n",
    "                                    'text':text,\n",
    "                                    'element':re.sub(r'.*}(.*)', '\\\\1', elem.tag),\n",
    "                                    'entity':entity},\n",
    "                                   ignore_index = True)\n",
    "\n",
    "            \n",
    "        else:\n",
    "            print ('Selected dataset not found.')\n",
    "        \n",
    "                \n",
    "entities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Functions to Find Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 4.77 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# NLTK\n",
    "def get_nltk_entities(text, label_list):\n",
    "    chunked = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "    prev = None\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for subtree in chunked:\n",
    "        if type(subtree) == Tree and subtree.label() in label_list:\n",
    "            current_chunk.append(\" \".join([token for token, pos in subtree.leaves()]))\n",
    "        if current_chunk:\n",
    "            named_entity = \" \".join(current_chunk)\n",
    "            if named_entity not in continuous_chunk:\n",
    "                continuous_chunk.append((named_entity, subtree.label()))\n",
    "                current_chunk = []\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return continuous_chunk\n",
    "\n",
    "# spaCy\n",
    "def get_spacy_entities(text, label_list):\n",
    "    sp_entities_l = []\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in label_list:\n",
    "            sp_entities_l.append((str(ent), ent.label_))\n",
    "        else:\n",
    "            pass\n",
    "    return sp_entities_l\n",
    "\n",
    "# CREATE CUSTOM SPACY FUNCTION\n",
    "def get_custom_spacy_entities(text, label_list):\n",
    "    sp_entities_l = []\n",
    "    doc = jqa_spacy(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in label_list:\n",
    "            sp_entities_l.append((str(ent), ent.label_))\n",
    "        else:\n",
    "            pass\n",
    "    return sp_entities_l\n",
    "\n",
    "\n",
    "# Stanford (return full-PERSON name as single string)\n",
    "# From alvas, StackOverflow\n",
    "def chunk_stanfordNER(ner_output, label_list):\n",
    "    chunked, pos = [], \"\"\n",
    "    for i, word_pos in enumerate(ner_output):\n",
    "        word, pos = word_pos\n",
    "        if pos in label_list and pos == prev_tag:\n",
    "            chunked[-1]+=word_pos\n",
    "        else:\n",
    "            chunked.append(word_pos)\n",
    "        prev_tag = pos\n",
    "\n",
    "    clean_chunked = [tuple([\" \".join(wordpos[::2]),\n",
    "                            wordpos[-1]]) if len(wordpos)!=2 else wordpos for wordpos in chunked]\n",
    "    chunks_subset = [tup for tup in clean_chunked if tup[1] in label_list]\n",
    "    \n",
    "    return chunks_subset\n",
    "\n",
    "# Stanford\n",
    "def get_stanford_entities(text, label_list):\n",
    "    tokenized_text = word_tokenize(text)\n",
    "    tagged_text = tagger.tag(tokenized_text)\n",
    "    chunked_entities = chunk_stanfordNER(tagged_text, label_list)\n",
    "\n",
    "    return chunked_entities\n",
    "\n",
    "# Custom Stanford\n",
    "def get_custom_stanford_NER(text, label_list):\n",
    "    tokenized_text = word_tokenize(text)\n",
    "    tagged_text = custom_ner_tagger.tag(tokenized_text)\n",
    "    chunked_entities = chunk_stanfordNER(tagged_text, label_list)\n",
    "    \n",
    "    return chunked_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK entities found.\n",
      "Spacy entities found.\n",
      "Custom spaCy entities found.\n",
      "Stanford entities found.\n",
      "Custom stanford entities found.\n",
      "CPU times: user 2.35 s, sys: 2.92 s, total: 5.27 s\n",
      "Wall time: 1min 42s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>entry</th>\n",
       "      <th>element</th>\n",
       "      <th>entity</th>\n",
       "      <th>model</th>\n",
       "      <th>found_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-02</td>\n",
       "      <td>persName</td>\n",
       "      <td>Lynd</td>\n",
       "      <td>nltk</td>\n",
       "      <td>[(Heard Lynd, PERSON), (Garnett, PERSON)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-02</td>\n",
       "      <td>persName</td>\n",
       "      <td>Baker’s</td>\n",
       "      <td>nltk</td>\n",
       "      <td>[(Heard Lynd, PERSON), (Garnett, PERSON)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-02</td>\n",
       "      <td>persName</td>\n",
       "      <td>Matthew</td>\n",
       "      <td>nltk</td>\n",
       "      <td>[(Heard Lynd, PERSON), (Garnett, PERSON)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-02</td>\n",
       "      <td>persName</td>\n",
       "      <td>Garnett</td>\n",
       "      <td>nltk</td>\n",
       "      <td>[(Heard Lynd, PERSON), (Garnett, PERSON)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-02</td>\n",
       "      <td>persName</td>\n",
       "      <td>G. Hay</td>\n",
       "      <td>nltk</td>\n",
       "      <td>[(Heard Lynd, PERSON), (Garnett, PERSON)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   file                      entry   element  \\\n",
       "0  TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-02  persName   \n",
       "1  TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-02  persName   \n",
       "2  TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-02  persName   \n",
       "3  TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-02  persName   \n",
       "4  TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-02  persName   \n",
       "\n",
       "    entity model                             found_entities  \n",
       "0     Lynd  nltk  [(Heard Lynd, PERSON), (Garnett, PERSON)]  \n",
       "1  Baker’s  nltk  [(Heard Lynd, PERSON), (Garnett, PERSON)]  \n",
       "2  Matthew  nltk  [(Heard Lynd, PERSON), (Garnett, PERSON)]  \n",
       "3  Garnett  nltk  [(Heard Lynd, PERSON), (Garnett, PERSON)]  \n",
       "4   G. Hay  nltk  [(Heard Lynd, PERSON), (Garnett, PERSON)]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Add or substract labels to list for NER to find.\n",
    "label_list = ['PERSON']\n",
    "\n",
    "entities_sub = entities[['entry', 'text']].drop_duplicates()\n",
    "\n",
    "# Apply function to find NLTK-based entities.\n",
    "entities_sub['nltk'] = entities_sub.apply(lambda row: get_nltk_entities(row['text'],\n",
    "                                                                        label_list),\n",
    "                                          axis = 1)\n",
    "print (\"NLTK entities found.\")\n",
    "\n",
    "# Apply function to find spaCy-based entities.\n",
    "entities_sub['spacy'] = entities_sub.apply(lambda row: get_spacy_entities(row['text'],\n",
    "                                                                          label_list),\n",
    "                                           axis = 1)\n",
    "print (\"Spacy entities found.\")\n",
    "\n",
    "\n",
    "# Apply function to find custom spaCy-based entities.\n",
    "entities_sub['custom_spacy'] = entities_sub \\\n",
    "    .apply(lambda row: get_custom_spacy_entities(row['text'], label_list),\n",
    "           axis = 1)\n",
    "\n",
    "print (\"Custom spaCy entities found.\")\n",
    "\n",
    "# Apply function to find Stanford-based entities.\n",
    "entities_sub['stanford'] = entities_sub.apply(lambda row: get_stanford_entities(row['text'],\n",
    "                                                                                label_list),\n",
    "                                           axis = 1)\n",
    "print (\"Stanford entities found.\")\n",
    "\n",
    "\n",
    "# Apply function to find Stanford-based entities.\n",
    "entities_sub['custom_stanford'] = entities_sub \\\n",
    "    .apply(lambda row: get_custom_stanford_NER(row['text'], label_list),\n",
    "           axis = 1)\n",
    "\n",
    "print (\"Custom stanford entities found.\")\n",
    "\n",
    "\n",
    "# Merge found entities with metadata & tidy up data.\n",
    "if dataset == \"all\":\n",
    "    entities = pd.merge(entities[['file', 'entry', 'element', 'refKey', 'entity']],\n",
    "                    entities_sub[['entry', 'nltk', 'spacy', 'custom_spacy',\n",
    "                                  'stanford', 'custom_stanford']],\n",
    "                    on = 'entry', how = 'left')\n",
    "    \n",
    "    entities = pd.melt(entities, id_vars = ['file', 'entry', 'element', 'refKey', 'entity'],\n",
    "                       value_vars = ['nltk', 'spacy', 'custom_spacy',\n",
    "                                     'stanford', 'custom_stanford'],\n",
    "                       var_name = 'model', value_name = 'found_entities')\n",
    "elif dataset == \"testing\":\n",
    "    entities = pd.merge(entities[['file', 'entry', 'element', 'entity']],\n",
    "                    entities_sub[['entry', 'nltk', 'spacy', 'custom_spacy',\n",
    "                                  'stanford', 'custom_stanford']],\n",
    "                    on = 'entry', how = 'left')\n",
    "    \n",
    "    entities = pd.melt(entities, id_vars = ['file', 'entry', 'element', 'entity'],\n",
    "                       value_vars = ['nltk', 'spacy', 'custom_spacy',\n",
    "                                     'stanford', 'custom_stanford'],\n",
    "                       var_name = 'model', value_name = 'found_entities')\n",
    "else:\n",
    "    \"Dataset not found.\"\n",
    "\n",
    "\n",
    "entities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Match Entities\n",
    "\n",
    "Fuzzy Matching has four modes of calculating likeness.\n",
    "\n",
    "1. ratio\n",
    "2. partial_ratio\n",
    "3. token_sort_ratio\n",
    "4. token_set_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.64 s, sys: 30 ms, total: 2.67 s\n",
      "Wall time: 2.69 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>entry</th>\n",
       "      <th>element</th>\n",
       "      <th>entity</th>\n",
       "      <th>model</th>\n",
       "      <th>found_entities</th>\n",
       "      <th>found_entity</th>\n",
       "      <th>entity_label</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-02</td>\n",
       "      <td>persName</td>\n",
       "      <td>Baker’s</td>\n",
       "      <td>custom_spacy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-02</td>\n",
       "      <td>persName</td>\n",
       "      <td>Baker’s</td>\n",
       "      <td>custom_stanford</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-02</td>\n",
       "      <td>persName</td>\n",
       "      <td>Baker’s</td>\n",
       "      <td>nltk</td>\n",
       "      <td>(Heard Lynd, PERSON)</td>\n",
       "      <td>Heard Lynd</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-02</td>\n",
       "      <td>persName</td>\n",
       "      <td>Baker’s</td>\n",
       "      <td>spacy</td>\n",
       "      <td>(Baker, PERSON)</td>\n",
       "      <td>Baker</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-02</td>\n",
       "      <td>persName</td>\n",
       "      <td>Baker’s</td>\n",
       "      <td>stanford</td>\n",
       "      <td>(Baker, PERSON)</td>\n",
       "      <td>Baker</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   file                      entry   element  \\\n",
       "0  TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-02  persName   \n",
       "1  TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-02  persName   \n",
       "2  TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-02  persName   \n",
       "3  TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-02  persName   \n",
       "4  TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-02  persName   \n",
       "\n",
       "    entity            model        found_entities found_entity entity_label  \\\n",
       "0  Baker’s     custom_spacy                   NaN          NaN         None   \n",
       "1  Baker’s  custom_stanford                   NaN          NaN         None   \n",
       "2  Baker’s             nltk  (Heard Lynd, PERSON)   Heard Lynd       PERSON   \n",
       "3  Baker’s            spacy       (Baker, PERSON)        Baker       PERSON   \n",
       "4  Baker’s         stanford       (Baker, PERSON)        Baker       PERSON   \n",
       "\n",
       "   confidence  \n",
       "0          20  \n",
       "1          20  \n",
       "2          35  \n",
       "3          83  \n",
       "4          83  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Unnest found_entities.\n",
    "entities = entities.explode('found_entities')\n",
    "\n",
    "# Un-tuple 'found_entities'.\n",
    "entities[['found_entity', 'entity_label']] = pd.DataFrame(entities['found_entities'] \\\n",
    "                                                          .values.tolist(),\n",
    "                                                     index = entities.index)\n",
    "\n",
    "# Determine quality of fuzzy match.\n",
    "entities['confidence'] = entities \\\n",
    "    .apply(lambda row: fuzz.token_sort_ratio(row['entity'], row['found_entity']),\n",
    "           axis = 1)\n",
    "\n",
    "# Define function to return the dataframe row with the highest value in a group.\n",
    "def grp_func(group, column):\n",
    "    return group.loc[group[column] == group[column].max()]\n",
    "\n",
    "\n",
    "# Select ner_match with highest confidence score for model, entity in each entry.\n",
    "entities = entities.groupby(['entry', 'entity', 'model'], as_index = False) \\\n",
    "    .apply(grp_func, 'confidence').reset_index(drop = True)\n",
    "\n",
    "entities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write File for Model Comparisons\n",
    "\n",
    "The final dataset compares every found entity (within an entry and model) and selects the best match for the encoded entity.\n",
    "\n",
    "In some cases, the best match is actually not a match (e.g. NLTK considers \"La Forêt\" the closest match to \"A. Gallatin,\" presumably because it doesn't find a \"Gallatin\"). Further filtering and adjustments will happen in JQA_NER-ModelsEvaluator because it's easier to remove data than re-run programs to collect more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.4 ms, sys: 2.26 ms, total: 22.7 ms\n",
      "Wall time: 22.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "entities.to_csv(abs_dir + 'Output/NER/ner-model-comparisons_' + str(dataset) + '.csv',\n",
    "                sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "* Additional found entities would appear as found entities NOT in list of (element) content\n",
    "* Rather than rely on encoded data, NER could refer to names authority\n",
    "    * Each found entity would be compared to entire list of names authority and any matches would be assumed to be an entity\n",
    "    \n",
    "## Examine Matched & Unmatched Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>entry</th>\n",
       "      <th>element</th>\n",
       "      <th>entity</th>\n",
       "      <th>model</th>\n",
       "      <th>found_entities</th>\n",
       "      <th>found_entity</th>\n",
       "      <th>entity_label</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-02</td>\n",
       "      <td>persName</td>\n",
       "      <td>Baker’s</td>\n",
       "      <td>nltk</td>\n",
       "      <td>(Heard Lynd, PERSON)</td>\n",
       "      <td>Heard Lynd</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-02</td>\n",
       "      <td>persName</td>\n",
       "      <td>G. Hay</td>\n",
       "      <td>nltk</td>\n",
       "      <td>(Heard Lynd, PERSON)</td>\n",
       "      <td>Heard Lynd</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-02</td>\n",
       "      <td>persName</td>\n",
       "      <td>Matthew</td>\n",
       "      <td>nltk</td>\n",
       "      <td>(Garnett, PERSON)</td>\n",
       "      <td>Garnett</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-02</td>\n",
       "      <td>persName</td>\n",
       "      <td>Matthew</td>\n",
       "      <td>spacy</td>\n",
       "      <td>(Garnett, PERSON)</td>\n",
       "      <td>Garnett</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-02</td>\n",
       "      <td>persName</td>\n",
       "      <td>Tracy</td>\n",
       "      <td>nltk</td>\n",
       "      <td>(Heard Lynd, PERSON)</td>\n",
       "      <td>Heard Lynd</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>TestData_JQADiaries-v33-1821-12-p001</td>\n",
       "      <td>jqadiaries-v33-1821-12-31</td>\n",
       "      <td>placeName</td>\n",
       "      <td>Vera-Cruz</td>\n",
       "      <td>nltk</td>\n",
       "      <td>(Morel, PERSON)</td>\n",
       "      <td>Morel</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756</th>\n",
       "      <td>TestData_JQADiaries-v33-1821-12-p001</td>\n",
       "      <td>jqadiaries-v33-1821-12-31</td>\n",
       "      <td>placeName</td>\n",
       "      <td>Vera-Cruz</td>\n",
       "      <td>nltk</td>\n",
       "      <td>(Eaton, PERSON)</td>\n",
       "      <td>Eaton</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>TestData_JQADiaries-v33-1821-12-p001</td>\n",
       "      <td>jqadiaries-v33-1821-12-31</td>\n",
       "      <td>placeName</td>\n",
       "      <td>Vera-Cruz</td>\n",
       "      <td>spacy</td>\n",
       "      <td>(Russell, PERSON)</td>\n",
       "      <td>Russell</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>TestData_JQADiaries-v33-1821-12-p001</td>\n",
       "      <td>jqadiaries-v33-1821-12-31</td>\n",
       "      <td>placeName</td>\n",
       "      <td>Vera-Cruz</td>\n",
       "      <td>stanford</td>\n",
       "      <td>(Morel, PERSON)</td>\n",
       "      <td>Morel</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3759</th>\n",
       "      <td>TestData_JQADiaries-v33-1821-12-p001</td>\n",
       "      <td>jqadiaries-v33-1821-12-31</td>\n",
       "      <td>placeName</td>\n",
       "      <td>Vera-Cruz</td>\n",
       "      <td>stanford</td>\n",
       "      <td>(Eaton, PERSON)</td>\n",
       "      <td>Eaton</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1262 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      file                      entry  \\\n",
       "2     TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-02   \n",
       "7     TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-02   \n",
       "22    TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-02   \n",
       "23    TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-02   \n",
       "27    TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-02   \n",
       "...                                    ...                        ...   \n",
       "3755  TestData_JQADiaries-v33-1821-12-p001  jqadiaries-v33-1821-12-31   \n",
       "3756  TestData_JQADiaries-v33-1821-12-p001  jqadiaries-v33-1821-12-31   \n",
       "3757  TestData_JQADiaries-v33-1821-12-p001  jqadiaries-v33-1821-12-31   \n",
       "3758  TestData_JQADiaries-v33-1821-12-p001  jqadiaries-v33-1821-12-31   \n",
       "3759  TestData_JQADiaries-v33-1821-12-p001  jqadiaries-v33-1821-12-31   \n",
       "\n",
       "        element     entity     model        found_entities found_entity  \\\n",
       "2      persName    Baker’s      nltk  (Heard Lynd, PERSON)   Heard Lynd   \n",
       "7      persName     G. Hay      nltk  (Heard Lynd, PERSON)   Heard Lynd   \n",
       "22     persName    Matthew      nltk     (Garnett, PERSON)      Garnett   \n",
       "23     persName    Matthew     spacy     (Garnett, PERSON)      Garnett   \n",
       "27     persName      Tracy      nltk  (Heard Lynd, PERSON)   Heard Lynd   \n",
       "...         ...        ...       ...                   ...          ...   \n",
       "3755  placeName  Vera-Cruz      nltk       (Morel, PERSON)        Morel   \n",
       "3756  placeName  Vera-Cruz      nltk       (Eaton, PERSON)        Eaton   \n",
       "3757  placeName  Vera-Cruz     spacy     (Russell, PERSON)      Russell   \n",
       "3758  placeName  Vera-Cruz  stanford       (Morel, PERSON)        Morel   \n",
       "3759  placeName  Vera-Cruz  stanford       (Eaton, PERSON)        Eaton   \n",
       "\n",
       "     entity_label  confidence  \n",
       "2          PERSON        35.0  \n",
       "7          PERSON        40.0  \n",
       "22         PERSON        43.0  \n",
       "23         PERSON        43.0  \n",
       "27         PERSON        27.0  \n",
       "...           ...         ...  \n",
       "3755       PERSON        29.0  \n",
       "3756       PERSON        29.0  \n",
       "3757       PERSON        38.0  \n",
       "3758       PERSON        29.0  \n",
       "3759       PERSON        29.0  \n",
       "\n",
       "[1262 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# Identify matched elements & entities.\n",
    "matches = entities.query('confidence >= 55')\n",
    "\n",
    "# # unmatched elements == elements without a found_entity > 70\n",
    "# Subset elements that are not matched.\n",
    "unmatched_elems = entities[~entities.isin(matches)].dropna()\n",
    "\n",
    "\n",
    "# # unmatched found_entities == found_entities without an element > 70\n",
    "\n",
    "unmatched_elems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>entry</th>\n",
       "      <th>element</th>\n",
       "      <th>entity</th>\n",
       "      <th>model</th>\n",
       "      <th>found_entities</th>\n",
       "      <th>found_entity</th>\n",
       "      <th>entity_label</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-08</td>\n",
       "      <td>persName</td>\n",
       "      <td>General Brown’s</td>\n",
       "      <td>nltk</td>\n",
       "      <td>(Baron Tuyll, PERSON)</td>\n",
       "      <td>Baron Tuyll</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-09</td>\n",
       "      <td>persName</td>\n",
       "      <td>Little</td>\n",
       "      <td>nltk</td>\n",
       "      <td>(Heard Little Eccles, PERSON)</td>\n",
       "      <td>Heard Little Eccles</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-13</td>\n",
       "      <td>persName</td>\n",
       "      <td>Wingate</td>\n",
       "      <td>nltk</td>\n",
       "      <td>(Met R. King, PERSON)</td>\n",
       "      <td>Met R. King</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-13</td>\n",
       "      <td>persName</td>\n",
       "      <td>Wingate</td>\n",
       "      <td>spacy</td>\n",
       "      <td>(Met R. King, PERSON)</td>\n",
       "      <td>Met R. King</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>TestData_JQADiaries-v23-1825-01-p403</td>\n",
       "      <td>jqadiaries-v23-1825-01-13</td>\n",
       "      <td>persName</td>\n",
       "      <td>Wingate</td>\n",
       "      <td>stanford</td>\n",
       "      <td>(R. King, PERSON)</td>\n",
       "      <td>R. King</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3655</th>\n",
       "      <td>TestData_JQADiaries-v33-1821-12-p001</td>\n",
       "      <td>jqadiaries-v33-1821-12-31</td>\n",
       "      <td>placeName</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>nltk</td>\n",
       "      <td>(Consul, PERSON)</td>\n",
       "      <td>Consul</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>TestData_JQADiaries-v33-1821-12-p001</td>\n",
       "      <td>jqadiaries-v33-1821-12-31</td>\n",
       "      <td>persName</td>\n",
       "      <td>R. Ingersoll</td>\n",
       "      <td>stanford</td>\n",
       "      <td>(R. M. Johnson, PERSON)</td>\n",
       "      <td>R. M. Johnson</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>TestData_JQADiaries-v33-1821-12-p001</td>\n",
       "      <td>jqadiaries-v33-1821-12-31</td>\n",
       "      <td>persName</td>\n",
       "      <td>Spanish Minister Anduaga</td>\n",
       "      <td>nltk</td>\n",
       "      <td>(Anduaga, PERSON)</td>\n",
       "      <td>Anduaga</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>TestData_JQADiaries-v33-1821-12-p001</td>\n",
       "      <td>jqadiaries-v33-1821-12-31</td>\n",
       "      <td>persName</td>\n",
       "      <td>Spanish Minister Anduaga</td>\n",
       "      <td>spacy</td>\n",
       "      <td>(Anduaga, PERSON)</td>\n",
       "      <td>Anduaga</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>TestData_JQADiaries-v33-1821-12-p001</td>\n",
       "      <td>jqadiaries-v33-1821-12-31</td>\n",
       "      <td>persName</td>\n",
       "      <td>Spanish Minister Anduaga</td>\n",
       "      <td>stanford</td>\n",
       "      <td>(Anduaga, PERSON)</td>\n",
       "      <td>Anduaga</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      file                      entry  \\\n",
       "137   TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-08   \n",
       "152   TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-09   \n",
       "227   TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-13   \n",
       "228   TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-13   \n",
       "229   TestData_JQADiaries-v23-1825-01-p403  jqadiaries-v23-1825-01-13   \n",
       "...                                    ...                        ...   \n",
       "3655  TestData_JQADiaries-v33-1821-12-p001  jqadiaries-v33-1821-12-31   \n",
       "3726  TestData_JQADiaries-v33-1821-12-p001  jqadiaries-v33-1821-12-31   \n",
       "3740  TestData_JQADiaries-v33-1821-12-p001  jqadiaries-v33-1821-12-31   \n",
       "3741  TestData_JQADiaries-v33-1821-12-p001  jqadiaries-v33-1821-12-31   \n",
       "3742  TestData_JQADiaries-v33-1821-12-p001  jqadiaries-v33-1821-12-31   \n",
       "\n",
       "        element                    entity     model  \\\n",
       "137    persName           General Brown’s      nltk   \n",
       "152    persName                    Little      nltk   \n",
       "227    persName                   Wingate      nltk   \n",
       "228    persName                   Wingate     spacy   \n",
       "229    persName                   Wingate  stanford   \n",
       "...         ...                       ...       ...   \n",
       "3655  placeName               Connecticut      nltk   \n",
       "3726   persName              R. Ingersoll  stanford   \n",
       "3740   persName  Spanish Minister Anduaga      nltk   \n",
       "3741   persName  Spanish Minister Anduaga     spacy   \n",
       "3742   persName  Spanish Minister Anduaga  stanford   \n",
       "\n",
       "                     found_entities         found_entity entity_label  \\\n",
       "137           (Baron Tuyll, PERSON)          Baron Tuyll       PERSON   \n",
       "152   (Heard Little Eccles, PERSON)  Heard Little Eccles       PERSON   \n",
       "227           (Met R. King, PERSON)          Met R. King       PERSON   \n",
       "228           (Met R. King, PERSON)          Met R. King       PERSON   \n",
       "229               (R. King, PERSON)              R. King       PERSON   \n",
       "...                             ...                  ...          ...   \n",
       "3655               (Consul, PERSON)               Consul       PERSON   \n",
       "3726        (R. M. Johnson, PERSON)        R. M. Johnson       PERSON   \n",
       "3740              (Anduaga, PERSON)              Anduaga       PERSON   \n",
       "3741              (Anduaga, PERSON)              Anduaga       PERSON   \n",
       "3742              (Anduaga, PERSON)              Anduaga       PERSON   \n",
       "\n",
       "      confidence  \n",
       "137           46  \n",
       "152           48  \n",
       "227           47  \n",
       "228           47  \n",
       "229           46  \n",
       "...          ...  \n",
       "3655          47  \n",
       "3726          45  \n",
       "3740          45  \n",
       "3741          45  \n",
       "3742          45  \n",
       "\n",
       "[138 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# entities.query('entry == \"jqadiaries-v23-1821-05-02\"')\n",
    "\n",
    "entities.query('45 <= confidence <= 49')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
