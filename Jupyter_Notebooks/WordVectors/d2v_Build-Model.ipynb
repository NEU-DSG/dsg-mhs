{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cloudy-explorer",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "built-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, string, glob, gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "import gensim.models.doc2vec\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1 # This will be painfully slow otherwise\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "\n",
    "# Import parser module.\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path + '//Scripts')\n",
    "\n",
    "from functions_xml_ET_parse import *\n",
    "\n",
    "# Declare absolute path.\n",
    "abs_dir = \"/Users/quinn.wi/Documents/\"\n",
    "\n",
    "# Define tokenizer.\n",
    "def fast_tokenize(text):\n",
    "    \n",
    "    # Get a list of punctuation marks\n",
    "    punct = string.punctuation + '“' + '”' + '‘' + \"’\"\n",
    "    \n",
    "    lower_case = text.lower()\n",
    "    lower_case = lower_case.replace('—', ' ').replace('\\n', ' ')\n",
    "    \n",
    "    # Iterate through text removing punctuation characters\n",
    "    no_punct = \"\".join([char for char in lower_case if char not in punct])\n",
    "    \n",
    "    # Split text over whitespace into list of words\n",
    "    tokens = no_punct.split()\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-leader",
   "metadata": {},
   "source": [
    "## Build Dataframe from XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "quantitative-auditor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.97 s, sys: 82.9 ms, total: 4.05 s\n",
      "Wall time: 4.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>entry</th>\n",
       "      <th>date</th>\n",
       "      <th>people</th>\n",
       "      <th>subject</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JQADiaries-v27-1808-08-p364.xml</td>\n",
       "      <td>jqadiaries-v27-1808-08-01</td>\n",
       "      <td>1808-08-01</td>\n",
       "      <td>courtdegebelin-antoine,gregory-george,rousseau...</td>\n",
       "      <td>Recreation</td>\n",
       "      <td>1. Bathed with George this morning, at the pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JQADiaries-v27-1808-08-p364.xml</td>\n",
       "      <td>jqadiaries-v27-1808-08-02</td>\n",
       "      <td>1808-08-02</td>\n",
       "      <td>degrand-peter,everett-alexander</td>\n",
       "      <td>Recreation</td>\n",
       "      <td>2. Bathed again this Morning, and took George ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JQADiaries-v27-1808-08-p364.xml</td>\n",
       "      <td>jqadiaries-v27-1808-08-03</td>\n",
       "      <td>1808-08-03</td>\n",
       "      <td>degrand-peter,welsh-thomas,davis-john,dawes-th...</td>\n",
       "      <td>Recreation</td>\n",
       "      <td>3. Bathed this morning, at 6. with Mr: De Gran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JQADiaries-v27-1808-08-p364.xml</td>\n",
       "      <td>jqadiaries-v27-1808-08-04</td>\n",
       "      <td>1808-08-04</td>\n",
       "      <td>boylston-ward,degrand-peter,adams-louisa-cathe...</td>\n",
       "      <td>Recreation</td>\n",
       "      <td>4. Mr: Boylston called for me by appointment, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              file                      entry        date  \\\n",
       "0  JQADiaries-v27-1808-08-p364.xml  jqadiaries-v27-1808-08-01  1808-08-01   \n",
       "1  JQADiaries-v27-1808-08-p364.xml  jqadiaries-v27-1808-08-02  1808-08-02   \n",
       "2  JQADiaries-v27-1808-08-p364.xml  jqadiaries-v27-1808-08-03  1808-08-03   \n",
       "3  JQADiaries-v27-1808-08-p364.xml  jqadiaries-v27-1808-08-04  1808-08-04   \n",
       "\n",
       "                                              people     subject  \\\n",
       "0  courtdegebelin-antoine,gregory-george,rousseau...  Recreation   \n",
       "1                    degrand-peter,everett-alexander  Recreation   \n",
       "2  degrand-peter,welsh-thomas,davis-john,dawes-th...  Recreation   \n",
       "3  boylston-ward,degrand-peter,adams-louisa-cathe...  Recreation   \n",
       "\n",
       "                                                text  \n",
       "0  1. Bathed with George this morning, at the pla...  \n",
       "1  2. Bathed again this Morning, and took George ...  \n",
       "2  3. Bathed this morning, at 6. with Mr: De Gran...  \n",
       "3  4. Mr: Boylston called for me by appointment, ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\"\n",
    "Declare variables.\n",
    "\"\"\"\n",
    "\n",
    "# Declare regex to simplify file paths below\n",
    "regex = re.compile(r'.*/.*/(.*.xml)')\n",
    "\n",
    "# Declare document level of file. Requires root starting point ('.').\n",
    "doc_as_xpath = './/ns:div/[@type=\"entry\"]'\n",
    "\n",
    "# Declare date element of each document.\n",
    "date_path = './ns:bibl/ns:date/[@when]'\n",
    "\n",
    "# Declare person elements in each document.\n",
    "person_path = './/ns:p/ns:persRef/[@ref]'\n",
    "\n",
    "# Declare subject elements in each document.\n",
    "subject_path = './/ns:bibl//ns:subject'\n",
    "\n",
    "# Declare text level within each document.\n",
    "text_path = './ns:div/[@type=\"docbody\"]/ns:p'\n",
    "\n",
    "\"\"\"\n",
    "Build dataframe.\n",
    "\"\"\"\n",
    "\n",
    "dataframe = []\n",
    "\n",
    "for file in glob.glob(abs_dir + 'Data/PSC/JQA/*/*.xml'):\n",
    "    reFile = str(regex.search(file).group(1))\n",
    "#         Call functions to create necessary variables and grab content.\n",
    "    root = get_root(file)\n",
    "    ns = get_namespace(root)\n",
    "\n",
    "    for eachDoc in root.findall(doc_as_xpath, ns):\n",
    "#         Call functions.\n",
    "        entry = get_document_id(eachDoc, '{http://www.w3.org/XML/1998/namespace}id')\n",
    "        date = get_date_from_attrValue(eachDoc, date_path, 'when', ns)\n",
    "        people = get_peopleList_from_attrValue(eachDoc, person_path, 'ref', ns)\n",
    "        subject = get_subject(eachDoc, subject_path, ns)\n",
    "        text = get_textContent(eachDoc, text_path, ns)\n",
    "\n",
    "        dataframe.append([reFile, entry, date, people, subject, text])\n",
    "\n",
    "dataframe = pd.DataFrame(dataframe, columns = ['file', 'entry', 'date', \n",
    "                                               'people', 'subject', 'text'])\n",
    "\n",
    "# Split subject list and return \"Multiple-Subject\" or lone subject.\n",
    "dataframe['subject'] = dataframe['subject'].str.split(r',')\n",
    "\n",
    "def handle_subjects(subj_list):\n",
    "    if len(subj_list) > 1:\n",
    "        return 'Multiple-Subjects'\n",
    "    else:\n",
    "        return subj_list[0]\n",
    "    \n",
    "dataframe['subject'] = dataframe['subject'].apply(handle_subjects)\n",
    "\n",
    "dataframe.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-mumbai",
   "metadata": {},
   "source": [
    "## Build doc2vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "present-camel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 2.28 s, total: 1min 25s\n",
      "Wall time: 38.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create corpus.\n",
    "tagged_docs = dataframe \\\n",
    "    .apply(lambda x: TaggedDocument(simple_preprocess(x.text),\n",
    "                                    [f'{x.entry}']\n",
    "#                                    ['doc{}',format(x.entry)]\n",
    "                                   ), \n",
    "           axis = 1)\n",
    "\n",
    "training_corpus = tagged_docs.values\n",
    "\n",
    "# Training\n",
    "model = Doc2Vec(vector_size = 200, min_count = 4, epochs = 10)\n",
    "\n",
    "model.build_vocab(training_corpus)\n",
    "\n",
    "model.train(training_corpus, \n",
    "            total_examples = model.corpus_count, \n",
    "            epochs = model.epochs)\n",
    "\n",
    "# Store model.\n",
    "model.save(abs_dir + 'Data/Output/WordVectors/jqa-d2v.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-powell",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
